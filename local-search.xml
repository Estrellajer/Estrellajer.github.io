<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/10/08/Paper/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/Cot-Decoding/"/>
    <url>/2024/10/08/Paper/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/Cot-Decoding/</url>
    
    <content type="html"><![CDATA[<h3 id="大语言模型的推理能力无需提示的思维链解码"><strong>🟢大语言模型的推理能力：无需提示的思维链解码</strong></h3><p>在🤖人工智能领域，大语言模型（LLMs），例如GPT-4和PaLM-2，展现出了强大的🧠推理能力。通常，我们通过提示（prompting）技术来激发这些推理能力，但这一过程需要复杂的🛠️手动设计，例如少样本提示和零样本提示。然而，最近的一项研究提出了一个全新的问题：大语言模型能否在没有提示的情况下进行有效推理？这种方法被称为“思维链解码”（CoT-decoding），揭示了LLMs的固有推理能力，而无需依赖人为提示。</p><h4 id="现有推理方法的局限性">现有推理方法的局限性</h4><p>现有的推理方法主要包括两种：</p><ol type="1"><li><p><strong>提示技术</strong>：通过少样本提示或零样本提示来激发模型的🧠推理能力。这种方式虽然有效，但通常依赖于人类的先验知识，难以真实评估模型的内在推理能力。</p></li><li><p><strong>模型训练</strong>：通过大量的监督数据对模型进行微调，使其学会推理。这种方法代价高昂，且依赖大量的📊标注数据。</p></li></ol><h4 id="思维链解码的创新">思维链解码的创新</h4><p>这项新研究的核心问题是：<strong>大语言模型是否具备在没有提示的情况下推理的能力？</strong>研究者通过改变解码过程，而不是使用传统的贪婪解码（即每次选择概率最高的词），来探索模型的推理路径。通过考虑前几个候选词（top-ktokens）的替代路径，他们发现模型能够自然地展现思维链推理能力。</p><p>例如，给定问题：“我有🍎3个苹果，我爸爸比我多🍎2个苹果，我们一共有多少个苹果？”</p><p><strong>贪婪解码示例</strong>： 1.使用贪婪解码时，模型直接选择概率最高的词，得到如下推理： -第一步，模型解码出“5”，最终生成答案为“🍎5个苹果”。 -这种情况下，模型并没有展现出逐步推理的能力，只是简单地给出了一个错误的直接答案。</p><p><strong>思维链解码示例</strong>： 1.使用思维链解码时，我们考虑前几个候选词（例如top-3tokens）并沿不同路径继续解码。 -在某一条路径中，模型首先选择了“我”，然后继续解码：“我有🍎3个苹果，我爸爸比我多🍎2个苹果，所以他有🍎5个苹果，3+ 5 = 8，我们一共有🍎8个苹果”。 -在这条路径中，模型展现出了逐步推理的过程，最终得出正确答案“🍎8个苹果”。</p><p>通过这种方式，研究者发现，模型内在具备推理能力，只是传统的贪婪解码方法没有充分利用这些能力。</p><h4 id="思维链解码的优势">思维链解码的优势</h4><ol type="1"><li><p><strong>无需提示</strong>：这种方法完全绕过了提示技术，直接激发了模型的内在🧠推理能力，避免了复杂的提示设计。</p></li><li><p><strong>揭示内在能力</strong>：通过改变解码过程，研究者能够更真实地评估模型的🧠推理能力，而不受人为先验知识的影响。</p></li><li><p><strong>提高推理准确性</strong>：在数学和常识推理任务中，思维链解码相比贪婪解码表现出显著的改进。例如，在数学推理任务中，选择top-10解码路径中的最优路径，88%的情况下模型能够找到包含思维链的正确解码路径。</p></li></ol><h4 id="思维链解码的局限性">思维链解码的局限性</h4><p>尽管思维链解码在激发模型的推理能力方面展示了巨大的潜力，但它也存在一些局限性：</p><ol type="1"><li><p><strong>计算开销高</strong>：与传统的贪婪解码相比，思维链解码需要考虑多个候选路径，这显著增加了计算的复杂性和⏳时间成本。特别是在处理较长的文本或复杂的问题时，计算资源的需求会大幅上升。</p></li><li><p><strong>路径选择的复杂性</strong>：在实际应用中，选择合适的top-k值是一个挑战。如果选择的k值过大，可能会导致计算成本过高；如果k值过小，则可能错过有效的思维链路径，导致推理失败。</p></li><li><p><strong>模型的不确定性</strong>：虽然思维链解码能够提高模型的置信度，但并不能保证每次都能找到正确的解码路径。在某些情况下，即使考虑了多个解码路径，模型仍可能得出错误的结论。这种不确定性限制了思维链解码在高精度场景中的应用。</p></li><li><p><strong>对任务类型的依赖</strong>：思维链解码在一些任务中表现优异，例如数学推理和常识推理，但在其他类型的任务（如语言生成或开放式问答）中，其效果可能不如提示技术或其他方法。这表明思维链解码的适用性并不是通用的，还需要针对不同任务类型进行优化。</p></li></ol><h4 id="关键发现">关键发现</h4><p>研究表明，<strong>大语言模型具备内在的🧠推理能力</strong>，这些能力可以通过简单的解码修改来激发，而无需复杂的提示技术。传统的贪婪解码路径往往忽略了这些推理路径，而思维链解码能够有效地找到包含完整推理过程的路径，从而提高模型的推理准确性。</p><p>此外，研究还发现，当模型的解码路径中包含思维链时，模型对最终答案的置信度显著提高。这意味着，思维链不仅能帮助模型推理，还能使模型在生成答案时更加确定。</p><h4 id="研究意义">研究意义</h4><p>这项研究为我们理解和利用大语言模型提供了新的思路。它挑战了“大语言模型无法在没有提示的情况下进行有效推理”的传统观点，揭示了模型潜在的🧠推理能力。这一发现可能推动开发出新的、更高效的🤖AI系统，使得它们能够在更少人为干预的情况下进行复杂推理。</p><h4 id="总结">总结</h4><p>思维链解码为大语言模型的推理能力提供了新的视角。通过简单地改变解码过程，这种方法绕过了提示技术的复杂性，揭示了LLMs的固有🧠推理能力。这不仅有助于我们更好地理解这些模型，也为🤖AI领域的未来研究和应用提供了重要的启示。</p><p>如果您对大语言模型的🧠推理能力或思维链解码方法有更多兴趣，欢迎在💬评论区留言讨论！</p><h3id="思维链cot能够让transformer解决固有的串行问题"><strong>思维链（CoT）能够让Transformer解决固有的串行问题</strong></h3><p>Transformer模型近年来在自然语言处理领域展现出了强大的能力。然而，对于某些需要逐步推理的复杂任务，Transformer的并行计算特点让它难以表现得很好。那么，如何提升 Transformer在这些复杂任务上的表现呢？这正是我们今天要讨论的一篇论文所提出的问题。通过引入思维链（Chainof Thought，CoT），这篇论文探索了如何显著提升 Transformer模型的计算能力，特别是在处理那些需要一步步推理的“串行问题”时。</p><h4 id="什么是思维链chain-of-thought-cot">什么是思维链（Chain ofThought, CoT）？</h4><p>思维链（CoT）是一种技术，旨在让 Transformer模型在回答问题之前先生成一系列中间推理步骤，类似于人类解题的思维过程。这种逐步生成的方式，帮助模型更好地理解复杂问题的内在逻辑，从而得出更为精确的答案。</p><p>简单来说，如果你让模型回答一个复杂的数学问题，CoT会让它先写下所有的中间步骤，而不是直接给出最终答案。这种方式不仅可以帮助模型理解问题，还让它能通过“思维过程”更好地得出正确的结论。</p><h4 id="transformer-在处理串行问题上的限制">Transformer在处理串行问题上的限制</h4><p>首先，让我们来看看不带有思维链的 Transformer能处理哪些问题。Transformer的主要优势是其并行计算能力，因此在处理可并行化的问题时表现非常好。然而，对于那些必须逐步推进的任务（我们称之为<strong>串行问题</strong>），传统Transformer 在能力上存在严重的不足。</p><p>论文中，作者通过理论分析指出，常数深度的 Transformer在计算能力上受限于 <strong>AC0</strong> 和 <strong>TC0</strong>复杂度类。简单来说，AC0 和 TC0 都是描述电路计算能力的术语。AC0允许并行地进行基本的“与/或/非”操作，但不能解决像奇偶性检查（parity）这样的复杂问题。这意味着，没有思维链的Transformer 很难有效处理一些需要按特定顺序完成的任务。</p><h4 id="cot-如何提升-transformer-的能力">CoT 如何提升 Transformer的能力？</h4><p>那么，引入思维链（CoT）后，情况会如何改变呢？</p><p><strong>定理 3.3</strong> 中的一个重要结论是：<strong>带有多项式步骤CoT 的 Transformer，可以模拟比传统 Transformer更复杂的电路计算</strong>。这意味着，加入 CoT 后，Transformer可以通过逐步生成中间推理步骤，逐一处理更复杂的计算逻辑，就像完成一个个“任务关卡”一样。每一步的思维链对应于电路中的一个逻辑门操作，从而帮助模型逐步接近问题的解决方案。</p><h5 id="理论推导过程">理论推导过程</h5><p>论文中的理论推导分为几个关键步骤，以证明带有思维链的 Transformer能够显著提升其表达能力。</p><ol type="1"><li><p><strong>有限精度建模：保证结果的现实性</strong></p><ul><li>Transformer 的训练和推理通常使用 16 或 32 位浮点数。论文首先引入了<strong>有限精度的浮点数计算</strong>模型，解决了以往理论研究中假设的无限精度问题。这种有限精度模型确保了论文中的推导结果更加贴近实际计算机硬件中Transformer 的工作机制。</li><li>使用 <span class="math inline">\(e\)</span> 位的指数和 <spanclass="math inline">\(s\)</span>位的尾数来表示浮点数，并在每次算术运算后立即进行舍入，防止无限精度假设。通过这种舍入模型，作者推导出适用于有限精度的Transformer 计算模型。</li></ul></li><li><p><strong>Transformer 的表达能力：没有 CoT 的上界</strong></p><ul><li><p><strong>定理 3.1：AC0 上界</strong></p><ul><li>常数深度、常数精度的 Transformer 只能表达 AC0 复杂度类的函数。AC0类问题允许常数深度和多项式大小的与/或电路，但不能解决例如奇偶性（parity）这样的任务。</li></ul><p>公式上表示： <span class="math display">\[T[poly(n), 1, 1] \subseteq CoT[\log n, poly(n), 1, 1] \subseteq AC0\]</span></p></li><li><p><strong>定理 3.2：TC0 上界</strong></p><ul><li>当 Transformer使用定点数（没有指数位）时，即使进行舍入操作，它的表达能力也可以保持在TC0 复杂度类内。TC0 电路可以有效并行处理任务，如乘法、模运算等。</li></ul><p>公式上表示： <span class="math display">\[T[poly(n), \log(n), 0] \subseteq CoT[\log n, poly(n), \log(n), 0]\subseteq TC0\]</span></p></li></ul><p>这些定理证明了，在没有 CoT 的情况下，Transformer的计算能力受到限制，尤其是在处理复杂的串行任务时。</p></li><li><p><strong>引入思维链（CoT）：提高表达能力</strong></p><ul><li><p><strong>定理 3.3：CoT 提高表达能力</strong></p><ul><li>通过引入多项式步骤的 CoT，Transformer 可以通过每一步 CoT来模拟电路中的一个门操作，这使得模型能够处理复杂的串行任务。具体步骤如下：<ul><li>每一步 CoT 对应模拟电路中的一个逻辑门，如与、或、非操作。</li><li>模型使用注意力机制提取前两个输入门的值，并通过前馈网络计算当前门的值。</li></ul></li></ul><p>这种模拟过程极大地提升了 Transformer 的表达能力，特别是当嵌入大小为<span class="math inline">\(\log n\)</span>时，模型能够正确存储并区分不同位置的门信息。</p><p>公式上表示： <span class="math display">\[SIZE[T(n)] \subseteq CoT[T(n), \log n, 1]\]</span> 这表明，带有多项式 CoT 的 Transformer可以模拟所有多项式大小的布尔电路，极大拓展了其表达能力。</p></li><li><p><strong>定理 3.5：置换群 S5 的问题</strong></p><ul><li>在串行任务中，置换群（如 S5）是一个典型的复杂问题。定理 3.5证明了带有 CoT 的 Transformer 可以解决 S5 的置换问题，而没有 CoT 的Transformer 无法解决这个问题。</li></ul></li></ul></li></ol><h4 id="实验验证cot-的力量">实验验证：CoT 的力量</h4><p>为了验证 CoT 的有效性，作者通过一系列实验对比了不带 CoT 和带有 CoT 的Transformer 在不同类型任务上的表现，包括：</p><ul><li><strong>模加法</strong>：这是一个可以并行化的任务，结果表明，带或不带CoT 的 Transformer 在处理该任务时表现相似。</li><li><strong>置换组合（S5）和迭代平方</strong>：这两个任务需要一步步推理才能得到正确答案，属于典型的串行问题。实验结果显示，带有CoT 的 Transformer 几乎可以达到 100% 的准确率，而没有 CoT 的 Transformer在这些任务上的表现非常差，准确率仅在 20%-30% 左右。</li></ul><p>这些实验结果清楚地表明，<strong>引入思维链能够显著提升 Transformer在复杂推理任务上的表现，尤其是在深度有限的情况下</strong>。</p><h4 id="具体的例子帮助理解">具体的例子帮助理解</h4><p>为了更好地理解思维链（CoT）对 Transformer的提升作用，让我们来看几个具体的例子。</p><h5 id="例子-1模加法任务">例子 1：模加法任务</h5><p>考虑一个简单的模加法问题，例如求一组数字的和，然后对结果取模。假设输入是<code>[1, 2, 3, 4, 5]</code>，目标是计算这组数字的和并对 7取模。对于不带 CoT 的Transformer，模型需要一次性理解并输出最终结果，这对于深度有限的Transformer 来说比较困难。而带有 CoT 的 Transformer可以逐步生成每个数字的加法过程，比如：</p><ul><li>第一步：<code>1 + 2 = 3</code></li><li>第二步：<code>3 + 3 = 6</code></li><li>第三步：<code>6 + 4 = 10</code></li><li>第四步：<code>10 + 5 = 15</code></li><li>最后一步：<code>15 % 7 = 1</code></li></ul><p>通过逐步计算，带有 CoT的模型可以显著提高其在模加法任务上的准确性。</p><h5 id="例子-2置换组合任务s5">例子 2：置换组合任务（S5）</h5><p>在置换组合任务中，输入是一系列元素的置换，例如<code>[2, 3, 1, 5, 4]</code> 和<code>[1, 4, 3, 5, 2]</code>，目标是求这两个置换的组合。对于这样的任务，模型需要先理解每个置换的含义，然后逐步将它们组合起来，这样的操作必须按特定顺序进行。</p><p>带有 CoT 的 Transformer 可以通过以下步骤来解决：</p><ul><li>第一步：计算第一个置换 <code>[2, 3, 1, 5, 4]</code> 的结果。</li><li>第二步：将结果与第二个置换 <code>[1, 4, 3, 5, 2]</code>进行组合。</li><li>最后一步：得到最终组合的结果。</li></ul><p>通过这种逐步推理的方式，带有 CoT的模型可以比直接输出最终答案的模型表现更好。</p><h5 id="例子-3迭代平方任务">例子 3：迭代平方任务</h5><p>在迭代平方任务中，输入是一个初始值和一系列平方操作，例如<code>2 ^ 2 ^ 2 =</code>，目标是求出最终结果。带有 CoT 的 Transformer可以逐步计算：</p><ul><li>第一步：<code>2 ^ 2 = 4</code></li><li>第二步：<code>4 ^ 2 = 16</code></li></ul><p>这样逐步计算的方式帮助模型更好地理解每一步的推理过程，从而得出正确的最终答案。</p><h4 id="为什么思维链这么有效">为什么思维链这么有效？</h4><p>思维链的有效性可以从几个方面理解： 1.<strong>逐步推理</strong>：通过分解任务，模型可以逐步理解并解决复杂问题，而不是试图一次性给出最终答案。2.<strong>减少错误积累</strong>：在没有思维链的情况下，模型容易因为中间推理错误而导致最终答案错误。而通过CoT，模型可以一步步检查自己的推理过程，减少错误的积累。 3.<strong>增强推理的表达能力</strong>：CoT本质上是将模型的计算能力从简单的“并行计算”提升到复杂的“串行推理”，从而能够处理更多样的任务类型。</p><h4 id="总结与未来展望">总结与未来展望</h4><p>这篇论文为我们展示了如何通过引入思维链（Chain ofThought）来大幅度提升 Transformer的推理能力，特别是在处理那些需要逐步推理的复杂任务时。通过理论分析和实验证明，带有CoT 的 Transformer能够模拟更复杂的电路计算，并在多个串行问题上表现出了远超没有 CoT的模型的能力。</p><p>这种研究为未来的 Transformer设计和改进提供了新的思路。或许未来的人工智能系统可以更像人类一样，逐步思考、分解问题，从而解决更复杂的任务。这不仅能提升模型的准确性，还可能让模型在处理复杂任务时更加透明和可解释。</p><p>好的人工智能-&gt;zero shot的推理能力</p><p>数据，领域知识，</p><p>微调</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Inspiration-Zoom In</title>
    <link href="/2024/10/06/Paper/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/Inspiration-Zoom%20In/"/>
    <url>/2024/10/06/Paper/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/Inspiration-Zoom%20In/</url>
    
    <content type="html"><![CDATA[<p>Many important transition points in the history of science have beenmoments when science “zoomedin.”，所以作者团队也试图去更微观的角度探究神经网络。</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>可解释性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>信息抽取论文阅读</title>
    <link href="/2024/08/20/Paper/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2024/08/20/Paper/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h3 id="knowcoder">KnowCoder</h3><h5 id="论文试图解决什么问题">1. 论文试图解决什么问题？</h5><p>论文试图解决通用信息抽取(Universal Information Extraction,UIE)中的两个主要挑战：</p><ul><li>缺乏一种统一的、大语言模型(LLMs)易于理解的模式表示方法；</li><li>缺乏一个有效的学习框架，能够鼓励LLMs准确地遵循特定模式来抽取结构化知识。</li></ul><h5 id="这是否是一个新的问题">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题。通用信息抽取(UIE)是一个已存在的研究方向，但论文提出了新的方法来解决UIE中的关键挑战。</p><h5 id="这篇文章要验证一个什么科学假设">3.这篇文章要验证一个什么科学假设？</h5><p>这篇文章试图验证以下假设：</p><ul><li>使用代码风格的模式表示方法可以帮助LLMs更好地理解和遵循复杂的抽取模式。</li><li>两阶段学习框架（模式理解阶段和模式遵循阶段）可以提高LLMs在UIE任务上的性能。</li></ul><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究可以归类为：</p><ul><li>使用分类标签的UIE模型 (Lin et al., 2020a)</li><li>使用关键词的UIE模型 (Gui et al., 2023)</li><li>使用特定形式语言的UIE模型 (Lu et al., 2022)</li><li>直接在LLMs上进行指令微调的UIE方法 (Sainz et al., 2023; Wang et al.,2023b)</li></ul><p>论文没有明确指出该领域的重要研究人员。</p><h5 id="论文中提到的解决方案之关键是什么">5.论文中提到的解决方案之关键是什么？</h5><p>解决方案的关键包括：</p><ul><li>代码风格的模式表示方法：将不同的模式统一转换为Python类。</li><li>构建了一个包含超过30,000种知识类型的代码风格模式库。</li><li>两阶段学习框架：<ul><li>模式理解阶段：通过代码预训练提高LLM理解模式的能力。</li><li>模式遵循阶段：通过指令微调提高LLM遵循特定模式的能力。</li></ul></li></ul><h5 id="论文中的实验是如何设计的">6. 论文中的实验是如何设计的？</h5><p>实验设计包括：</p><ul><li>在约15亿自动构建的数据上进行代码预训练。</li><li>在约15亿自动标注的数据上进行指令微调。</li><li>在人工标注的IE数据集上进行微调。</li><li>在不同的IE任务（如命名实体识别、关系抽取等）上进行评估。</li><li>在零样本、低资源和有监督设置下进行性能比较。</li></ul><h5 id="用于定量评估的数据集是什么代码有没有开源">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>论文没有详细列出用于评估的具体数据集，但提到了使用了多个IE任务的数据集，包括命名实体识别(NER)和关系抽取任务。</p><p>关于代码开源，论文提到计划发布相关资源，但没有给出具体的代码链接。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>实验结果似乎支持了作者的科学假设：</p><ul><li>在少样本设置下，KnowCoder在NER任务上相比基线模型LLaMA2提高了49.8%的相对F1分数。</li><li>在零样本设置下，KnowCoder在NER任务上平均相对提升达12.5%。</li><li>在低资源设置下，KnowCoder在所有IE任务上平均相对提升达21.9%。</li><li>在有监督设置下，KnowCoder在关系抽取任务上提升了7.5%。</li></ul><p>这些结果表明，所提出的代码风格模式表示方法和两阶段学习框架确实提高了模型在UIE任务上的性能。</p><h5 id="这篇论文到底有什么贡献">9. 这篇论文到底有什么贡献？</h5><p>论文的主要贡献包括：</p><ul><li>提出了一种代码风格的模式表示方法，统一表示不同的UIE模式。</li><li>构建了一个大规模的代码风格模式库，包含超过30,000种知识类型。</li><li>提出了一个两阶段学习框架，包括模式理解和模式遵循阶段。</li><li>在各种IE任务和不同设置（零样本、低资源、有监督）下展示了优越的性能。</li></ul><h5 id="下一步呢有什么工作可以继续深入">10.下一步呢？有什么工作可以继续深入？</h5><p>可能的深入方向包括：</p><ul><li>进一步扩展模式库，包含更多领域和类型的知识。</li><li>探索如何更有效地利用代码风格模式进行复杂的推理任务。</li><li>研究如何将该方法应用于其他自然语言处理任务。</li><li>提高模型在处理非结构化文本时的鲁棒性。</li></ul><h5 id="要了解深入一个模型为什么好">11.要了解深入，一个模型为什么好？</h5><p>KnowCoder模型表现良好的原因可能包括：</p><ul><li>代码风格的模式表示方法使LLMs更容易理解和遵循复杂的抽取模式。</li><li>大规模模式库提供了丰富的知识类型，有助于模型理解各种概念。</li><li>两阶段学习框架分别增强了模型的模式理解和遵循能力。</li><li>大规模的自动构建数据和自动标注数据用于训练，提供了丰富的学习样本。</li></ul><h5 id="以前的模型为什么不好">12. 以前的模型为什么不好？</h5><p>以前模型的主要不足包括：</p><ul><li>忽略了概念分类法和概念间约束等信息。</li><li>分类标签或特定设计的形式语言难以被LLMs理解和遵循。</li><li>针对特定IE数据集设计，缺乏通用的模式库。</li><li>直接进行指令微调，难以应对大规模模式库中的众多概念。</li></ul><h5 id="哪个关键点对性能提升最大">13. 哪个关键点对性能提升最大？</h5><p>虽然论文没有明确指出哪个单一因素贡献最大，但根据实验结果，两个因素似乎特别重要：</p><ul><li>代码风格的模式表示方法：使LLMs更容易理解和遵循复杂模式。</li><li>两阶段学习框架：特别是代码预训练阶段，显著提高了模型的泛化能力。</li></ul><h5 id="编程怎么实现">14. 编程怎么实现？</h5><p>论文没有提供详细的编程实现步骤，但主要步骤可能包括：</p><ul><li>构建代码风格的模式库</li><li>生成训练数据（模式定义代码和实例代码）</li><li>进行代码预训练（模式理解阶段）</li><li>进行指令微调（模式遵循阶段）</li><li>在人工标注数据集上进行微调</li><li>在各种IE任务上进行评估</li></ul><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>论文提到计划发布相关资源，但没有提供具体的代码链接。因此，无法直接验证源代码是否与论文内容完全匹配。</p><h5 id="哪些数学运算是关键的">16. 哪些数学运算是关键的？</h5><p>论文没有强调特定的数学运算。KnowCoder主要基于大语言模型，可能涉及的关键数学运算包括注意力机制、矩阵乘法等，但论文没有详细讨论这些方面。</p><h5 id="整个全流程是怎么走的">17. 整个全流程是怎么走的？</h5><p>研究流程大致如下：</p><ul><li>提出代码风格的模式表示方法</li><li>构建大规模模式库</li><li>设计两阶段学习框架</li><li>生成大规模训练数据</li><li>进行代码预训练</li><li>进行指令微调</li><li>在人工标注数据集上进行微调</li><li>在各种IE任务和设置下进行实验评估</li><li>分析结果并得出结论</li></ul><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动和转换大致如下：</p><ul><li>模式库 →代码风格模式表示：将知识概念转换为Python类，便于LLM理解。</li><li>原始文本 + 模式 →训练样本：生成包含模式定义代码和实例代码的训练数据。</li><li>训练样本 → 模型输入：用于代码预训练和指令微调。</li><li>模型输出 → 结构化知识：模型生成的代码被解析为结构化的抽取结果。</li></ul><p>这些转换的意义是将非结构化文本和抽象模式转化为LLM可以学习和生成的代码形式，最终实现准确的信息抽取。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>具体实现思路：</p><ul><li>使用Python类表示知识概念</li><li>利用类继承、类注释、类型提示等特性表达复杂的模式信息</li><li>通过代码生成任务训练模型理解和遵循模式</li></ul><p>上层抽象意义：</p><ul><li>将复杂的知识抽取任务转化为代码生成任务</li><li>利用LLM在代码理解和生成方面的能力来提高信息抽取性能</li><li>通过统一的模式表示方法实现通用信息抽取</li></ul><p>论文没有明确说明作者的灵感来源，但可能来自对LLMs在代码任务上的强大能力的观察，以及对现有UIE方法局限性的认识。</p><h5 id="作者思考路线如何">20. 作者思考路线如何？</h5><p>作者的思考路线可能是：</p><ul><li>观察到现有UIE方法在模式表示和学习框架方面的局限性</li><li>意识到LLMs在代码理解和生成方面的强大能力</li><li>提出使用代码风格表示模式，将UIE任务转化为代码生成任务</li><li>设计两阶段学习框架，分别增强模型的模式理解和遵循能力</li><li>通过大规模实验验证方法的有效性</li></ul><hr /><h3 id="linkner">LinkNer</h3><p>##### 1. 论文试图解决什么问题？</p><p>这篇论文主要致力于通过引入LinkNer模型来改善命名实体识别（NER）在特定领域中的表现。作者识别到目前的NER模型在处理具有长距离依赖关系的实体时存在不足，因此提出了LinkNer，以解决这个问题。</p><p>##### 2. 这是否是一个新的问题？</p><p>该问题并非全新问题，命名实体识别是自然语言处理中的一个经典问题。但作者针对该领域特定挑战（如长距离依赖）提出的新模型，则展示了对该问题的一种创新性解决思路。</p><p>##### 3. 这篇文章要验证一个什么科学假设？</p><p>作者假设通过在NER模型中引入链接信息（如句法依赖关系或实体间的共现关系），可以提高模型在处理长距离依赖实体时的表现。这是文章的核心假设。</p><p>##### 4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</p><p>论文在引言中提到了一些相关研究，主要可以归类为以下几类：</p><ul><li>传统NER模型（如LSTM、CRF等）。</li><li>利用自注意力机制（如Transformer）来捕捉长距离依赖关系的模型。</li><li>在NER中引入额外的结构信息（如依存树）的研究。</li></ul><p>一些值得关注的研究员或研究小组可能包括BERT模型的开发者（如Google AILanguage团队），以及从事NER模型结构化信息整合的研究人员。</p><p>##### 5. 论文中提到的解决方案之关键是什么？</p><p>关键在于LinkNer模型的设计。LinkNer模型通过将NER问题转化为链接预测任务，并结合上下文信息与结构信息，从而提升对长距离依赖实体的识别能力。</p><p>##### 6. 论文中的实验是如何设计的？</p><p>实验设计包括在标准NER数据集上进行模型的性能评估，同时与现有的最先进模型进行比较。具体设计的实验涉及到不同类别实体的识别准确度、模型在不同数据集上的泛化能力等方面的测试。</p><p>##### 7. 用于定量评估的数据集是什么？代码有没有开源？</p><p>论文中使用的主要数据集包括CoNLL-2003等标准数据集。关于代码是否开源，目前在文档中的信息还未能确认是否有具体说明，需要进一步检查文档的相关部分。</p><p>##### 8. 论文中的实验及结果有没有很好地支持需要验证的科学假设？</p><p>实验结果显示LinkNer在长距离依赖的实体识别上确实优于传统模型，表明科学假设得到了良好验证。</p><p>##### 9. 这篇论文到底有什么贡献？</p><p>论文的主要贡献包括提出了LinkNer模型，并展示了其在NER任务中特别是在处理长距离依赖关系时的优越性。模型的创新性和实验验证结果都是重要的学术贡献。</p><p>##### 10. 下一步呢？有什么工作可以继续深入？</p><p>未来工作可以探讨LinkNer在更大规模或更加复杂的NER任务中的应用，进一步优化模型结构，或者将LinkNer模型与其他前沿技术（如图神经网络）结合以提升性能。</p><p>##### 11. 要了解深入，一个模型为什么好？</p><p>一个模型是否优秀通常取决于其在多个方面的表现，包括准确性、鲁棒性、泛化能力和计算效率。具体到LinkNer模型，它的优势在于能够有效处理长距离依赖关系的实体识别任务，模型通过引入链接信息，提升了识别的准确性。这在实验中通过与其他模型的对比得到了验证。</p><p>##### 12. 以前的模型为什么不好？</p><p>以前的NER模型在处理长距离依赖关系的实体时，往往表现不佳，主要因为传统模型通常依赖于局部上下文信息，而忽略了更广泛的句法或语义信息。这导致在识别需要全局信息的复杂实体时，模型的表现不足。此外，传统模型在面对跨句子的实体关系时也存在较大挑战。</p><p>##### 13. 哪个关键点对性能提升最大？</p><p>LinkNer模型的关键创新在于将NER问题转化为链接预测任务，并结合了上下文信息与实体之间的链接信息。这一设计使得模型在长距离依赖关系的实体识别上性能显著提升。因此，链接信息的整合可以被认为是对性能提升贡献最大的关键点。</p><p>##### 14. 编程怎么实现？</p><p>编程实现通常涉及到以下几个步骤：</p><ol type="1"><li>数据预处理：将文本数据转换为适合模型输入的格式，并提取句法依赖信息或实体共现信息。</li><li>模型架构：构建LinkNer模型，其中包括特征提取模块、自注意力机制、以及链接预测模块。</li><li>训练：使用标注好的NER数据集进行模型训练，并进行超参数调优。</li><li>评估：在测试集上进行模型性能评估，并与其他模型进行比较。</li><li>代码开源（如果有）：将实现代码整理，并发布在公共代码仓库（如GitHub）上，供社区使用。</li></ol><p>##### 15. 论文源代码和paper匹配度怎么样、都覆盖了吗？</p><p>由于文档中没有明确提到代码的具体情况，暂时无法确认源代码与论文的匹配度是否完整。通常，作者会提供与论文描述相符的代码，但在某些情况下可能会出现代码未完全覆盖论文内容的情况。如果有代码仓库链接，建议进一步检查以确认细节。</p><p>##### 16. 哪些数学运算是关键的？</p><p>论文中关键的数学运算包括：</p><ul><li>自注意力机制（self-attention）的计算，用于捕捉序列中不同位置的依赖关系。</li><li>链接预测的概率计算，通常涉及点积操作和softmax函数。</li><li>交叉熵损失函数（cross-entropy loss）用于模型的训练优化。</li></ul><p>##### 17. 整个全流程是怎么走的？</p><p>全流程大致如下：</p><ol type="1"><li>数据准备：收集和标注NER数据，并提取必要的句法或语义链接信息。</li><li>模型设计：构建LinkNer模型架构，定义输入特征、模型层次结构和损失函数。</li><li>模型训练：在训练集上进行迭代训练，调整模型参数。</li><li>模型评估：在验证集和测试集上评估模型性能。</li><li>结果分析：分析实验结果，验证科学假设，撰写论文。</li></ol><p>##### 18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</p><p>在LinkNer模型中，数据流动可以概括为：</p><ol type="1"><li>文本输入：原始句子被分词，并生成句法依赖或实体链接信息。</li><li>特征提取：通过嵌入层提取词向量，并利用自注意力机制提取全局上下文信息。</li><li>链接预测：根据提取的特征进行实体间的链接预测，并结合NER任务进行联合训练。</li><li>输出结果：预测每个词的实体类别标签。各个变换步骤的实际意义在于：提升模型对复杂句子结构的理解能力，使得最终的NER任务具有更高的准确性。</li></ol><p>##### 19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</p><p>作者的灵感可能来源于以下几个方面：</p><ul><li>当前NER模型在长距离依赖处理上的不足，促使他们思考如何引入更多结构化信息。</li><li>链接预测任务在其他领域（如图神经网络）中的成功应用，可能启发了他们将这一思想引入NER模型中。</li><li>自注意力机制在自然语言处理中的广泛应用，促使他们结合链接信息与全局上下文信息进行模型设计。</li></ul><p>##### 20. 作者思考路线如何？</p><p>作者的思考路线大致如下：</p><ol type="1"><li>识别现有NER模型在处理长距离依赖关系上的不足。</li><li>借鉴链接预测方法，设计一种能够捕捉实体间关系的NER模型。</li><li>将模型应用于标准数据集上，进行实验验证其有效性。</li><li>分析实验结果，确认新模型在目标任务上的优越性，并撰写论文总结。</li></ol><hr /><h3 id="medical-ner知识增强"><ahref="https://github.com/allenai/beacon">medical-ner知识增强</a></h3><h5 id="论文试图解决什么问题-1">1. 论文试图解决什么问题？</h5><p>论文试图解决的问题是提高大型语言模型（LLMs）在生物医学文本命名实体识别（NER）任务中的表现。尽管LLMs在零样本和少样本学习上表现出色，但在处理生物医学文本时，由于专业术语和领域知识的复杂性，其表现不佳。</p><h5 id="这是否是一个新的问题-1">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题。之前的研究表明，LLMs在生物医学文本的NER任务上表现不佳，且GPT-3使用上下文学习的效果甚至不如经过微调的小型模型。</p><h5 id="这篇文章要验证一个什么科学假设-1">3.这篇文章要验证一个什么科学假设？</h5><p>这篇文章要验证的科学假设是通过引入外部知识（特别是生物医学概念的定义）来增强LLMs的推理能力，从而提高其在生物医学NER任务中的性能。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-1">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究可以归类为：</p><ul><li>使用LLMs进行信息提取的研究。</li><li>LLMs的上下文学习（ICL）研究。</li><li>LLMs的迭代提示研究。</li><li>LLMs的知识增强研究。</li></ul><p>值得关注的研究员可能包括在LLMs和生物医学信息提取领域有显著贡献的研究者，如那些在顶级会议和期刊上发表相关研究论文的作者。</p><h5 id="论文中提到的解决方案之关键是什么-1">5.论文中提到的解决方案之关键是什么？</h5><p>论文中提到的解决方案的关键是通过在推理时识别和提供相关生物医学概念的定义，以及探索不同的提示策略（单轮和迭代提示）来增强LLMs的性能。</p><h5 id="论文中的实验是如何设计的-1">6. 论文中的实验是如何设计的？</h5><p>实验设计包括：</p><ul><li>构建包含6个NER数据集的评估集。</li><li>在零样本和少样本设置下对多个SOTA LLMs进行基准测试。</li><li>探索不同的提示策略，如使用定义/解释和生成结构化格式。</li><li>提出在推理时识别和提供相关生物医学概念的定义。</li></ul><h5 id="用于定量评估的数据集是什么代码有没有开源-1">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>用于定量评估的数据集包括CHEM、CDR、NCBI、MEDM、PICO和CHIA。关于代码是否开源，文中没有提及，因此需要查看论文附录或相关代码仓库以确认。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-1">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>是的，实验结果支持了科学假设。提示策略使LLMs在少样本设置下超过了经过微调的小型语言模型，定义增强显著提高了LLMs的性能，特别是在零样本设置中。</p><h5 id="这篇论文到底有什么贡献-1">9. 这篇论文到底有什么贡献？</h5><p>这篇论文的贡献包括：</p><ul><li>首次深入研究了这些方法在生物医学NER中的应用。</li><li>提出了改进LLMs在生物医学NER任务表现的新方法。</li><li>引发了关于定义知识在改善LLM性能方面的价值的有趣问题。</li></ul><h5 id="下一步呢有什么工作可以继续深入-1">10.下一步呢？有什么工作可以继续深入？</h5><p>下一步可以继续深入的工作包括：</p><ul><li>探索该方法在其他领域的潜在应用。</li><li>研究如何解决生成模型在信息提取任务中的评估问题。</li></ul><h5 id="要了解深入一个模型为什么好-1">11.要了解深入，一个模型为什么好？</h5><p>一个模型之所以好，是因为它能够有效地利用外部知识（如生物医学概念的定义）来增强其推理能力，从而在特定任务（如生物医学NER）中表现出色。</p><h5 id="以前的模型为什么不好-1">12. 以前的模型为什么不好？</h5><p>以前的模型不好是因为它们缺乏足够的领域专业知识，特别是在处理生物医学文本时，由于专业术语和领域知识的复杂性，其表现不佳。</p><h5 id="哪个关键点对性能提升最大-1">13. 哪个关键点对性能提升最大？</h5><p>关键点对性能提升最大的是提供相关生物医学概念的定义，特别是在零样本设置中使用迭代提示策略。</p><h5 id="编程怎么实现-1">14. 编程怎么实现？</h5><p>编程实现的具体细节需要查看论文附录或相关代码仓库，但一般步骤可能包括：</p><ul><li>构建生物医学概念定义知识库。</li><li>使用实体链接器将文本中的概念映射到知识库。</li><li>实现两步推理过程，包括常规实体提取和使用增加了概念定义的提示要求模型修正初始提取结果。</li></ul><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-1">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>文中没有提及源代码和论文的匹配度，因此需要查看论文附录或相关代码仓库以确认。</p><h5 id="哪些数学运算是关键的-1">16. 哪些数学运算是关键的？</h5><p>关键的数学运算可能包括实体链接（如使用SciSpaCy包）和模型评估（如使用实体级F1分数）。</p><h5 id="整个全流程是怎么走的-1">17. 整个全流程是怎么走的？</h5><p>整个全流程包括：</p><ul><li>构建评估集。</li><li>进行基准测试。</li><li>提出知识增强方法。</li><li>进行实验和评估。</li></ul><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-1">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动和变换包括：</p><ul><li>从文本中提取实体。</li><li>将提取的实体映射到知识库。</li><li>使用增加了概念定义的提示要求模型修正初始提取结果。</li></ul><p>各个变换的实际意义在于增强模型的推理能力，使其能够更好地理解和识别生物医学实体。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-1">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者的灵感可能来自于先前研究中关于知识增强和迭代提示的研究，以及在生物医学领域中LLMs表现不佳的观察。</p><h5 id="作者思考路线如何-1">20. 作者思考路线如何？</h5><p>作者的思考路线可能包括：</p><ul><li>观察到LLMs在生物医学NER任务中的局限性。</li><li>提出通过引入外部知识来增强LLMs的性能。</li><li>设计实验来验证这一假设。</li><li>分析实验结果并提出进一步的研究方向。</li></ul><h4 id="研究背景">研究背景</h4><ul><li>问题背景：<ul><li>尽管LLMs在零样本和少样本学习上表现出色，但在生物医学文本的NER任务上表现不佳。</li><li>之前的研究表明，GPT-3使用上下文学习的效果甚至不如smallerfine-tuned模型。</li></ul></li><li>挑战：<ul><li>生物医学文本使用专业术语，需要领域专业知识。</li><li>标注数据昂贵、耗时且难以获取，导致标记数据有限。</li></ul></li><li>研究动机：<ul><li>LLMs在一般信息提取任务上显示出改进潜力。</li><li>作者旨在通过新的知识增强方法提高LLMs在生物医学领域的表现。</li></ul></li></ul><h4 id="具体例子">具体例子</h4><p>假设我们有一个生物医学文本片段：</p><blockquote><p>"BRCA1 is a gene that is associated with an increased risk ofdeveloping breast cancer."</p></blockquote><p>在这个文本中，"BRCA1"是一个生物医学实体，代表一个基因。传统的LLMs可能无法准确识别 "BRCA1"作为一个基因实体，尤其是在零样本或少样本学习设置中。</p><h5 id="论文的解决方案">论文的解决方案</h5><p>论文提出了一种方法，通过在推理时提供相关生物医学概念的定义来增强LLMs的性能。具体步骤如下：</p><ol type="1"><li><p><strong>识别相关概念</strong>：首先，使用实体链接器（如SciSpaCy包）识别文本中的生物医学概念，例如"BRCA1"。</p></li><li><p><strong>提供概念定义</strong>：从生物医学知识库（如UMLS）中提取"BRCA1" 的定义，例如：</p><blockquote><p>"BRCA1: A gene located on chromosome 17 that is involved in therepair of DNA double-strand breaks and is associated with an increasedrisk of breast and ovarian cancer."</p></blockquote></li><li><p><strong>增强提示</strong>：将这个定义添加到LLMs的提示中，形成一个新的提示：</p><blockquote><p>"BRCA1 is a gene that is associated with an increased risk ofdeveloping breast cancer. BRCA1: A gene located on chromosome 17 that isinvolved in the repair of DNA double-strand breaks and is associatedwith an increased risk of breast and ovarian cancer."</p></blockquote></li><li><p><strong>模型推理</strong>：使用增强后的提示，LLMs可以更好地理解"BRCA1" 是一个基因实体，并准确地识别和分类它。</p></li></ol><h5 id="实验结果">实验结果</h5><p>论文中的实验结果表明，通过这种定义增强的方法，LLMs在生物医学NER任务中的性能显著提高。例如，GPT-4的性能平均提高了15%。这表明，提供相关概念的定义确实有助于LLMs更好地理解和识别生物医学实体。</p><h5 id="结论">结论</h5><p>这个例子展示了论文的核心思想：通过引入外部知识（特别是生物医学概念的定义）来增强LLMs在生物医学NER任务中的表现。这种方法不仅提高了模型的准确性，还为处理专业领域文本提供了一种有效的策略。</p><table><thead><tr><th>实验设置</th><th>描述</th></tr></thead><tbody><tr><td>a. 零样本学习</td><td>- 输入格式：<br>      (i)Text：标准提示，简要描述任务和有效目标实体类型<br>      (ii) SchemaDef：增加了详细的目标实体类型描述<br> - 输出格式：<br>      (i) JSON<br>     (ii) 代码片段<br> - 评估了四种输入/输出格式组合（除GPT-4外）</td></tr><tr><td>b. 少样本学习</td><td>- 使用零样本设置中表现最佳的输入/输出格式组合<br> -实例选择：随机选择<br> - 实例顺序：每个测试实例随机打乱<br> - 评估k ={1, 3, 5}的情况，报告三个种子的平均性能</td></tr><tr><td>c. 微调实验</td><td>- 使用Flan-T5 XL模型<br> - 在每个数据集上进行微调<br> -使用LoRA（参数高效微调方法）</td></tr></tbody></table><table><thead><tr><th>主要结果</th><th>描述</th></tr></thead><tbody><tr><td>a. 零样本学习</td><td>- Schema Def输入格式在所有模型和数据集上表现较差<br> -JSON输出格式在大多数数据集上表现更好，但PICO和CHIA例外<br> -这些发现在所有模型中保持一致</td></tr><tr><td>b. 少样本学习</td><td>- 性能随样本数量增加而提高<br> -指令微调的LLMs在少样本学习中显著优于在相同5个实例上微调的小型语言模型</td></tr><tr><td>c. 模型比较</td><td>- GPT-3.5、Claude 2和Llama 2在不同数据集上表现各有优劣<br> -在某些数据集上，开源模型Llama 2的性能与闭源API模型相当</td></tr></tbody></table><table><thead><tr><th>具体数据</th><th>描述</th></tr></thead><tbody><tr><td>- 表2</td><td>展示了零样本学习的结果，包括不同输入/输出格式组合的性能</td></tr><tr><td>- 表3</td><td>展示了少样本学习的结果，包括不同样本数量(k = 1, 3, 5)下的性能<br> -结果以F1分数表示，并包括标准差</td></tr></tbody></table><p>知识增强方法：</p><ul><li>在推理过程中，识别并提供相关生物医学概念的定义。</li><li>探索两种跟进提示策略：单轮提示和迭代提示。</li></ul><p>方法概述：</p><ul><li>构建生物医学概念定义知识库。</li><li>利用现成的实体链接器将文本中的概念映射到知识库。</li><li>实施两步推理过程：<ol type="a"><li>首先进行常规实体提取。</li><li>随后使用包含概念定义的提示，要求模型修正初始提取结果。</li></ol></li></ul><p>概念定义来源：</p><ul><li>采用统一医学语言系统(UMLS)。</li><li>通过人工筛选，保留细粒度的语义类型。</li><li>使用SciSpaCy包进行实体链接。</li></ul><p>零样本定义增强：</p><ul><li>单轮策略(ZS+Def)：一次性提供所有定义，要求模型修正所有提取的实体。</li><li>迭代提示策略(IP+Def)：每次提供一个概念的定义，逐一修正提取的实体。</li></ul><p>少样本定义增强：</p><ul><li>在跟进提示中包含少样本示例及其相关概念定义。</li><li>仅测试单轮策略，因为迭代策略在这种情况下成本过高。</li></ul><p>实验结果：</p><ul><li>零样本设置：<ul><li>Llama 2和GPT-4在两种策略下都有显著提升。</li><li>Claude 2和GPT-3.5仅在迭代提示策略下受益。</li></ul></li><li>少样本设置：<ul><li>大多数情况下都有改善。</li><li>GPT-4配合迭代提示策略效果最佳。</li></ul></li><li>总体上，概念定义增强提示改善了生物医学NER的性能。</li></ul><p>额外分析：</p><ul><li>验证了实体链接器本身的性能较差，平均F1分数仅为1.05。</li><li>进行了消融实验，仅添加候选实体而不添加定义，结果表明这种方法不如提议的方法有效。</li></ul><p>关键发现：</p><ul><li>提供概念定义可以帮助LLMs更好地理解和识别生物医学实体。</li><li>迭代提示策略通常比单轮策略更有效。</li><li>GPT-4在此任务中表现最佳，特别是与迭代提示策略结合时。</li><li>改进不仅来自实体链接，而主要源于提供的概念定义。</li></ul><p>方法的创新点：</p><ul><li>将自我验证与上下文知识提供相结合。</li><li>在生物医学领域应用定义增强提示。</li><li>探索了不同的提示策略（单轮vs迭代）。</li></ul><hr /><h3 id="consistner"><ahref="https://ojs.aaai.org/index.php/AAAI/article/view/29892">ConsistNER</a></h3><h5 id="论文试图解决什么问题-2">1. 论文试图解决什么问题？</h5><p>论文试图解决低资源场景下的命名实体识别(NER)问题。具体来说,它旨在提高在训练数据有限的情况下NER模型的性能。</p><p><strong>本体一致性问题</strong>： 一些研究（如Ma等,2023和Gutiérrez等,2022）利用预训练语言模型（PLM）的CLS嵌入来选择语义上相似的训练示例作为演示。然而，这种方法可能导致检索的示例在实体类型上与目标句子不一致。以图1中的CLS方法为例，示例#1和#3虽然在语义上与目标句子相似，但它们包含的是人名（如Sally），而不是目标句子中需要识别的事件实体“NewYear”。这种缺乏本体一致性的示例不能为模型正确识别“NewYear”提供足够的帮助。</p><p><strong>上下文一致性问题</strong>： 另一种方法（如Wang等,2023a）建议基于实体相似性检索示例，但这无法保证演示示例与目标句子之间的上下文一致性。以图1中的实体方法为例，示例#2和#4中的“newyear”是日期实体，而目标句子中的“NewYear”是事件实体。这种差异可能会误导模型将目标句子中的“NewYear”识别为日期实体，而不是事件实体。</p><p><img src="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202408211457800.png" alt="image-20240821145745691" style="zoom:80%;" /></p><h5 id="这是否是一个新的问题-2">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题。低资源NER一直是研究热点,但本文提出了新的解决方案。</p><h5 id="这篇文章要验证一个什么科学假设-2">3.这篇文章要验证一个什么科学假设？</h5><p>本文的科学假设是:通过同时考虑本体一致性和上下文一致性来检索高相关的示例,可以显著提高低资源场景下NER的性能。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-2">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究可以归类为:</p><ol type="1"><li>元学习方法 (如Wu et al. 2020)</li><li>提示学习方法 (如Ma et al. 2022a)</li><li>上下文学习方法 (如Brown et al. 2020)</li></ol><p>值得关注的研究员包括Tom Mitchell(CMU)、PercyLiang(Stanford)等在少样本学习和NER领域有重要贡献的学者。</p><h5 id="论文中提到的解决方案之关键是什么-2">5.论文中提到的解决方案之关键是什么？</h5><p>关键在于ConsistNER的三阶段框架,特别是第二阶段的示例检索机制:</p><ol type="1"><li>使用本体分布(OD)表示来保持本体一致性</li><li>使用实体感知上下文(EAC)表示来保持上下文一致性</li></ol><h5 id="论文中的实验是如何设计的-2">6. 论文中的实验是如何设计的？</h5><p>实验设计包括:</p><ol type="1"><li>在4个benchmark数据集上评估(CoNLL2003, OntoNotes5.0, NCBI,BC5CDR)</li><li>比较不同查询形式(Vanilla Query vs. Generated NER)</li><li>比较不同示例检索技术(Random vs. CLS vs. ConsistNER)</li><li>进行消融实验验证各组件的有效性</li></ol><h5 id="用于定量评估的数据集是什么代码有没有开源-2">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>数据集:CoNLL2003, OntoNotes5.0, NCBI, BC5CDR 未开源。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-2">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>是的,实验结果很好地支持了假设。ConsistNER在所有数据集上都优于基线方法,特别是在低资源(1-shot和5-shot)场景下。消融实验也验证了本体和上下文一致性的重要性。</p><h5 id="这篇论文到底有什么贡献-2">9. 这篇论文到底有什么贡献？</h5><p>主要贡献:</p><ol type="1"><li>提出ConsistNER框架解决低资源NER问题</li><li>设计了同时考虑本体和上下文的示例检索机制</li><li>在多个数据集上验证了方法的有效性</li></ol><h5 id="下一步呢有什么工作可以继续深入-2">10.下一步呢？有什么工作可以继续深入？</h5><p>可能的下一步工作:</p><ol type="1"><li>将ConsistNER扩展到其他NLP任务</li><li>探索更高效的预识别方法</li><li>研究如何减少对大语言模型的依赖</li></ol><h5 id="要了解深入一个模型为什么好-2">11.要了解深入，一个模型为什么好？</h5><p>ConsistNER表现好的原因:</p><ol type="1"><li>利用大语言模型进行零样本预识别,提供初始实体信息</li><li>同时考虑本体和上下文一致性,检索更相关的示例</li><li>结合句子特定和数据集特定的示例,平衡局部和全局信息</li></ol><h5 id="以前的模型为什么不好-2">12. 以前的模型为什么不好？</h5><p>之前的模型存在以下问题:</p><ol type="1"><li>仅基于CLS嵌入进行示例检索,忽视了实体类型信息</li><li>仅基于实体相似度检索示例,忽视了上下文语义</li><li>没有充分利用大语言模型的零样本能力</li></ol><h5 id="哪个关键点对性能提升最大-2">13. 哪个关键点对性能提升最大？</h5><p>根据论文的消融实验,同时考虑本体和上下文一致性的示例检索机制对性能提升贡献最大。</p><h5 id="编程怎么实现-2">14. 编程怎么实现？</h5><p>实现ConsistNER的主要步骤:</p><ol type="1"><li>使用大语言模型(如GPT-3)进行零样本实体预识别</li><li>实现本体分布(OD)表示和实体感知上下文(EAC)表示</li><li>基于OD和EAC进行示例检索</li><li>将检索到的示例输入大语言模型进行最终预测</li></ol><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-2">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>论文中没有提供源代码信息,无法评估匹配度。</p><h5 id="哪些数学运算是关键的-2">16. 哪些数学运算是关键的？</h5><p>关键的数学运算包括:</p><ol type="1"><li>计算本体分布(OD)表示</li><li>计算实体感知上下文(EAC)表示</li><li>计算示例相似度</li></ol><h5 id="整个全流程是怎么走的-2">17. 整个全流程是怎么走的？</h5><p>ConsistNER的全流程:</p><ol type="1"><li>预识别:使用大语言模型零样本识别潜在实体</li><li>示例检索:<ol type="a"><li>计算目标句子的OD和EAC表示</li><li>基于OD过滤候选示例</li><li>基于EAC从候选中选择最相似的示例</li></ol></li><li>NER预测:将检索到的示例与目标句子一起输入大语言模型进行预测</li></ol><h6 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-2">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h6><p>数据流动:</p><ol type="1"><li>原始文本 → 预识别实体:提供初始实体信息</li><li>预识别实体 → OD表示:捕捉句子的实体类型分布</li><li>原始文本+预识别实体 → EAC表示:获取实体感知的上下文语义</li><li>OD+EAC → 相似示例:检索相关示例</li><li>目标句子+示例 → NER结果:生成最终预测</li></ol><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-2">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者的灵感可能来自:</p><ol type="1"><li>观察到现有方法忽视了本体和上下文一致性的重要性</li><li>借鉴了<strong>原型网络</strong>和<strong>词袋模型</strong>的思想</li><li>认识到大语言模型在零样本任务上的潜力</li></ol><h5 id="作者思考路线如何-2">20. 作者思考路线如何？</h5><p>作者的思考路线可能是:</p><ol type="1"><li>识别低资源NER的关键挑战:示例检索</li><li>分析现有方法的不足:忽视本体或上下文一致性</li><li>提出解决方案:同时考虑两种一致性的检索机制</li><li>设计框架:结合大语言模型的零样本能力和新的检索机制</li><li>实验验证:在多个数据集上与现有方法比较</li><li>分析和讨论:消融实验和理论边界分析</li></ol><h4 id="具体方法示例">具体方法示例</h4><p>假设我们有以下目标句子需要进行实体识别: "The patient was diagnosedwith pneumonia and prescribed amoxicillin."</p><p>ConsistNER的三个阶段如下:</p><ol type="1"><li>预识别阶段:</li></ol><p>使用大语言模型(如GPT-3)进行零样本识别。可能的输出:</p><ul><li>疾病: pneumonia</li><li>药物: amoxicillin</li></ul><ol type="1"><li>示例检索阶段:</li></ol><ol type="a"><li><p>计算本体分布(OD)表示:假设我们的本体类别包括{疾病,药物,症状}。根据预识别结果,这句话的OD可能是:OD = [0.5, 0.5, 0]</p></li><li><p>计算实体感知上下文(EAC)表示:使用双重自注意力机制,重点关注"pneumonia"和"amoxicillin"周围的上下文。</p></li><li><p>示例检索:</p></li></ol><ul><li>首先,使用OD过滤候选示例,选择包含相似实体类型分布的句子。</li><li>然后,使用EAC从候选中选择语义最相似的示例。</li></ul><p>假设检索到的示例是: "The doctor confirmed influenza and recommendedoseltamivir for treatment."</p><ol type="1"><li>NER预测阶段:</li></ol><p>将目标句子和检索到的示例一起输入大语言模型:</p><p>输入:</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">示例:</span><br><span class="hljs-section">句子: The doctor confirmed influenza and recommended oseltamivir for treatment.</span><br><span class="hljs-section">实体: [疾病: influenza, 药物: oseltamivir]</span><br><br><span class="hljs-section">目标:</span><br><span class="hljs-section">句子: The patient was diagnosed with pneumonia and prescribed amoxicillin.</span><br><span class="hljs-section">实体:</span><br></code></pre></td></tr></table></figure><p>大语言模型输出:</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs inform7">实体: <span class="hljs-comment">[疾病: pneumonia, 药物: amoxicillin]</span><br></code></pre></td></tr></table></figure><p>这个例子展示了ConsistNER如何:</p><ol type="1"><li>利用大语言模型进行初步实体识别</li><li>基于本体和上下文一致性检索相关示例</li><li>利用检索到的示例指导最终的NER预测</li></ol><hr /><h3 id="self-improving-nerzero-shot"><ahref="https://aclanthology.org/2024.naacl-short.49/">self-improving-ner(zero-shot)</a></h3><h5 id="论文试图解决什么问题-3">1. 论文试图解决什么问题？</h5><p>本论文试图解决零样本命名实体识别(NER)任务中如何提高大型语言模型(LLMs)性能的问题。具体来说，论文提出了一个无需训练的自我改进框架，利用未标注语料库来激发LLMs的自学习能力，从而提高零样本NER的性能。</p><h5 id="这是否是一个新的问题-3">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题。利用LLMs进行零样本NER已经有一些研究。但是，本文提出的无需训练的自我改进框架是一种新颖的方法来解决这个问题。</p><h5 id="这篇文章要验证一个什么科学假设-3">3.这篇文章要验证一个什么科学假设？</h5><p>本文要验证的科学假设是：通过利用未标注语料库来刺激LLMs的自学习能力，可以显著提高零样本NER的性能，而无需任何额外的训练或标注数据。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-3">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究可以大致分为以下几类：</p><ol type="1"><li>设计高级提示方法进行零样本或少样本NER (如Wei et al., 2023b; Wang etal., 2023)</li><li>训练特定于NER任务的LLMs (如Zhou et al., 2023; Sainz et al.,2023)</li><li>使用LLMs生成数据来训练小型专用模型 (如Zhang et al., 2023; Ma et al.,2023)</li></ol><p>值得关注的研究员可能包括来自OpenAI、Google、Microsoft等大型AI实验室的研究人员，以及在NLP和NER领域有突出贡献的学者。然而，论文中没有具体提到特定的研究员名字。</p><h5 id="论文中提到的解决方案之关键是什么-3">5.论文中提到的解决方案之关键是什么？</h5><p>论文提出的解决方案的关键是一个三步骤的自我改进框架：</p><ol type="1"><li>零样本自我标注：使用LLM对未标注语料库进行零样本标注，并通过自一致性方法为每个实体和样本生成置信度分数。</li><li>可靠标注选择：基于生成的置信度分数，选择可靠的标注样本。</li><li>使用自我标注的示例进行推理：为每个测试输入检索相关的示例，并通过上下文学习进行推理。</li></ol><h5 id="论文中的实验是如何设计的-3">6. 论文中的实验是如何设计的？</h5><p>实验设计包括以下几个方面：</p><ol type="1"><li>在四个NER基准数据集上评估提出的框架。</li><li>比较不同的标注选择策略的效果。</li><li>评估不同的示例检索策略的影响。</li><li>分析自我改进过程中的性能变化。</li><li>与其他零样本NER方法进行比较。</li></ol><h5 id="用于定量评估的数据集是什么代码有没有开源-3">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>论文使用了四个NER基准数据集进行定量评估，包括CoNLL-2003。具体的四个数据集名称在提供的摘要中没有详细列出。</p><p>关于代码开源，论文提到代码和数据已经公开发布，可以在GitHub上找到：https://github.com/Emma1066/Self-Improve-Zero-Shot-NER</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-3">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>根据提供的信息，实验结果显示该框架在所有四个基准数据集上都取得了显著的性能提升。这些结果支持了论文的科学假设，即利用未标注语料库来刺激LLMs的自学习能力可以提高零样本NER的性能。</p><h5 id="这篇论文到底有什么贡献-3">9. 这篇论文到底有什么贡献？</h5><p>本论文的主要贡献包括：</p><ol type="1"><li>提出了一个无需训练的自我改进框架，用于提高LLMs在零样本NER任务上的性能。</li><li>探索了各种策略来选择可靠的自我标注样本。</li><li>证明了利用未标注语料库可以显著提高零样本NER的性能。</li><li>提供了一种新的方法来利用LLMs的自学习能力，而无需额外的训练或标注数据。</li></ol><h5 id="下一步呢有什么工作可以继续深入-3">10.下一步呢？有什么工作可以继续深入？</h5><p>可能的下一步工作包括：</p><ol type="1"><li>探索更高级的可靠标注选择策略。</li><li>研究如何优化自我改进的迭代次数。</li><li>将该框架应用到其他NLP任务中，如关系抽取或事件抽取。</li><li>探究如何结合其他技术（如主动学习）来进一步提高性能。</li><li>分析该方法在不同规模和类型的LLMs上的表现。</li></ol><h5 id="要了解深入一个模型为什么好-3">11.要了解深入，一个模型为什么好？</h5><p>要深入了解模型为什么好，可以从以下几个方面分析：</p><ol type="1"><li>在不同类型的实体和场景下的表现。</li><li>自我改进过程中的行为和学习曲线。</li><li>模型在处理困难样本或边缘案例时的表现。</li><li>模型生成的自我标注的质量和一致性。</li><li>模型在不同领域或数据分布上的泛化能力。</li><li>与其他基线方法的详细对比分析。</li></ol><h4 id="以前的模型为什么不好-3">12. 以前的模型为什么不好？</h4><p>以前的模型在零样本NER任务上可能存在以下问题：</p><ol type="1"><li>缺乏利用未标注数据的能力。</li><li>过度依赖大量标注数据或预训练。</li><li>难以适应新的实体类型或领域。</li><li>缺乏自我改进和持续学习的机制。</li><li>在处理复杂或模糊实体时表现不佳。</li></ol><h5 id="哪个关键点对性能提升最大-3">13. 哪个关键点对性能提升最大？</h5><p>根据论文的描述，可靠标注选择策略可能是对性能提升贡献最大的关键点。这是因为它决定了用于学习的示例质量，直接影响了模型的自我改进效果。不同的选择策略可能导致显著的性能差异。</p><h5 id="编程怎么实现-3">14. 编程怎么实现？</h5><p>实现这个框架需要以下几个主要步骤：</p><ol type="1"><li>设计适当的提示来进行零样本NER。</li><li>实现自我一致性评分机制，为每个实体和样本生成置信度分数。</li><li>实现不同的标注选择策略，如基于实体级别或样本级别的阈值。</li><li>实现示例检索策略，如随机选择或基于相似度的检索。</li><li>实现上下文学习机制，将检索到的示例与测试输入结合进行推理。</li><li>设计迭代自我改进的流程，包括性能评估和停止条件。</li></ol><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-3">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>由于没有直接访问源代码的信息，无法确定源代码和论文的具体匹配度。然而，论文提到代码已经公开发布，这通常意味着主要算法和实验应该被实现。要确定完整的覆盖度，需要直接检查源代码库。</p><h5 id="哪些数学运算是关键的-3">16. 哪些数学运算是关键的？</h5><p>关键的数学运算包括：</p><ol type="1"><li>自我一致性评分的计算，可能涉及概率或统计方法。</li><li>实体级别和样本级别置信度分数的计算。</li><li>示例检索中的相似度计算，如余弦相似度。</li><li>可能涉及的阈值选择和排序算法。</li><li>性能指标的计算，如准确率、召回率和F1分数。</li></ol><h5 id="整个全流程是怎么走的-3">17. 整个全流程是怎么走的？</h5><p>整个流程大致如下：</p><ol type="1"><li>对未标注语料库进行零样本NER标注。</li><li>使用自我一致性方法生成置信度分数。</li><li>基于置信度分数选择可靠的标注样本。</li><li>为每个测试输入检索相关的示例。</li><li>使用检索到的示例通过上下文学习进行推理。</li><li>评估性能并可能重复步骤1-5进行迭代改进。</li></ol><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-3">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动和变换如下：</p><ol type="1"><li>未标注文本 →自我标注文本：通过LLM进行零样本标注，为实体识别提供初始预测。</li><li>自我标注文本 →置信度评分：通过自我一致性方法生成置信度，评估预测的可靠性。</li><li>置信度评分 →可靠标注集：选择高置信度样本，提炼出高质量的"伪标注"数据。</li><li>可靠标注集 →检索示例：为每个测试样本选择相关示例，提供上下文信息。</li><li>检索示例 + 测试输入 →最终预测：通过上下文学习进行推理，得到更准确的NER结果。</li></ol><p>每个变换都旨在提高数据质量或提供更多上下文信息，最终提升零样本NER的性能。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-3">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者的灵感可能来自以下几个方面：</p><ol type="1"><li>对LLMs强大的零样本能力的认识。</li><li>自监督学习和自我训练在其他领域的成功应用。</li><li>人类学习过程中的自我改进和迭代学习机制。</li><li>对现有零样本NER方法局限性的认识。</li><li>利用未标注数据潜力的探索。</li></ol><p>从上层抽象意义来看，这项工作展示了如何利用LLMs的自学习能力来改进特定任务的性能，而无需额外的标注数据或微调。这种方法可能为其他NLP任务提供了新的范式。</p><h5 id="作者思考路线如何-3">20. 作者思考路线如何？</h5><p>作者的思考路线可能如下：</p><ol type="1"><li>认识到零样本NER的潜力和局限性。</li><li>思考如何在无监督场景下利用LLMs的能力。</li><li>提出利用未标注语料库来刺激LLMs自学习的想法。</li><li>设计自我改进框架的三个关键步骤。</li><li>探索不同的标注选择和示例检索策略。</li><li>通过实验验证方法的有效性。</li><li>分析结果并思考未来的改进方向。</li></ol><h4 id="具体实现示例">具体实现示例</h4><p>假设我们正在处理一个新闻文本的命名实体识别任务，实体类型包括人名(PER)、组织(ORG)和地点(LOC)。</p><p><strong>零样本自我标注</strong></p><p>假设我们有一段未标注的新闻文本： "Apple CEO Tim Cook visited Beijinglast week to meet with government officials."</p><p>使用大型语言模型进行零样本NER，得到结果：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">Apple</span><span class="hljs-punctuation">:</span> <span class="hljs-string">ORG</span><br><span class="hljs-attribute">Tim Cook</span><span class="hljs-punctuation">:</span> <span class="hljs-string">PER</span><br><span class="hljs-attribute">Beijing</span><span class="hljs-punctuation">:</span> <span class="hljs-string">LOC</span><br></code></pre></td></tr></table></figure><p><strong>自我一致性评分</strong></p><p>多次运行得到置信度分数：</p><ul><li>Apple (ORG): 1.0</li><li>Tim Cook (PER): 0.8</li><li>Beijing (LOC): 1.0</li></ul><p><strong>可靠标注选择</strong></p><p>设置阈值0.7，选择所有实体作为可靠标注。</p><p><strong>示例检索</strong></p><p>现在我们有了一个可靠标注集，包含上面的句子。假设我们要处理一个新的测试句子："Microsoft's Satya Nadella announced new AI products in Seattle."</p><p>我们将使用基于相似度的检索方法：</p><ol type="a"><li>使用BERT模型生成句子嵌入：</li></ol><ul><li>对可靠标注集中的每个句子生成嵌入向量</li><li>对测试句子生成嵌入向量</li></ul><ol start="2" type="a"><li><p>计算余弦相似度：计算测试句子与可靠标注集中每个句子的余弦相似度</p></li><li><p>选择最相似的样本：假设我们要检索3个最相似的样本，我们会选择相似度最高的3个句子。在这个例子中，由于我们只有一个可靠标注的句子，所以它会被选中。</p></li></ol><p><strong>上下文学习推理</strong></p><p>将检索到的示例与新的测试句子结合，形成新的提示：</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">以下是一个已标注的例子：<br><span class="hljs-comment">&quot;Apple[ORG] CEO Tim Cook[PER] visited Beijing[LOC] last week to meet with government officials.&quot;</span><br><br>请使用相同的方法标注这个新句子：<br><span class="hljs-comment">&quot;Microsoft&#x27;s Satya Nadella announced new AI products in Seattle.&quot;</span><br><br>输出格式：<br>实体: 类型<br></code></pre></td></tr></table></figure><p>LLM可能会输出：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">Microsoft</span><span class="hljs-punctuation">:</span> <span class="hljs-string">ORG</span><br><span class="hljs-attribute">Satya Nadella</span><span class="hljs-punctuation">:</span> <span class="hljs-string">PER</span><br><span class="hljs-attribute">Seattle</span><span class="hljs-punctuation">:</span> <span class="hljs-string">LOC</span><br></code></pre></td></tr></table></figure><p><strong>迭代改进</strong></p><p>将新标注的句子添加到可靠标注集中（假设它们通过了置信度阈值）。随着时间推移，可靠标注集会逐渐扩大，包含更多样的实体和上下文。</p><p>在下一轮迭代中，当我们遇到一个新的测试句子时，例如： "Google's SundarPichai gave a keynote speech at the annual developer conference inMountain View."</p><p>我们会重复上述过程，但这次在示例检索阶段，我们有更多的样本可以选择。我们可能会选择包含类似实体类型（科技公司CEO和地点）的最相似的几个句子作为示例</p><hr /><h3 id="rag-uieknowcoder前置工作"><ahref="https://arxiv.org/abs/2311.02962">RAG-UIE(KnowCoder前置工作)</a></h3><h5 id="论文试图解决什么问题-4">1. 论文试图解决什么问题？</h5><p>论文试图解决信息抽取(IE)任务中的两个主要挑战:</p><ol type="1"><li>不同IE任务有不同的特定模式(schema),难以用统一的方式表示。</li><li>自然语言表达复杂多样,同样的结构化知识可以用多种方式表达。</li></ol><p>论文提出了Code4UIE框架,旨在为各种IE任务提供一个通用的解决方案。</p><h5 id="这是否是一个新的问题-4">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题。信息抽取一直是自然语言处理领域的重要任务,其中的挑战也一直存在。但是,随着大语言模型(LLM)的发展,用代码生成的方式来解决IE任务是一个相对较新的思路。</p><h5 id="这篇文章要验证一个什么科学假设-4">3.这篇文章要验证一个什么科学假设？</h5><p>这篇文章主要验证以下科学假设:</p><ol type="1"><li>使用Python类可以统一表示各种IE任务的特定模式。</li><li>将IE任务转化为代码生成任务,并利用LLM的能力,可以有效地解决IE任务中的模式多样性和表达复杂性问题。</li><li>基于检索的示例增强可以提高LLM在IE任务上的表现。</li></ol><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-4">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究主要可以归类为以下几类:</p><ol type="1"><li>传统的特定任务IE方法:<ul><li>Wang et al. (2021) 的ACE框架用于NER任务</li><li>Ye et al. (2022) 的PL-Marker用于NER和RE任务</li><li>Hsu et al. (2022) 的DEGREE用于EAE和EE任务</li></ul></li><li>通用IE框架:<ul><li>Lu et al. (2022a) 提出的UIE框架</li><li>Lou et al. (2023) 提出的USM框架</li><li>Wang et al. (2023a) 提出的InstructUIE框架</li></ul></li><li>基于LLM的IE方法:<ul><li>Li et al. (2023a) 评估了ChatGPT在IE任务上的能力</li><li>Dyer (2023) 探索了LLM在RE任务上的表现</li><li>Li et al. (2023b) 提出的CodeIE方法</li><li>Wang et al. (2023c) 提出的Code4Struct方法</li></ul></li></ol><p>值得关注的研究员包括上述论文的作者,特别是在通用IE框架和基于LLM的IE方法方面做出贡献的研究者。</p><h5 id="论文中提到的解决方案之关键是什么-4">5.论文中提到的解决方案之关键是什么？</h5><p>论文中提到的解决方案的关键包括:</p><ol type="1"><li>使用Python类来统一表示各种IE任务的特定模式。</li><li>将IE任务转化为代码生成任务。</li><li>利用LLM的强大能力来完成代码生成。</li><li>设计了检索增强的策略,通过检索相似示例来辅助LLM更好地理解任务。</li></ol><p>这些关键点共同构成了Code4UIE框架,使其能够有效地处理各种IE任务。</p><h5 id="论文中的实验是如何设计的-4">6. 论文中的实验是如何设计的？</h5><p>论文的实验设计包括以下几个方面:</p><ol type="1"><li>任务覆盖:实验涵盖了5种IE任务,包括命名实体识别(NER)、关系抽取(RE)、事件检测(ED)、事件论元抽取(EAE)和事件抽取(EE)。</li><li>数据集:使用了9个不同的数据集来评估模型在各种IE任务上的表现。</li><li>比较方法:将Code4UIE与其他基于LLM的IE方法进行了比较。</li><li>评估指标:使用了常见的IE评估指标,如精确率、召回率和F1分数。</li><li>消融实验:进行了消融研究,以验证框架中各个组件的有效性。</li></ol><p>具体实验细节在论文的实验部分有详细描述。</p><h5 id="用于定量评估的数据集是什么代码有没有开源-4">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>论文中使用了以下数据集进行定量评估:</p><ol type="1"><li>NER任务: CoNLL 2003, OntoNotes 5.0</li><li>RE任务: ACE 2005, SciERC</li><li>ED任务: ACE 2005</li><li>EAE任务: ACE 2005</li><li>EE任务: ACE 2005, CASIE, Cybersecurity</li></ol><p>关于代码开源,论文中没有明确提到代码是否开源。通常,如果代码已开源,作者会在论文中提供GitHub链接或其他代码仓库地址。由于没有看到这样的信息,可能代码尚未公开。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-4">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>根据论文中的实验结果,可以认为实验较好地支持了论文提出的科学假设:</p><ol type="1"><li>Python类能够统一表示各种IE任务的特定模式:实验涵盖了多种IE任务(NER,RE, ED, EAE,EE),并在所有任务上取得了良好的效果,证明了这种表示方法的有效性和通用性。</li><li>将IE任务转化为代码生成任务并利用LLM能有效解决IE问题:Code4UIE在所有测试的IE任务上都优于现有的基于LLM的方法,支持了这一假设。</li><li>基于检索的示例增强可以提高LLM在IE任务上的表现:消融实验结果显示,加入检索策略后模型性能有所提升,验证了这一假设。</li></ol><p>总的来说,实验结果较好地支持了论文的主要科学假设。</p><h5 id="这篇论文到底有什么贡献-4">9. 这篇论文到底有什么贡献？</h5><p>这篇论文的主要贡献包括:</p><ol type="1"><li>提出了一种基于模式的通用表示方法,可以统一定义各种IE任务的特定模式。这种方法使用Python类来表示实体、关系和事件,为不同的IE任务提供了一个统一的框架。</li><li>将IE任务转化为统一的代码生成任务,并提出了基于LLM的检索增强代码生成框架Code4UIE。这种方法利用了LLM在代码生成方面的强大能力,为IE任务提供了一个新的解决思路。</li><li>设计了统一的示例检索策略,包括基于句子嵌入的检索和基于匿名句子嵌入的检索。这些策略帮助LLM更好地理解复杂的文本表达,提高了模型的性能。</li><li>通过广泛的实验验证了所提出方法的有效性。在5种IE任务的9个数据集上的实验结果表明,Code4UIE在各种IE任务上都优于现有的基于LLM的方法。</li><li>为通用信息抽取领域提供了一个新的研究方向,即利用代码生成和LLM来解决IE任务。</li></ol><h5 id="下一步呢有什么工作可以继续深入-4">10.下一步呢？有什么工作可以继续深入？</h5><p>基于这篇论文的工作,以下几个方向可以继续深入研究:</p><ol type="1"><li>扩展到更多IE任务:探索Code4UIE在其他IE任务(如共指消解、情感分析等)上的应用。</li><li>优化检索策略:研究更先进的检索方法,如使用语义相似度或考虑上下文信息的检索策略。</li><li>提高模型效率:研究如何减少模型推理时间,使其更适合实际应用场景。</li><li>多语言支持:扩展框架以支持多语言IE任务。</li><li>结合领域知识:探索如何将领域特定知识整合到框架中,以提高特定领域IE任务的性能。</li><li>模型可解释性:研究如何提高基于代码生成的IE模型的可解释性。</li><li>处理长文本:改进模型以更好地处理长文档或多段落文本的IE任务。</li><li>跨任务学习:探索如何利用不同IE任务之间的关系来提高整体性能。</li></ol><h5 id="要了解深入一个模型为什么好-4">11.要了解深入，一个模型为什么好？</h5><p>Code4UIE模型的优势主要体现在以下几个方面:</p><ol type="1"><li>统一表示:使用Python类统一表示各种IE任务的模式,使得模型可以在一个统一的框架下处理不同类型的IE任务。</li><li>利用LLM能力:通过将IE任务转化为代码生成任务,充分利用了LLM在理解自然语言和生成代码方面的强大能力。</li><li>检索增强:使用示例检索策略,帮助模型更好地理解任务要求和处理复杂的文本表达。</li><li>灵活性:可以轻松适应新的IE任务,只需定义相应的Python类,无需重新训练整个模型。</li><li>少样本学习:通过检索相似示例,模型可以在少量样本的情况下也能取得较好的性能。</li><li>可扩展性:基于代码生成的方法使得模型可以生成复杂的嵌套结构,适用于各种复杂的IE任务。</li><li>自然语言理解:利用LLM的强大语言理解能力,可以更好地处理复杂的文本表达和上下文信息。</li></ol><h5 id="以前的模型为什么不好-4">12. 以前的模型为什么不好？</h5><p>以前的IE模型存在以下一些局限性:</p><ol type="1"><li>任务特定性:传统方法往往为每个IE任务设计特定的模型,缺乏通用性。</li><li>模式固定:很多模型只能处理预定义的固定模式,难以适应新的IE任务或模式。</li><li>需要大量标注数据:传统的监督学习方法通常需要大量标注数据才能取得好的效果。</li><li>表达理解有限:部分模型难以处理复杂的自然语言表达和上下文信息。</li><li>可扩展性差:难以处理嵌套或复杂的结构化信息。</li><li>跨任务迁移困难:为一个IE任务训练的模型难以直接应用到其他IE任务上。</li><li>少样本场景表现差:在低资源或少样本场景下,性能往往大幅下降。</li><li>灵活性不足:难以快速适应新的任务需求或领域特定的抽取要求。</li></ol><p>Code4UIE通过统一的代码生成框架和利用LLM的能力,在很大程度上解决了这些问题。</p><h5 id="哪个关键点对性能提升最大-4">13. 哪个关键点对性能提升最大？</h5><p>根据论文中的实验结果和分析,对Code4UIE性能提升贡献最大的关键点可能是:</p><ol type="1"><li>将IE任务转化为代码生成任务:这一关键点使得模型可以充分利用LLM在代码生成方面的强大能力。通过生成Python类的实例代码,模型可以更精确地表示复杂的结构化信息,从而提高了IE任务的性能。</li><li>检索增强策略:论文中提到的示例检索策略,特别是基于匿名句子嵌入的检索方法,对模型性能的提升有显著贡献。这种策略帮助模型找到语义相似的示例,从而更好地理解任务要求和处理复杂的文本表达。</li></ol><p>这两个关键点的结合使得Code4UIE能够在各种IE任务上取得优秀的表现,特别是在处理复杂文本和适应新任务方面表现出色。然而,要确定哪个关键点贡献最大,可能需要更详细的消融实验来量化每个组件的影响。</p><h5 id="编程怎么实现-4">14. 编程怎么实现？</h5><p>根据论文描述,Code4UIE的实现可以分为以下几个主要步骤:</p><ol type="1"><li><p>定义模式类: 使用Python类定义实体、关系和事件的模式。例如:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Entity</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, <span class="hljs-symbol">name:</span> str</span>):<br>        <span class="hljs-variable language_">self</span>.name = name<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>(<span class="hljs-title class_">Entity</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, <span class="hljs-symbol">name:</span> str</span>):<br>        <span class="hljs-variable language_">super</span>().__init__(name=name)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Relation</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, <span class="hljs-symbol">name:</span> str</span>):<br>        <span class="hljs-variable language_">self</span>.name = name<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Kill</span>(<span class="hljs-title class_">Relation</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, <span class="hljs-symbol">head:</span> <span class="hljs-title class_">Person</span> = <span class="hljs-string">&quot;&quot;</span>, <span class="hljs-symbol">tail:</span> <span class="hljs-title class_">Person</span> = <span class="hljs-string">&quot;&quot;</span></span>):<br>        <span class="hljs-variable language_">self</span>.head = head<br>        <span class="hljs-variable language_">self</span>.tail = tail<br></code></pre></td></tr></table></figure></li><li><p>构建提示: 创建包含模式定义代码和未完成代码的提示。例如:</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">prompt = f&quot;&quot;&quot;<br>&#123;schema_definition_code&#125;<br><br>&#123;in_context_examples&#125;<br><br>&#x27;&#x27;&#x27;<br>List all the Entity words in the following sentence as instances of corresponding subclasses of class Entity. If there do not exist any Entity words that belong to the Entity subclasses we defined, print &quot;None&quot;.<br>&quot;&#123;input_sentence&#125;&quot;<br>&#x27;&#x27;&#x27;<br>&quot;&quot;&quot;<br></code></pre></td></tr></table></figure></li><li><p>实现检索策略: 使用句子嵌入模型(如SBERT)实现示例检索:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> sentence_transformers import SentenceTransformer, util<br><br>model = SentenceTransformer(<span class="hljs-string">&#x27;all-MiniLM-L6-v2&#x27;</span>)<br><br>def retrieve_examples(input_sentence, example_pool, <span class="hljs-attribute">k</span>=3):<br>    input_embedding = model.encode(input_sentence, <span class="hljs-attribute">convert_to_tensor</span>=<span class="hljs-literal">True</span>)<br>    example_embeddings = model.encode(example_pool, <span class="hljs-attribute">convert_to_tensor</span>=<span class="hljs-literal">True</span>)<br>    <br>    cos_scores = util.cos_sim(input_embedding, example_embeddings)[0]<br>    top_results = torch.topk(cos_scores, <span class="hljs-attribute">k</span>=k)<br>    <br>    return [example_pool[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> top_results.indices]<br></code></pre></td></tr></table></figure></li><li><p>使用LLM生成代码: 调用LLM API(如OpenAI GPT)来生成代码:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import openai<br><br>def generate_code(prompt):<br>    response = openai.Completion.create(<br>        <span class="hljs-attribute">engine</span>=<span class="hljs-string">&quot;text-davinci-002&quot;</span>,<br>        <span class="hljs-attribute">prompt</span>=prompt,<br>        <span class="hljs-attribute">max_tokens</span>=500,<br>        <span class="hljs-attribute">n</span>=1,<br>        <span class="hljs-attribute">stop</span>=None,<br>        <span class="hljs-attribute">temperature</span>=0.5,<br>    )<br>    return response.choices[0].text.strip()<br></code></pre></td></tr></table></figure></li><li><p>解析生成的代码:使用Python的exec()函数执行生成的代码,并收集结果:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs css">def parse_generated_code(<span class="hljs-selector-tag">code</span>):<br>    local_vars = &#123;&#125;<br>    exec(<span class="hljs-selector-tag">code</span>, globals(), local_vars)<br>    return &#123;k: v for k, v in local_vars.<span class="hljs-built_in">items</span>() if <span class="hljs-built_in">isinstance</span>(v, (Entity, Relation, Event))&#125;<br></code></pre></td></tr></table></figure></li><li><p>主流程:</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs scss">def <span class="hljs-built_in">extract_information</span>(input_sentence, schema, example_pool):<br>    examples = <span class="hljs-built_in">retrieve_examples</span>(input_sentence, example_pool)<br>    prompt = <span class="hljs-built_in">construct_prompt</span>(schema, examples, input_sentence)<br>    generated_code = <span class="hljs-built_in">generate_code</span>(prompt)<br>    extracted_info = <span class="hljs-built_in">parse_generated_code</span>(generated_code)<br>    return extracted_info<br></code></pre></td></tr></table></figure></li></ol><p>这是一个基本的实现框架,实际应用中可能需要根据具体任务和需求进行调整和优化。</p><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-4">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>没有开源</p><h5 id="哪些数学运算是关键的-4">16. 哪些数学运算是关键的？</h5><p>在Code4UIE框架中,虽然没有复杂的数学公式,但仍有一些关键的数学运算和概念:</p><ol type="1"><li>向量表示和相似度计算:在检索相似示例时,使用了句子嵌入模型将句子转换为向量表示。关键的数学运算包括:<ul><li>向量嵌入: 将文本转换为高维向量空间中的点</li><li>余弦相似度: 用于计算句子向量之间的相似度 cosine_similarity(A, B) =(A · B) / (||A|| * ||B||)</li></ul></li><li>Top-k检索: 在检索最相似的k个示例时,需要进行排序和选择操作。这涉及到:<ul><li>排序算法</li><li>k个最大值的选择</li></ul></li><li>概率分布和采样: 在使用LLM生成代码时,可能涉及到:<ul><li>概率分布: 模型输出的token概率分布</li><li>温度参数调整: 影响输出的随机性</li><li>采样策略: 如何从概率分布中选择下一个token</li></ul></li><li>评估指标计算: 在实验评估中,使用了常见的IE评估指标,如:<ul><li>精确率 (Precision) = TP / (TP + FP)</li><li>召回率 (Recall) = TP / (TP + FN)</li><li>F1分数 = 2 * (Precision * Recall) / (Precision + Recall)</li></ul></li><li>统计分析: 在比较不同方法的性能时,可能涉及:<ul><li>平均值和标准差的计算</li><li>显著性检验(如t检验)</li></ul></li></ol><p>虽然这些数学运算相对基础,但它们在Code4UIE框架的不同组件中起着关键作用,特别是在示例检索和性能评估方面。</p><h5 id="整个全流程是怎么走的-4">17. 整个全流程是怎么走的？</h5><p>Code4UIE框架的整个流程可以概括为以下几个主要步骤:</p><ol type="1"><li>模式定义:<ul><li>使用Python类定义实体、关系和事件的模式</li><li>这些定义将用于后续的代码生成任务</li></ul></li><li>输入处理:<ul><li>接收待处理的输入文本</li><li>确定要执行的IE任务类型(如NER、RE、EE等)</li></ul></li><li>示例检索:<ul><li>使用句子嵌入模型将输入文本转换为向量</li><li>在预先准备的示例池中检索语义相似的示例</li><li>选择top-k个最相似的示例</li></ul></li><li>提示构造:<ul><li>组合模式定义代码</li><li>添加检索到的示例</li><li>加入针对当前任务的指令</li><li>加入输入文本</li><li>形成完整的提示</li></ul></li><li>LLM代码生成:<ul><li>将构造好的提示送入LLM(如GPT-3)</li><li>LLM生成Python代码,该代码实例化了相应的类来表示抽取的信息</li></ul></li><li>代码解析:<ul><li>解析LLM生成的Python代码</li><li>提取代码中实例化的类对象,这些对象代表了从输入文本中抽取的信息</li></ul></li><li>结果处理:<ul><li>将解析得到的对象转换为结构化的输出格式</li><li>可能需要进行一些后处理,如去重、合并等</li></ul></li><li>评估(如果是在实验环境中):<ul><li>将抽取结果与真实标注进行比较</li><li>计算评估指标,如精确率、召回率、F1分数等</li></ul></li><li>输出:<ul><li>返回最终的信息抽取结果</li><li>在实验环境中,还会输出评估指标</li></ul></li></ol><p>这个流程是端到端的,从输入原始文本到输出结构化信息,充分利用了LLM的能力和检索增强的策略来完成各种IE任务。整个过程是通用的,可以通过调整模式定义和任务指令来适应不同的IE任务。</p><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-4">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>在Code4UIE框架中,数据的流动和变换过程如下:</p><ol type="1"><li>输入文本 → 向量表示:<ul><li>变换: 使用句子嵌入模型将文本转换为高维向量</li><li>意义: 使文本可以在向量空间中进行相似度比较,为示例检索提供基础</li></ul></li><li>向量表示 → 相似示例:<ul><li>变换: 计算输入向量与示例池中向量的相似度,选择最相似的示例</li><li>意义: 找到语义相似的示例,为LLM提供任务相关的上下文信息</li></ul></li><li>模式定义 + 示例 + 输入文本 → 提示:<ul><li>变换: 将多个组件组合成一个结构化的提示</li><li>意义: 为LLM提供完整的任务描述和上下文,指导其生成正确的代码</li></ul></li><li>提示 → 生成的代码:<ul><li>变换: LLM将自然语言提示转换为Python代码</li><li>意义: 将信息抽取任务转化为代码生成任务,利用LLM的代码生成能力</li></ul></li><li>生成的代码 → 结构化信息:<ul><li>变换: 解析和执行生成的Python代码,实例化相应的类</li><li>意义: 将生成的代码转换回结构化的信息表示,完成信息抽取</li></ul></li><li>结构化信息 → 标准化输出:<ul><li>变换: 将类实例转换为标准的输出格式(如JSON)</li><li>意义: 使输出结果易于处理和使用</li></ul></li><li>输出 → 评估指标(在实验环境中):<ul><li>变换: 将输出与真实标注比较,计算评估指标</li><li>意义: 量化模型的性能,便于与其他方法比较</li></ul></li></ol><p>这些数据流动和变换的过程体现了Code4UIE框架的几个核心思想:</p><ol type="1"><li>利用向量表示和检索增强LLM的表现</li><li>将IE任务转化为代码生成任务</li><li>使用统一的Python类表示来处理各种IE任务</li><li>端到端的处理流程,从文本输入到结构化信息输出</li></ol><p>每一步的变换都有其特定的作用,共同构成了一个灵活、通用且高效的IE框架。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-4">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者的灵感可能来源于以下几个方面:</p><ol type="1"><li>代码即知识表示:<ul><li>具体思路: 使用Python类来表示IE任务中的实体、关系和事件</li><li>抽象意义:代码作为一种形式化语言,能够精确地描述结构化知识,这与IE任务的目标高度一致</li></ul></li><li>LLM的代码生成能力:<ul><li>具体思路: 利用LLM将自然语言转换为Python代码</li><li>抽象意义:将NLP任务转化为代码生成任务,充分利用LLM在语言理解和代码生成方面的双重优势</li></ul></li><li>检索增强生成:<ul><li>具体思路: 使用相似示例检索来增强LLM的性能</li><li>抽象意义:结合了检索和生成两种方法的优点,提高了模型的泛化能力和少样本学习能力</li></ul></li><li>统一框架的需求:<ul><li>具体思路: 设计一个可以处理多种IE任务的通用框架</li><li>抽象意义: 追求NLP任务的统一解决方案,减少任务特定模型的开发成本</li></ul></li><li>软件工程原则:<ul><li>具体思路: 使用面向对象编程和继承等概念来设计模式表示</li><li>抽象意义:将软件工程的最佳实践应用于NLP任务,提高代码的可读性和可扩展性</li></ul></li><li>人类编程过程的启发:<ul><li>具体思路: 模仿人类将自然语言需求转换为代码的过程</li><li>抽象意义: 将人类的认知过程映射到AI系统,实现更自然的人机交互</li></ul></li></ol><p>作者的灵感很可能来自于观察到LLM在代码生成方面的强大能力,以及对现有IE方法局限性的深入思考。他们可能意识到,将IE任务转化为代码生成任务可以同时解决模式表示和复杂文本理解的问题。</p><p>这种方法的上层抽象意义在于:</p><ol type="1"><li>提供了一种新的思考NLP任务的方式,即通过代码生成来解决复杂的语言理解问题</li><li>打破了传统IE方法中任务特定模型的界限,为通用NLP系统的发展提供了新的思路</li><li>展示了如何将不同领域的技术(如软件工程、信息检索、语言模型)融合,以解决复杂的AI问题</li></ol><p>总的来说,Code4UIE反映了一种将形式化语言(代码)与自然语言处理相结合的创新思路,为未来的NLP研究提供了新的视角和方向。</p><h5 id="作者思考路线如何-4">20. 作者思考路线如何？</h5><p>分析作者的思考路线,可能包括以下几个关键步骤:</p><ol type="1"><li>问题识别:作者可能首先观察到现有IE方法的局限性,特别是在处理多样化模式和复杂文本表达方面的挑战。</li><li>跨领域联想:意识到代码作为一种形式化语言的优势,以及LLM在代码生成方面的能力,作者可能开始思考如何将这些优势应用到IE任务中。</li><li>概念融合:将IE任务与代码生成任务联系起来,提出了使用Python类来表示IE模式的创新想法。</li><li>方法设计:基于这个核心想法,作者设计了完整的Code4UIE框架,包括模式定义、提示构造、示例检索等组件。</li><li>挑战应对:意识到直接使用LLM可能存在的局限性,作者引入了检索增强策略来提高模型性能。</li><li>通用性考虑:在设计过程中,作者可能不断思考如何使框架适用于多种IE任务,最终实现了一个统一的解决方案。</li></ol><hr /><h3 id="codeie"><ahref="https://virtual2023.aclweb.org/paper_P2649.html">CodeIE</a></h3><p>代码定义直接定义任务，算是KnowCoder的简化版本</p><h4 id="具体示例">具体示例</h4><p><strong>命名实体识别</strong>(NER)任务示例:</p><p>输入文本: "Steve became CEO of Apple in 1998."</p><p>传统NER输出: (person: Steve) (organization: Apple)</p><p>CODEIE方法将其转换为Python代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">named_entity_recognition</span>(<span class="hljs-params">input_text</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;extract named entities from the input_text.&quot;&quot;&quot;</span><br>    input_text = <span class="hljs-string">&quot;Steve became CEO of Apple in 1998.&quot;</span><br>    entity_list = []<br>    <span class="hljs-comment"># extracted named entities</span><br>    entity_list.append(&#123;<span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;Steve&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;person&quot;</span>&#125;)<br>    entity_list.append(&#123;<span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;Apple&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;organization&quot;</span>&#125;)<br></code></pre></td></tr></table></figure><p><strong>关系抽取</strong>(RE)任务示例:</p><p>输入文本: "Steve became CEO of Apple in 1998."</p><p>传统RE输出: (Steve, work for, Apple)</p><p>CODEIE方法将其转换为Python代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relation_extraction</span>(<span class="hljs-params">input_text</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;extract the relations of named entities from the input text.&quot;&quot;&quot;</span><br>    input_text = <span class="hljs-string">&quot;Steve became CEO of Apple in 1998.&quot;</span><br>    entity_relation_list = []<br>    <span class="hljs-comment"># extracted relations</span><br>    entity_relation_list.append(&#123;<br>        <span class="hljs-string">&quot;rel_type&quot;</span>: <span class="hljs-string">&quot;work for&quot;</span>, <br>        <span class="hljs-string">&quot;ent1_type&quot;</span>: <span class="hljs-string">&quot;person&quot;</span>, <span class="hljs-string">&quot;ent1_text&quot;</span>: <span class="hljs-string">&quot;Steve&quot;</span>, <br>        <span class="hljs-string">&quot;ent2_type&quot;</span>: <span class="hljs-string">&quot;organization&quot;</span>, <span class="hljs-string">&quot;ent2_text&quot;</span>: <span class="hljs-string">&quot;Apple&quot;</span><br>    &#125;)<br></code></pre></td></tr></table></figure><p><strong>少样本学习实现</strong>:</p><p>假设我们有一个3-shot学习场景,即有3个标注样本。CODEIE方法的实现步骤如下:</p><ol type="a"><li>将3个标注样本转换为代码形式,例如:</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs css"># Sample <span class="hljs-number">1</span><br>def named_entity_recognition(input_text):<br>    input_text = <span class="hljs-string">&quot;Bill Gates founded Microsoft.&quot;</span><br>    entity_list = []<br>    entity_list.<span class="hljs-built_in">append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Bill Gates&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;person&quot;</span>&#125;)<br>    entity_list<span class="hljs-selector-class">.append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Microsoft&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;organization&quot;</span>&#125;)<br><br># Sample <span class="hljs-number">2</span><br>def named_entity_recognition(input_text):<br>    input_text = <span class="hljs-string">&quot;Apple was founded in 1976.&quot;</span><br>    entity_list = []<br>    entity_list.<span class="hljs-built_in">append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Apple&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;organization&quot;</span>&#125;)<br><br># Sample <span class="hljs-number">3</span><br>def named_entity_recognition(input_text):<br>    input_text = <span class="hljs-string">&quot;Elon Musk is the CEO of Tesla.&quot;</span><br>    entity_list = []<br>    entity_list.<span class="hljs-built_in">append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Elon Musk&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;person&quot;</span>&#125;)<br>    entity_list<span class="hljs-selector-class">.append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Tesla&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;organization&quot;</span>&#125;)<br></code></pre></td></tr></table></figure><ol start="2" type="a"><li><p>将这些样本代码串联起来,形成上下文演示。</p></li><li><p>对于新的测试样本,将其转换为相同格式的代码提示:</p></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">def <span class="hljs-title">named_entity_recognition</span><span class="hljs-params">(input_text)</span>:</span><br><span class="hljs-function">    input_text =</span> <span class="hljs-string">&quot;Jeff Bezos started Amazon in 1994.&quot;</span><br>    entity_list = []<br>    <span class="hljs-meta"># extracted named entities</span><br></code></pre></td></tr></table></figure><ol start="4" type="a"><li><p>将上下文演示和新样本的代码提示合并,作为输入发送给Code-LLM(如Codex)。</p></li><li><p>Code-LLM生成补全的代码,即预测结果:</p></li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs css">entity_list<span class="hljs-selector-class">.append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Jeff Bezos&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;person&quot;</span>&#125;)<br>entity_list<span class="hljs-selector-class">.append</span>(&#123;&quot;<span class="hljs-selector-tag">text</span>&quot;: <span class="hljs-string">&quot;Amazon&quot;</span>, <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;organization&quot;</span>&#125;)<br></code></pre></td></tr></table></figure><ol start="6" type="a"><li>解析生成的代码,提取出最终的NER结果。</li></ol><p>这种方法的优势在于:</p><ol type="1"><li>利用了Code-LLMs在处理结构化数据方面的优势。</li><li>保持了输入和输出格式的一致性,减少了模型在预训练和推理阶段的不匹配。</li><li>通过代码结构,自然地表达了实体和关系的层次结构,有利于模型理解任务。</li></ol><hr /><h3id="retrieval-augmented-generation-based-relation-extraction">Retrieval-AugmentedGeneration-based Relation Extraction</h3><p>RAG用来检索和要抽取的关系最相关的例子作为上下文展示头和尾实体，所谓的zero-shot就是这个查询出来的例子只给头尾不给关系类型，对比的方法也只是直接查询</p><hr /><h3id="c-icl-contrastive-in-context-learning-for-information-extraction"><ahref="https://arxiv.org/abs/2402.11254">C-ICL: Contrastive In-contextLearning for Information Extraction</a></h3><h5 id="论文试图解决什么问题-5">1. 论文试图解决什么问题？</h5><p>论文试图解决少样本信息抽取任务中，传统方法仅使用正确样本作为示例的局限性，通过引入C-ICL方法，利用大语言模型的上下文学习能力，同时使用正确和错误的样本来提高模型的实体和关系抽取性能。</p><h5 id="这是否是一个新的问题-5">2. 这是否是一个新的问题？</h5><p>这个问题在信息抽取领域中是一个相对较新的问题。传统方法通常只使用正确样本，而忽视了错误样本可能包含的有价值信息。C-ICL方法的创新之处在于同时利用正确和错误的样本来构建上下文学习示例。</p><h5 id="这篇文章要验证一个什么科学假设-5">3.这篇文章要验证一个什么科学假设？</h5><p>文章要验证的科学假设是：通过同时使用正确和错误的样本构建上下文学习示例，可以让大语言模型不仅学习正确的抽取方式，还能理解和避免常见错误，从而提高模型的实体和关系抽取性能。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-5">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究包括传统的少样本信息抽取方法和基于大语言模型的上下文学习方法。</p><h5 id="论文中提到的解决方案之关键是什么-5">5.论文中提到的解决方案之关键是什么？</h5><p>解决方案的关键是C-ICL方法，它通过同时利用正确和错误的样本构建上下文学习示例，让大语言模型不仅学习正确的抽取方式，还能理解和避免常见错误。</p><p>还有就是样本的检索策略。</p><h5 id="论文中的实验是如何设计的-5">6. 论文中的实验是如何设计的？</h5><p>实验设计包括在多个命名实体识别(NER)和关系抽取(RE)基准数据集上进行测试，使用基于句子嵌入的检索策略和自一致性检索策略来选择上下文学习示例，并通过对比实验验证C-ICL方法的有效性。</p><h5 id="用于定量评估的数据集是什么代码有没有开源-5">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>用于定量评估的数据集包括CoNLL03(NER)和CoNLL04(RE)等基准数据集。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-5">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>是的，实验结果显示C-ICL方法在大多数数据集上建立了新的最先进结果，证明了通过引入对比学习的思想，充分利用正确和错误样本中的信息，可以提高模型的抽取性能和泛化能力。</p><h5 id="这篇论文到底有什么贡献-5">9. 这篇论文到底有什么贡献？</h5><p>这篇论文的贡献包括： -提出了C-ICL方法，通过同时使用正确和错误的样本来提高模型的实体和关系抽取性能。- 设计了基于句子嵌入的检索策略和自一致性检索策略来选择上下文学习示例。 -在多个基准数据集上验证了C-ICL方法的有效性，并建立了新的最先进结果。</p><h5 id="下一步呢有什么工作可以继续深入-5">10.下一步呢？有什么工作可以继续深入？</h5><p>下一步可以继续深入的工作包括： -探索更多类型的错误样本和检索策略，以进一步提高模型的性能。 -在更多不同类型的数据集上验证C-ICL方法的泛化能力。 -研究如何将C-ICL方法应用于其他自然语言处理任务，如文本分类、问答系统等。</p><h5 id="要了解深入一个模型为什么好-5">11.要了解深入，一个模型为什么好？</h5><p>一个模型之所以好，是因为它能够有效地解决特定问题，并且在实验中表现出优异的性能。C-ICL方法之所以好，是因为它通过对比学习，充分利用了正确和错误样本中的信息，使大语言模型能够更全面地理解信息抽取任务，从而提高了模型的抽取性能和泛化能力。</p><h5 id="以前的模型为什么不好-5">12. 以前的模型为什么不好？</h5><p>以前的模型之所以不好，是因为它们通常只使用正确样本作为示例，忽视了错误样本可能包含的有价值信息。这种局限性导致模型在面对复杂或模糊的文本时，难以准确抽取实体和关系。</p><h5 id="哪个关键点对性能提升最大-5">13. 哪个关键点对性能提升最大？</h5><p>对性能提升最大的关键点是同时使用正确和错误的样本构建上下文学习示例，让大语言模型不仅学习正确的抽取方式，还能理解和避免常见错误。</p><h5 id="编程怎么实现-5">14. 编程怎么实现？</h5><p>编程实现C-ICL方法包括以下步骤： -使用大语言模型生成已标注数据的标签，以选择难分的负样本。 -从训练数据中选择与测试数据语义相似的正样本。 -设计包含正确和错误样本的上下文学习示例。 -使用语义相似度感知的自一致性来对错误/负样本进行排序，选择最有价值的样本。</p><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-5">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><h5 id="哪些数学运算是关键的-5">16. 哪些数学运算是关键的？</h5><p>关键的数学运算包括： - 使用余弦相似度计算句子之间的语义相似度。 -应用自一致性方法，通过多次预测和投票机制获得高置信度的预测结果。 -计算F1分数来判断预测结果是否为难分负样本。</p><h5 id="整个全流程是怎么走的-5">17. 整个全流程是怎么走的？</h5><p>整个全流程包括： -使用大语言模型生成已标注数据的标签，以选择难分的负样本。 -从训练数据中选择与测试数据语义相似的正样本。 -设计包含正确和错误样本的上下文学习示例。 -使用语义相似度感知的自一致性来对错误/负样本进行排序，选择最有价值的样本。- 在多个基准数据集上进行测试，验证C-ICL方法的有效性。</p><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-5">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动和变换包括： -使用大语言模型生成已标注数据的标签，以选择难分的负样本。 -从训练数据中选择与测试数据语义相似的正样本。 -设计包含正确和错误样本的上下文学习示例。 -使用语义相似度感知的自一致性来对错误/负样本进行排序，选择最有价值的样本。各个变换的实际意义在于： -选择语义相似的正样本有助于模型更好地理解和处理测试数据。 -选择高质量的难分负样本有助于模型学习错误类型并改进预测。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-5">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者的灵感可能来自于对比学习的思想，即通过同时使用正确和错误的样本来提高模型的性能。这种思想在其他领域（如计算机视觉）中已有应用，作者将其引入到自然语言处理领域，特别是少样本信息抽取任务中。</p><h5 id="作者思考路线如何-5">20. 作者思考路线如何？</h5><p>作者的思考路线可能包括： - 意识到传统方法仅使用正确样本的局限性。 -探索如何利用错误样本中的有价值信息。 -设计C-ICL方法，通过对比学习，充分利用正确和错误样本中的信息。 -在多个基准数据集上验证C-ICL方法的有效性，并建立新的最先进结果。</p><h4 id="具体例子-1">具体例子</h4><h5 id="c-icl方法概述">C-ICL方法概述</h5><p>C-ICL方法利用大语言模型的上下文学习能力，通过以下步骤实现： -<strong>选择正确样本</strong>：使用基于句子嵌入的检索策略，选择与测试数据在语义上相似的正确样本。-<strong>选择错误样本</strong>：使用自一致性检索策略，选择高质量的难分负样本作为错误示例。-<strong>构建上下文学习示例</strong>：将选择的正确和错误样本组合成上下文学习示例，供模型学习。</p><h5 id="基于句子嵌入的检索策略">基于句子嵌入的检索策略</h5><p>假设我们有以下测试句子： <figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk"><span class="hljs-comment">&quot;Tim Cook is the CEO of Apple Inc., headquartered in Cupertino, California.&quot;</span><br></code></pre></td></tr></table></figure> 步骤如下： 1.<strong>计算句子嵌入</strong>：使用大语言模型（如CodeLLMs）计算测试句子的嵌入向量。 2.<strong>检索相似句子</strong>：从训练数据集中找到语义相似的句子，例如：<figure class="highlight mizar"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mizar">&quot;Satya Nadella serves <span class="hljs-keyword">as</span> the CEO <span class="hljs-keyword">of</span> Microsoft, based <span class="hljs-keyword">in</span> Redmond, Washington.&quot;<br>&quot;Jeff Bezos founded Amazon.com, which <span class="hljs-keyword">is</span> headquartered <span class="hljs-keyword">in</span> Seattle.&quot;<br>&quot;Mark Zuckerberg <span class="hljs-keyword">is</span> the CEO <span class="hljs-keyword">of</span> Facebook, <span class="hljs-keyword">now</span> known <span class="hljs-keyword">as</span> Meta Platforms.&quot;<br></code></pre></td></tr></table></figure> 3.<strong>计算相似度</strong>：使用余弦相似度计算这些句子与测试句子的相似度。4.<strong>选择示例</strong>：选择排名靠前的k个包含实体或关系的样本作为上下文学习示例。</p><h5 id="自一致性检索策略">自一致性检索策略</h5><p>对于错误/负面样本，假设我们有以下训练样本： <figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-string">&quot;Elon Musk, the founder of SpaceX and Tesla, recently acquired Twitter.&quot;</span><br></code></pre></td></tr></table></figure> 步骤如下：1. <strong>多次预测</strong>：使用大语言模型进行多次预测，例如5次：<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gcode">预测<span class="hljs-number">1</span>: <span class="hljs-comment">(Elon Musk, founder of, SpaceX)</span>, <span class="hljs-comment">(Elon Musk, founder of, Tesla)</span>, <span class="hljs-comment">(Elon Musk, acquired, Twitter)</span><br>预测<span class="hljs-number">2</span>: <span class="hljs-comment">(Elon Musk, founder of, SpaceX)</span>, <span class="hljs-comment">(Elon Musk, founder of, Tesla)</span><br>预测<span class="hljs-number">3</span>: <span class="hljs-comment">(Elon Musk, founder of, SpaceX)</span>, <span class="hljs-comment">(Elon Musk, founder of, Tesla)</span>, <span class="hljs-comment">(Elon Musk, acquired, Twitter)</span><br>预测<span class="hljs-number">4</span>: <span class="hljs-comment">(Elon Musk, founder of, SpaceX)</span>, <span class="hljs-comment">(Elon Musk, CEO of, Tesla)</span>, <span class="hljs-comment">(Elon Musk, acquired, Twitter)</span><br>预测<span class="hljs-number">5</span>: <span class="hljs-comment">(Elon Musk, founder of, SpaceX)</span>, <span class="hljs-comment">(Elon Musk, founder of, Tesla)</span>, <span class="hljs-comment">(Elon Musk, bought, Twitter)</span><br></code></pre></td></tr></table></figure> 2.<strong>投票机制</strong>：通过投票机制获得高置信度的预测结果：<figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-name">Elon</span> Musk<span class="hljs-punctuation">,</span> founder of<span class="hljs-punctuation">,</span> SpaceX)<span class="hljs-punctuation">,</span> (<span class="hljs-name">Elon</span> Musk<span class="hljs-punctuation">,</span> founder of<span class="hljs-punctuation">,</span> Tesla)<span class="hljs-punctuation">,</span> (<span class="hljs-name">Elon</span> Musk<span class="hljs-punctuation">,</span> acquired<span class="hljs-punctuation">,</span> Twitter)<br></code></pre></td></tr></table></figure> 3. <strong>计算F1分数</strong>：假设正确的标注是：<figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-name">Elon</span> Musk<span class="hljs-punctuation">,</span> founder of<span class="hljs-punctuation">,</span> SpaceX)<span class="hljs-punctuation">,</span> (<span class="hljs-name">Elon</span> Musk<span class="hljs-punctuation">,</span> CEO of<span class="hljs-punctuation">,</span> Tesla)<span class="hljs-punctuation">,</span> (<span class="hljs-name">Elon</span> Musk<span class="hljs-punctuation">,</span> acquired<span class="hljs-punctuation">,</span> Twitter)<br></code></pre></td></tr></table></figure>这个预测的F1分数会很高（比如0.89），但不是1.0，因为它错误地将ElonMusk标注为Tesla的创始人而不是CEO。 4.<strong>选择难分负样本</strong>：由于F1分数很高但不完全正确，这个样本被选为难分负样本，可以用作错误/负面示例。</p><h5 id="上下文学习示例集合">上下文学习示例集合</h5><p>最终的上下文学习示例集合可能如下： - <strong>正确示例</strong>：<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-string">&quot;Satya Nadella serves as the CEO of Microsoft, based in Redmond, Washington.&quot;</span><br>关系: <span class="hljs-comment">(Satya Nadella, CEO of, Microsoft)</span>, <span class="hljs-comment">(Microsoft, headquartered in, Redmond)</span><br><span class="hljs-string">&quot;Jeff Bezos founded Amazon.com, which is headquartered in Seattle.&quot;</span><br>关系: <span class="hljs-comment">(Jeff Bezos, founded, Amazon.com)</span>, <span class="hljs-comment">(Amazon.com, headquartered in, Seattle)</span><br></code></pre></td></tr></table></figure> - <strong>错误示例</strong>： <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-string">&quot;Elon Musk, the founder of SpaceX and Tesla, recently acquired Twitter.&quot;</span><br><span class="hljs-section">错误关系: (Elon Musk, founder of, SpaceX), (Elon Musk, founder of, Tesla), (Elon Musk, acquired, Twitter)</span><br><span class="hljs-section">正确关系: (Elon Musk, founder of, SpaceX), (Elon Musk, CEO of, Tesla), (Elon Musk, acquired, Twitter)</span><br><span class="hljs-section">错误说明: 将Elon Musk误标为Tesla的创始人,而不是CEO。</span><br></code></pre></td></tr></table></figure></p><h5 id="实验设计">实验设计</h5><ul><li><strong>数据集</strong>：使用CoNLL03(NER)和CoNLL04(RE)等基准数据集。</li><li><strong>评估指标</strong>：使用准确率、召回率和F1分数等指标。</li><li><strong>对比实验</strong>：对比完整的C-ICL方法与只使用正面样本的方法，验证C-ICL方法的有效性。</li></ul><hr /><h3 id="codekgc">CodeKGC</h3><ol type="1"><li><p><strong>论文试图解决什么问题？</strong>论文试图解决生成式知识图谱构建方法中，传统方法无法很好地捕捉结构化知识的问题。传统方法通常将自然语言扁平化为序列化文本或特定语言，而CodeKGC方法通过利用代码语言模型来生成知识图谱，能够更好地处理复杂的结构信息和重叠事实。</p></li><li><p><strong>这是否是一个新的问题？</strong>这是一个在知识图谱构建领域中已知的问题，但论文提出了一种新的解决方案——CodeKGC方法，该方法通过将自然语言重构为代码格式，利用代码语言模型的结构理解和推理能力，有效地改进了知识图谱构建的性能。</p></li><li><p><strong>这篇文章要验证一个什么科学假设？</strong>文章要验证的科学假设是：通过将自然语言重构为代码格式，并利用代码语言模型的结构理解和推理能力，可以有效地改进知识图谱构建的性能，特别是在处理复杂结构提取问题如重叠问题方面。</p></li><li><p><strong>有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</strong>相关研究包括现有的生成式知识图谱构建方法，这些方法通常将自然语言扁平化为序列化文本或特定语言。这些研究可以归类为知识图谱构建方法的改进和创新。在这一领域内，值得关注的研究员包括提出CodeKGC方法的研究者，以及在知识图谱构建领域有深入研究的其他学者。</p></li><li><p><strong>论文中提到的解决方案之关键是什么？</strong>论文中提到的解决方案之关键是将知识图谱构建任务转化为代码生成任务，利用代码语言模型的结构理解和推理能力，通过模式感知提示和基于理由的增强生成方法，有效地改进了知识图谱构建的性能。</p></li><li><p><strong>论文中的实验是如何设计的？</strong>论文中的实验设计包括在ADE、CONLL04和SciERC三个数据集上进行实验，比较CodeKGC方法在零样本和少样本设置下的性能，以及分析上下文样本数量、关键模块变化对性能的影响。</p></li><li><p><strong>用于定量评估的数据集是什么？代码有没有开源？</strong>用于定量评估的数据集是ADE、CONLL04和SciERC。关于代码是否开源，文中没有明确提及，但通常这类研究会在论文发表后开源代码以供复现和进一步研究。</p></li><li><p><strong>论文中的实验及结果有没有很好地支持需要验证的科学假设？</strong>论文中的实验及结果很好地支持了需要验证的科学假设。实验结果表明，CodeKGC方法在零样本和少样本设置下都优于基线方法，特别是在处理复杂结构提取问题如重叠问题方面表现出色。</p></li><li><p><strong>这篇论文到底有什么贡献？</strong>这篇论文的贡献包括提出了一种新的知识图谱构建方法——CodeKGC，该方法通过将自然语言重构为代码格式，利用代码语言模型的结构理解和推理能力，有效地改进了知识图谱构建的性能，特别是在处理复杂结构提取问题如重叠问题方面。</p></li><li><p><strong>下一步呢？有什么工作可以继续深入？</strong>下一步可以继续深入的工作包括进一步优化CodeKGC方法，探索其在更多领域和数据集上的应用，以及研究如何减少对大型预训练模型的依赖，提高方法的泛化能力。</p></li><li><p><strong>要了解深入，一个模型为什么好？</strong>一个模型之所以好，是因为它能够有效地处理复杂的结构信息和重叠事实，通过代码格式保留语法和结构特征，使代码语言模型能生成更准确的关系和实体，同时通过基于理由的生成方法，提高了模型的推理能力。</p></li><li><p><strong>以前的模型为什么不好？</strong>以前的模型不好是因为它们通常将自然语言扁平化为序列化文本或特定语言，无法很好地捕捉结构化知识，导致在处理复杂结构信息和重叠事实时表现不佳。</p></li><li><p><strong>哪个关键点对性能提升最大？</strong>对性能提升最大的关键点是模式感知提示和基于理由的增强生成方法，这些方法通过利用知识图谱内的语义结构和提供中间步骤来提高知识提取能力。</p></li><li><p><strong>编程怎么实现？</strong>编程实现涉及使用预定义的Python类（如Entity、Relation、Triple、Extract）来表示知识图谱的结构，利用Python的类继承机制来表示实体和关系的层次结构，并通过Triple实例列表来表示复杂的结构信息。</p></li><li><p><strong>论文源代码和paper匹配度怎么样、都覆盖了吗</strong>文中没有明确提及源代码和论文的匹配度，但通常这类研究会在论文发表后开源代码以供复现和进一步研究，确保源代码和论文内容的一致性。</p></li><li><p><strong>哪些数学运算是关键的？</strong>关键的数学运算可能包括概率模型的计算、推理步骤的分解和组合，以及在生成过程中对结构化信息的编码和解码。</p></li><li><p><strong>整个全流程是怎么走的？</strong>整个全流程包括将自然语言重构为代码格式，利用模式感知提示和基于理由的增强生成方法，通过预定义的Python类和类继承机制来表示知识图谱的结构，最终生成结构化的三元组表示。</p></li><li><p><strong>数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</strong>数据流动包括将自然语言输入转换为代码格式，通过模式感知提示和基于理由的生成方法进行结构化处理，最终生成结构化的三元组表示。各个变换的实际意义在于保留语法和结构特征，提高模型的推理能力，以及有效地处理复杂的结构信息和重叠事实。</p></li><li><p><strong>既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</strong>作者灵感可能来自于对现有知识图谱构建方法的局限性的认识，以及对代码语言模型在处理结构化信息方面优势的发现。通过将自然语言重构为代码格式，利用代码语言模型的结构理解和推理能力，提出了一种新的解决方案。</p></li><li><p><strong>作者思考路线如何？</strong>作者的思考路线可能包括识别现有方法的局限性，探索代码语言模型的优势，提出将知识图谱构建任务转化为代码生成任务的思路，并通过实验验证方法的有效性。整个思考路线体现了对问题本质的深刻理解和对解决方案的创新设计。</p></li></ol><h4 id="具体例子-2">具体例子</h4><h5 id="输入文本示例">输入文本示例:</h5><p>"Prenatal cytomegalovirus (CMV) infection associated with severebrain damage was detected in an infant whose mother had been treatedwith prednisolone and azathioprine for systemic lupus erythematosus(SLE)."</p><h5 id="模式感知提示构建">模式感知提示构建:</h5><h6 id="a-首先我们定义基本的python类结构">a)首先,我们定义基本的Python类结构:</h6><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs markdown">class Entity:<br><span class="hljs-code">    def __init__(self, name: str):</span><br><span class="hljs-code">        self.name = name</span><br><span class="hljs-code"></span><br>class Relation:<br><span class="hljs-code">    def __init__(self, name: str):</span><br><span class="hljs-code">        self.name = name</span><br><span class="hljs-code"></span><br>class Triple:<br><span class="hljs-code">    def __init__(self, head, relation, tail):</span><br><span class="hljs-code">        self.head = head</span><br><span class="hljs-code">        self.relation = relation</span><br><span class="hljs-code">        self.tail = tail</span><br><span class="hljs-code"></span><br>class Extract:<br><span class="hljs-code">    def __init__(self, triples):</span><br><span class="hljs-code">        self.triples = triples</span><br></code></pre></td></tr></table></figure><h6 id="b-然后我们为这个特定领域定义具体的实体和关系类">b)然后,我们为这个特定领域定义具体的实体和关系类:</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Disease</span>(<span class="hljs-title class_ inherited__">Entity</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Medication</span>(<span class="hljs-title class_ inherited__">Entity</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Symptom</span>(<span class="hljs-title class_ inherited__">Entity</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AssociatedWith</span>(<span class="hljs-title class_ inherited__">Relation</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TreatedWith</span>(<span class="hljs-title class_ inherited__">Relation</span>):<br>    <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><h5 id="基于理由的增强生成">基于理由的增强生成:</h5><h6 id="步骤1-识别关系">步骤1: 识别关系</h6><ul><li><code>AssociatedWith</code> (CMV感染与脑损伤)</li><li><code>TreatedWith</code> (母亲与药物治疗)</li></ul><h6 id="步骤2-提取实体">步骤2: 提取实体</h6><ul><li><code>Disease</code>: CMV, brain damage, SLE</li><li><code>Medication</code>: prednisolone, azathioprine</li><li><code>Symptom</code>: brain damage</li></ul><h6 id="步骤3-生成最终结果">步骤3: 生成最终结果</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">extract = Extract([<br>    Triple(Disease(<span class="hljs-string">&quot;CMV infection&quot;</span>), AssociatedWith(), Symptom(<span class="hljs-string">&quot;severe brain damage&quot;</span>)),<br>    Triple(Entity(<span class="hljs-string">&quot;mother&quot;</span>), TreatedWith(), Medication(<span class="hljs-string">&quot;prednisolone&quot;</span>)),<br>    Triple(Entity(<span class="hljs-string">&quot;mother&quot;</span>), TreatedWith(), Medication(<span class="hljs-string">&quot;azathioprine&quot;</span>)),<br>    Triple(Entity(<span class="hljs-string">&quot;mother&quot;</span>), AssociatedWith(), Disease(<span class="hljs-string">&quot;SLE&quot;</span>))<br>])<br></code></pre></td></tr></table></figure><h5 id="代码生成">代码生成:</h5><p>最终,CodeKGC会生成类似这样的Python代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">cmv = Disease(<span class="hljs-string">&quot;CMV infection&quot;</span>)<br>brain_damage = Symptom(<span class="hljs-string">&quot;severe brain damage&quot;</span>)<br>mother = Entity(<span class="hljs-string">&quot;mother&quot;</span>)<br>prednisolone = Medication(<span class="hljs-string">&quot;prednisolone&quot;</span>)<br>azathioprine = Medication(<span class="hljs-string">&quot;azathioprine&quot;</span>)<br>sle = Disease(<span class="hljs-string">&quot;SLE&quot;</span>)<br><br>triples = [<br>    Triple(cmv, AssociatedWith(), brain_damage),<br>    Triple(mother, TreatedWith(), prednisolone),<br>    Triple(mother, TreatedWith(), azathioprine),<br>    Triple(mother, AssociatedWith(), sle)<br>]<br><br>extract = Extract(triples)<br></code></pre></td></tr></table></figure><h5 id="优势展示">优势展示:</h5><p>CodeKGC能够正确处理重叠和长距离的三元组。例如,它可以同时识别"CMVinfection"与"braindamage"的关系,以及"mother"与多种药物的治疗关系,这在传统方法中可能会被忽略或错误处理。</p><hr /><h3id="consistency-guided-knowledge-retrieval-and-denoising-in-llms-for-zero-shot-document-level-relation-triplet-extraction"><ahref="https://github.com/QiSun123/GenRDK">Consistency Guided KnowledgeRetrieval and Denoising in LLMs for Zero-shot Document-level RelationTriplet Extraction</a></h3><h5 id="论文试图解决什么问题-6">1. 论文试图解决什么问题？</h5><p>论文试图解决零样本文档级关系三元组抽取（ZeroDocRTE）的问题，即从未见过的文档中抽取包含未见过关系类型的关系三元组。</p><h5 id="这是否是一个新的问题-6">2. 这是否是一个新的问题？</h5><p>是的，ZeroDocRTE是一个新的问题，它比句子级的零样本抽取更具挑战性。</p><h5 id="这篇文章要验证一个什么科学假设-6">3.这篇文章要验证一个什么科学假设？</h5><p>文章要验证通过使用链式检索提示和一致性引导的跨文档知识去噪策略，可以有效地从大型语言模型中生成高质量的合成数据，用于零样本文档级关系三元组抽取。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-6">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究包括句子级关系抽取、零样本学习、大语言模型在NLP中的应用等。这些研究可以归类为自然语言处理和机器学习领域。</p><h5 id="论文中提到的解决方案之关键是什么-6">5.论文中提到的解决方案之关键是什么？</h5><p>解决方案的关键是使用链式检索提示来引导大语言模型生成合成数据，并通过一致性引导的跨文档知识去噪策略来提高数据质量。</p><h5 id="论文中的实验是如何设计的-6">6. 论文中的实验是如何设计的？</h5><p>实验设计包括使用链式检索提示生成合成数据，训练预去噪模型，进行一致性引导的跨文档知识去噪，以及最终使用去噪后的数据训练关系三元组抽取器。</p><h5 id="用于定量评估的数据集是什么代码有没有开源-6">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>开源</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-6">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>实验结果显示，使用链式检索提示和一致性引导的去噪策略生成的数据在ZeroDocRTE和ZeroDocRE任务上都取得了显著的性能提升，支持了科学假设。</p><h5 id="这篇论文到底有什么贡献-6">9. 这篇论文到底有什么贡献？</h5><p>论文的贡献包括提出ZeroDocRTE这一新任务，设计链式检索提示方法，提出一致性引导的跨文档知识去噪策略，并在零样本文档级关系三元组抽取任务上取得显著性能提升。</p><h5 id="下一步呢有什么工作可以继续深入-6">10.下一步呢？有什么工作可以继续深入？</h5><p>下一步可以继续提高生成数据的多样性和可控性，以及探索更多有效的去噪策略。</p><h5 id="要了解深入一个模型为什么好-6">11.要了解深入，一个模型为什么好？</h5><p>一个模型之所以好，是因为它能够有效地处理复杂的语义上下文和篇章结构，生成高质量的合成数据，并通过去噪策略提高数据质量。</p><h5 id="以前的模型为什么不好-6">12. 以前的模型为什么不好？</h5><p>以前的模型可能在处理复杂的文档级关系抽取任务时性能不佳，尤其是在零样本场景下，缺乏有效的去噪策略。</p><h5 id="哪个关键点对性能提升最大-6">13. 哪个关键点对性能提升最大？</h5><p>链式检索提示和一致性引导的跨文档知识去噪策略对性能提升最大。</p><h5 id="编程怎么实现-6">14. 编程怎么实现？</h5><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-6">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><h5 id="哪些数学运算是关键的-6">16. 哪些数学运算是关键的？</h5><p>关键的数学运算可能包括一致性得分的计算和动态阈值的确定。</p><h5 id="整个全流程是怎么走的-6">17. 整个全流程是怎么走的？</h5><p>全流程包括生成合成数据、预去噪、一致性引导的去噪、最终训练关系三元组抽取器。</p><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-6">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动包括从生成合成数据到预去噪，再到一致性引导的去噪，最终用于训练模型。各个变换的实际意义在于提高数据质量和模型性能。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-6">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者灵感可能来自于大语言模型的生成能力和零样本学习的挑战，以及如何通过去噪策略提高数据质量。</p><h5 id="作者思考路线如何-6">20. 作者思考路线如何？</h5><p>作者的思考路线可能包括如何利用大语言模型生成合成数据，如何设计有效的去噪策略，以及如何将这些方法应用于零样本文档级关系三元组抽取任务。</p><h4 id="具体例子-3">具体例子</h4><h5 id="选择未见关系类型">1. 选择未见关系类型</h5><p>假设我们要处理一个未见过的关系类型“兄弟姐妹”（sibling）。</p><h5 id="链式检索提示chain-of-retrieval-prompt">2.链式检索提示（Chain-of-Retrieval Prompt）</h5><h6 id="a-选择相关关系">a) 选择相关关系</h6><p>我们引导ChatGPT从关系集 ( R )中选择与“兄弟姐妹”相关的几个关系，例如“父母”（parent）、“配偶”（spouse）等。</p><h6 id="b-生成虚构文档">b) 生成虚构文档</h6><p>基于选择的相关关系，我们引导ChatGPT生成一个包含这些关系的虚构文档。例如，生成的文档可能描述一个家族的关系，包括父母、配偶和兄弟姐妹的关系。</p><h6 id="c-提取实体集">c) 提取实体集</h6><p>从生成的文档中提取实体集合 ( E_k )，例如提取出人物名字（如John Smith,Emily Johnson等）。</p><h6 id="d-抽取关系三元组">d) 抽取关系三元组</h6><p>基于文档和实体集，从中提取所有类型的关系三元组。例如，提取出“JohnSmith 和 Emily Johnson 是兄弟姐妹”这样的三元组。</p><h6 id="e-推理解释">e) 推理解释</h6><p>为每个关系三元组生成一个合理的解释，并从文本中提取支持信息。例如，解释为什么JohnSmith和Emily Johnson是兄弟姐妹，并提供支持句子。</p><h6 id="f-生成结构化标签">f) 生成结构化标签</h6><p>将所有信息组织为结构化数据，例如： <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;head_entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;John Smith&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;relation_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sibling&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;tail_entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Emily Johnson&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;explanation&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;John Smith and Emily Johnson are siblings because they share the same parents.&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;support_sentence&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;John and Emily are the children of Mr. and Mrs. Smith.&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></p><h5 id="预去噪模型pre-denoising-model">3. 预去噪模型（Pre-denoisingModel）</h5><h6 id="a-模型微调">a) 模型微调</h6><p>使用已知关系的数据集 ( D_s )对LLaMA2-13B-Chat模型进行微调，使其适应已知关系的数据。</p><h6 id="b-生成伪标签">b) 生成伪标签</h6><p>使用预去噪模型对合成数据进行推理，从而生成伪标签。例如，对生成的文档进行推理，生成伪标签：<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;head_entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;John Smith&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;relation_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sibling&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;tail_entity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Emily Johnson&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pseudo_label&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></p><h5id="一致性引导的跨文档知识去噪consistency-guided-knowledge-denoising">4.一致性引导的跨文档知识去噪（Consistency-guided KnowledgeDenoising）</h5><p>假设我们有两个文档 ( D_1 ) 和 ( D_2)，它们都描述了同一个人物关系网络。我们需要计算关系三元组 ( (A, , B) )的一致性得分。</p><h5 id="文档-d_1-中的关系事实">文档 ( D_1 ) 中的关系事实：</h5><ul><li>( (A, , C) )</li><li>( (B, , C) )</li><li>( (A, , B) )</li></ul><h5 id="文档-d_2-中的关系事实">文档 ( D_2 ) 中的关系事实：</h5><ul><li>( (A, , C) )</li><li>( (B, , C) )</li><li>( (A, , B) )</li></ul><h6 id="计算一致性得分">2. 计算一致性得分</h6><p>一致性得分 ( s_{ijk} ) 的计算公式如下： [ s_{ijk} = F_s(i, j, k) +F_p(i, j, k) ] 其中，( F_s(i, j, k) ) 和 ( F_p(i, j, k) ) 分别表示在 (KG_s ) 和 ( KG_p ) 中关系三元组 ( (e_i, e_j, r_k) ) 的频率。</p><p><strong>计算 ( F_s(i, j, k) ) 和 ( F_p(i, j, k) )</strong></p><p>对于关系三元组 ( (A, , B) )： - 在 ( KG_s ) 中，( (A, , B) )出现了一次，所以 ( F_s(A, B, ) = 1 )。 - 在 ( KG_p ) 中，( (A, , B) )出现了一次，所以 ( F_p(A, B, ) = 1 )。</p><h6 id="计算一致性得分-1">3. 计算一致性得分</h6><p>根据公式，一致性得分 ( s_{ijk} ) 为： [ s_{A, B, } = F_s(A, B, ) +F_p(A, B, ) = 1 + 1 = 2 ]</p><h6 id="剪枝不可靠的三元组">4. 剪枝不可靠的三元组</h6><p>假设我们设定了一个动态阈值 ( <em>k )，对于关系类型 ()，我们设定的阈值 ( </em>{} = 1.5 )。</p><p>由于 ( s_{A, B, } = 2 ) 大于阈值 ( _{} = 1.5 )，因此关系三元组 ( (A,, B) ) 被认为是可靠的，不会被剪枝。</p><h6 id="重新标注合成数据">5. 重新标注合成数据</h6><p>使用去噪后的知识图谱重新标注合成数据，确保包含可靠的关系三元组。</p><h5 id="关系三元组抽取器relation-triplet-extractor">5.关系三元组抽取器（Relation Triplet Extractor）</h5><h6 id="a-训练关系三元组抽取器">a) 训练关系三元组抽取器</h6><p>使用去噪后的合成数据微调LLaMA2-13B-Chat模型，使其能够从文档中自动识别并提取关系三元组。</p><h6 id="b-抽取关系三元组">b) 抽取关系三元组</h6><p>最终，使用训练好的关系三元组抽取器从未见过的文档中抽取包含“兄弟姐妹”关系的三元组。</p><p>通过这个具体的例子，我们可以看到论文方法的全流程是如何从选择未见关系类型开始，通过链式检索提示生成合成数据，使用预去噪模型和一致性引导的去噪策略提高数据质量，最终训练关系三元组抽取器来完成任务的。</p><hr /><h3id="empirical-analysis-of-dialogue-relation-extraction-with-large-language-models">EmpiricalAnalysis of Dialogue Relation Extraction with Large Language Models</h3><h5 id="论文试图解决什么问题-7">1. 论文试图解决什么问题？</h5><p>论文试图解决对话关系抽取（DRE）任务中的挑战，特别是如何有效地从对话中提取两个论元之间的关系，尤其是在处理长距离和稀疏的多轮信息以及基于部分对话提取正确关系的问题。</p><h5 id="这是否是一个新的问题-7">2. 这是否是一个新的问题？</h5><p>这是一个全新的问题，但论文针对DRE任务中的一些特定挑战提出了新的解决方案和评估方法。</p><h5 id="这篇文章要验证一个什么科学假设-7">3.这篇文章要验证一个什么科学假设？</h5><p>文章要验证的科学假设是大型语言模型（LLMs）能够显著缓解现有DRE方法的两个主要问题，即捕捉长距离和稀疏多轮信息的困难，以及在从完整对话到部分对话设置时性能下降的问题。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-7">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究包括关系抽取（RE）的发展，包括句子级、文档级和对话级RE，以及现有的基于序列和基于图的DRE方法。</p><h5 id="论文中提到的解决方案之关键是什么-7">5.论文中提到的解决方案之关键是什么？</h5><p>解决方案的关键是利用大型语言模型（如ChatGPT和LLaMA）进行DRE，通过设计不同的提示格式和微调技术（如LoRA）来提高模型在DRE任务上的性能。</p><h5 id="论文中的实验是如何设计的-7">6. 论文中的实验是如何设计的？</h5><p>实验设计包括评估不同LLMs在DRE任务上的表现，使用标准设置和对话设置进行评估，以及在不同数据集上测试模型的泛化能力。</p><h5 id="用于定量评估的数据集是什么代码有没有开源-7">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>用于定量评估的数据集包括DialogRE、MELD和EmoryNLP等。关于代码是否开源，文章中没有明确提及，但通常这类研究在完成后会选择开源代码以促进进一步的研究和应用。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-7">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>是的，实验结果支持了科学假设，表明LLMs能够显著提升DRE的整体性能，有效解决了捕捉长距离和稀疏多轮信息的困难，并且在从完整对话到部分对话设置时性能下降幅度更小。</p><h5 id="这篇论文到底有什么贡献-7">9. 这篇论文到底有什么贡献？</h5><p>论文的贡献包括首次对LLMs在DRE任务上进行评估，提出使用基于生成的方法进行DRE，显著缓解了DRE的两个主要问题，并通过分析不同基于生成的方法的性能和复杂性，为未来DRE研究提供了有价值的见解。</p><h5 id="下一步呢有什么工作可以继续深入-7">10.下一步呢？有什么工作可以继续深入？</h5><p>下一步可以继续深入研究LLMs在DRE任务上的应用，探索更多有效的提示策略和微调技术，以及在更多不同类型的对话数据集上测试模型的性能和泛化能力。</p><h5 id="要了解深入一个模型为什么好-7">11.要了解深入，一个模型为什么好？</h5><p>一个模型之所以好，是因为它能够有效地捕捉和理解对话中的复杂关系，尤其是在处理长距离和稀疏的多轮信息时表现出优势，并且能够在不同设置下保持稳定的性能。</p><h5 id="以前的模型为什么不好-7">12. 以前的模型为什么不好？</h5><p>以前的模型可能不好是因为它们难以捕捉长距离和稀疏的多轮信息，以及在基于部分对话提取正确关系时性能较差。</p><h5 id="哪个关键点对性能提升最大-7">13. 哪个关键点对性能提升最大？</h5><p>关键点对性能提升最大的是使用大型语言模型和有效的提示策略及微调技术，这些方法能够显著提升模型在DRE任务上的表现。</p><h5 id="编程怎么实现-7">14. 编程怎么实现？</h5><p>编程实现涉及构建输入提示、选择基础模型、使用LoRA技术进行参数高效微调，以及通过训练和优化模型来最小化预测输出与真实关系标签之间的损失。</p><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-7">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>文章中没有提及源代码的具体情况，但通常论文的源代码应该与论文内容高度匹配，覆盖了论文中提到的所有实验和方法。</p><h5 id="哪些数学运算是关键的-7">16. 哪些数学运算是关键的？</h5><p>关键的数学运算包括损失函数的最小化（负对数似然）、参数高效微调中的秩分解矩阵计算等。</p><h5 id="整个全流程是怎么走的-7">17. 整个全流程是怎么走的？</h5><p>全流程包括数据构建、模型选择、参数高效微调、模型训练、验证与评估等步骤。</p><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-7">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动包括从原始对话数据构建输入输出对，通过模型进行关系抽取，最终生成关系标签。数据变换包括对话上下文的编码、参数对的提取和关系标签的生成，这些变换有助于模型理解和预测对话中的关系。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-7">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者灵感可能来自于对现有DRE方法的局限性的认识，以及对大型语言模型在其他NLP任务上成功应用的观察。</p><h5 id="作者思考路线如何-7">20. 作者思考路线如何？</h5><p>作者的思考路线可能包括识别DRE任务的挑战、探索LLMs的应用潜力、设计实验验证假设、分析结果并提出改进方法。</p><h4 id="微调具体">微调具体</h4><h5 id="数据准备">1. 数据准备</h5><p>假设我们有以下对话片段： <figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"><span class="hljs-symbol">S1:</span> Hey, <span class="hljs-keyword">do</span> you know who <span class="hljs-built_in">is</span> John<span class="hljs-comment">&#x27;s sister?</span><br><span class="hljs-symbol">S2:</span> Yeah, it<span class="hljs-comment">&#x27;s Sarah.</span><br></code></pre></td></tr></table></figure>我们的目标是提取出John和Sarah之间的关系，即“兄弟姐妹关系（per:siblings）”。</p><h5 id="构建输入输出对">2. 构建输入输出对</h5><p>我们将对话片段构建成适合模型输入的格式。输入提示包括对话上下文和参数对，输出是关系标签。</p><p><strong>输入提示：</strong></p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">| S1: Hey, <span class="hljs-keyword">do</span> you know who <span class="hljs-keyword">is</span> John<span class="hljs-symbol">&#x27;s</span> sister? S2: Yeah, it<span class="hljs-symbol">&#x27;s</span> Sarah. | John | Sarah |<br></code></pre></td></tr></table></figure><p><strong>输出标签：</strong> <figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">|<span class="hljs-string"> per:siblings </span>|<br></code></pre></td></tr></table></figure></p><h5 id="选择基础模型">3. 选择基础模型</h5><p>我们选择一个开源的大型语言模型（如LLaMA）作为基础模型。</p><h5 id="参数高效微调lora">4. 参数高效微调（LoRA）</h5><p>使用LoRA技术进行参数高效微调。具体步骤如下： -<strong>冻结预训练模型的权重：</strong>保持基础模型的大部分权重不变，减少内存占用。 -<strong>注入可训练的秩分解矩阵：</strong>在每层Transformer中加入小规模的可训练参数，用于特定任务的调整。</p><h5 id="微调过程">5. 微调过程</h5><p>在微调过程中，我们使用上一步构建的输入输出对来训练模型。模型通过最小化预测输出与真实关系标签之间的损失（负对数似然）来进行优化。</p><p><strong>损失函数：</strong></p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">L <span class="hljs-punctuation">=</span> <span class="hljs-punctuation">-</span> Σ <span class="hljs-punctuation">(</span><span class="hljs-built_in">log</span> P<span class="hljs-punctuation">(</span>预测关系 <span class="hljs-string">| 对话上下文, 参数对))</span><br></code></pre></td></tr></table></figure><h5 id="验证与评估">6. 验证与评估</h5><p>在模型微调完成后，我们在验证集或测试集上评估模型的表现。我们可以通过精确率（Precision）、召回率（Recall）、F1分数等指标来衡量模型的提取效果。</p><p><strong>示例评估：</strong>如果模型成功预测出John和Sarah之间的关系为<code>per:siblings</code>，那么它的预测是正确的，这将反映在模型的精确率和召回率中。</p><h4 id="prompt-design">Prompt design</h4><p>为了更好地理解不同的Prompt策略在对话关系抽取任务中的应用，我们可以结合一个具体的例子来进行讲解。假设我们有一段对话数据，其中涉及两个人物之间的关系提取。以下是详细的方案流程：</p><h6 id="数据准备-1">1. 数据准备</h6><p>假设我们有以下对话片段： <figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">S1:</span> Hey Pheebs.<br><span class="hljs-symbol">S2:</span> Hey!<br><span class="hljs-symbol">S1:</span> Any sign of your brother?<br></code></pre></td></tr></table></figure>我们的目标是提取出S2和Pheebs之间的关系，即“别名关系（per:alternate_names）”。</p><h6 id="不同的prompt策略">2. 不同的Prompt策略</h6><p>我们将使用四种不同的Prompt策略来展示如何引导模型进行关系抽取和问题回答。</p><p><strong>示例：</strong></p><ul><li><p><strong>Vanilla Prompting:</strong> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql">执行关系抽取任务。<br>关系架构: [<span class="hljs-keyword">per</span>:friends, <span class="hljs-keyword">per</span>:girl<span class="hljs-operator">/</span>boyfriend, <span class="hljs-keyword">per</span>:siblings, <span class="hljs-keyword">per</span>:alternate_names, ...]<br>对话上下文: S1: Hey Pheebs. S2: Hey<span class="hljs-operator">!</span> S1: <span class="hljs-keyword">Any</span> sign <span class="hljs-keyword">of</span> your brother? ......<br>参数对: (S2, Pheebs)<br>关系类型: <span class="hljs-keyword">per</span>:alternate_names<br></code></pre></td></tr></table></figure></p></li><li><p><strong>Restrictive Prompting:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql">执行关系抽取任务。<br>关系架构: [<span class="hljs-keyword">per</span>:friends, <span class="hljs-keyword">per</span>:girl<span class="hljs-operator">/</span>boyfriend, <span class="hljs-keyword">per</span>:siblings, <span class="hljs-keyword">per</span>:alternate_names, ...]<br>对话上下文: S1: Hey Pheebs. S2: Hey<span class="hljs-operator">!</span> S1: <span class="hljs-keyword">Any</span> sign <span class="hljs-keyword">of</span> your brother? ......<br>参数对: (S2, Pheebs)<br>关系类型: <span class="hljs-keyword">per</span>:alternate_names<br></code></pre></td></tr></table></figure></li><li><p><strong>Yes-No Prompting:</strong> <figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">问题: The alternate <span class="hljs-type">name</span> <span class="hljs-keyword">for</span> S2 <span class="hljs-keyword">is</span> Pheebs. 输出 <span class="hljs-keyword">True</span> <span class="hljs-keyword">or</span> <span class="hljs-keyword">False</span>?<br>答案: <span class="hljs-keyword">True</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>Open-Ended Prompting:</strong> <figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs delphi">问题: What <span class="hljs-keyword">is</span> S2’s alternate <span class="hljs-keyword">name</span>?<br>答案: Pheebs<br></code></pre></td></tr></table></figure></p></li></ul><h6 id="解释不同的prompt策略">3. 解释不同的Prompt策略</h6><ul><li><strong>Vanilla Prompting:</strong>直接让模型基于输入对话和候选关系输出参数对之间的关系标签。这种策略简单、直接且高效。</li><li><strong>Restrictive Prompting:</strong>限制模型只输出特定的关系类型。这种策略有助于模型专注于特定的关系，减少歧义。</li><li><strong>Yes-No Prompting:</strong>通过提问的方式让模型回答是否存在某种关系。这种策略适用于需要快速验证关系是否存在的情况。</li><li><strong>Open-Ended Prompting:</strong>让模型自由生成关系类型。这种策略适用于需要模型提供详细答案的情况。</li></ul><h6 id="应用场景">4. 应用场景</h6><ul><li><strong>Vanilla Prompting</strong>适用于需要快速提取关系的情况。</li><li><strong>Restrictive Prompting</strong>适用于需要精确控制关系类型的情况。</li><li><strong>Yes-No Prompting</strong>适用于需要快速验证关系是否存在的情况。</li><li><strong>Open-Ended Prompting</strong>适用于需要详细答案的情况。</li></ul><p>通过这些不同的Prompt策略，模型可以更灵活地处理不同类型的关系抽取任务，从而提高整体的性能和适应性。</p><hr /><h3id="gpt-re-in-context-learning-for-relation-extraction-using-large-language-models">GPT-RE:In-context Learning for Relation Extraction using Large LanguageModels</h3><h5 id="论文试图解决什么问题-8">1. 论文试图解决什么问题？</h5><p>论文试图解决大型语言模型（LLMs）在关系抽取（RE）任务中的表现不如全监督方法的问题，特别是在示例检索的相关性低和缺乏对输入-标签映射的解释这两个方面。</p><h5 id="这是否是一个新的问题-8">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题，但论文针对现有上下文学习（ICL）方法在RE任务中的缺陷提出了新的解决方案。</p><h5 id="这篇文章要验证一个什么科学假设-8">3.这篇文章要验证一个什么科学假设？</h5><p>文章要验证的科学假设是通过改进示例检索和增强推理能力，可以提高LLMs在关系抽取任务中的表现，甚至超越全监督方法。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-8">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究包括使用微调的BERT模型进行全监督关系抽取，以及使用上下文学习（ICL）方法改进LLMs在RE任务中的表现。这些研究可以归类为自然语言处理（NLP）中的关系抽取技术。领域内值得关注的研究员可能包括那些在NLP和关系抽取领域有显著贡献的学者，如JacobDevlin（BERT的开发者）等。</p><h5 id="论文中提到的解决方案之关键是什么-8">5.论文中提到的解决方案之关键是什么？</h5><p>解决方案的关键是提出了任务感知检索（Task-awareRetrieval）和金标签诱导推理（Gold Label-inducedReasoning）两个策略，以改进示例检索的相关性和增强推理能力。</p><h5 id="论文中的实验是如何设计的-8">6. 论文中的实验是如何设计的？</h5><p>实验设计包括在四个广泛使用的RE数据集上评估GPT-RE方法，比较其与现有的GPT-3基线和全监督基线的性能。</p><h5 id="用于定量评估的数据集是什么代码有没有开源-8">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>用于定量评估的数据集包括Semeval、SciERC、TACRED和ACE05。代码是否开源在文中没有提及。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-8">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>是的，实验结果显示GPT-RE不仅优于现有的GPT-3基线，还优于全监督基线，在某些数据集上达到了最先进的性能，支持了科学假设。</p><h5 id="这篇论文到底有什么贡献-8">9. 这篇论文到底有什么贡献？</h5><p>论文的贡献包括提出了任务感知的示例检索方法，引入了金标签诱导推理来增强示例的解释性，有效缓解了LLMs在RE任务中的“过度预测”问题。</p><h5 id="下一步呢有什么工作可以继续深入-8">10.下一步呢？有什么工作可以继续深入？</h5><p>下一步可以继续深入研究如何进一步优化示例检索和推理逻辑，以及如何将这些方法应用于更广泛的NLP任务和领域。</p><h5 id="要了解深入一个模型为什么好-8">11.要了解深入，一个模型为什么好？</h5><p>一个模型之所以好，是因为它能够有效地解决特定问题，如提高示例检索的相关性和增强推理能力，从而提升模型在关系抽取任务中的性能。</p><h5 id="以前的模型为什么不好-8">12. 以前的模型为什么不好？</h5><p>以前的模型在关系抽取任务中表现不佳，主要是因为示例检索的相关性低和缺乏对输入-标签映射的解释，导致模型无法准确识别和分类实体间的关系。</p><h5 id="哪个关键点对性能提升最大-8">13. 哪个关键点对性能提升最大？</h5><p>关键点对性能提升最大的是任务感知检索和金标签诱导推理的引入，这两个策略显著提高了示例的相关性和推理能力。</p><h5 id="编程怎么实现-8">14. 编程怎么实现？</h5><p>编程实现包括使用实体提示的句子嵌入和微调的关系表示来进行任务感知检索，以及通过金标签诱导推理生成推理解释并将其添加到示例中。</p><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-8">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>文中没有提及源代码和论文的匹配度，因此无法确定是否都覆盖了。</p><h5 id="哪些数学运算是关键的-8">16. 哪些数学运算是关键的？</h5><p>关键的数学运算包括句子嵌入的计算、实体标记的隐藏表示提取和关系表示的连接，以及使用这些表示进行最近邻搜索。</p><h5 id="整个全流程是怎么走的-8">17. 整个全流程是怎么走的？</h5><p>全流程包括提示构造、任务感知示例检索、金标签诱导推理和最终预测。具体步骤如前所述。</p><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-8">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动包括从输入句子中提取实体信息，通过任务感知检索找到相关示例，通过金标签诱导推理生成推理解释，最终输入到LLMs中进行预测。变换包括句子嵌入、关系表示提取和推理解释生成，这些变换有助于提高示例的相关性和推理能力。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-8">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者灵感可能来自于对现有ICL方法在RE任务中缺陷的深入分析，以及对如何改进这些缺陷的创新思考。</p><h5 id="作者思考路线如何-8">20. 作者思考路线如何？</h5><p>作者的思考路线可能包括识别现有方法的不足，提出新的解决方案，设计实验验证新方法的有效性，并分析实验结果以进一步优化方法。</p><h4 id="具体示例-1">具体示例</h4><h5 id="提示构造">提示构造</h5><p>首先，我们构造一个包含以下组件的提示：</p><ol type="a"><li><p>指令(I):"给定一个句子和两个实体，确定这两个实体之间的关系。可能的关系包括：创始人（FOUNDER），员工（EMPLOYEE），无关系（NULL）等。"</p></li><li><p>ICL示例(D): 这些示例通过任务感知检索获得，每个包含 (xi, yi,ri)。例如：</p></li></ol><p>示例1:</p><ul><li>输入: "Mark Zuckerberg launched Facebook from his Harvard dormroom."</li><li>实体: Mark Zuckerberg, Facebook</li><li>关系: FOUNDER</li><li>解释: Mark Zuckerberg 被描述为启动 (launched)Facebook，这表明他是创始人。</li></ul><p>示例2:</p><ul><li>输入: "Elon Musk is currently the CEO of Tesla."</li><li>实体: Elon Musk, Tesla</li><li>关系: EMPLOYEE</li><li>解释: CEO 是一个雇员职位，表明 Elon Musk 是 Tesla 的员工。</li></ul><ol start="3" type="a"><li>测试输入(xtest): "确定句子 'Steve Jobs co-founded Apple Inc. in 1976with Steve Wozniak.' 中 Steve Jobs 和 Apple Inc. 之间的关系。"</li></ol><h5 id="任务感知示例检索">任务感知示例检索</h5><p>为了获得上述高质量的 ICL 示例，GPT-RE 使用两种方法：</p><ol type="a"><li><p>实体提示的句子嵌入: 将原句转化为: "The relation between 'SteveJobs' and 'Apple Inc.' in the context: Steve Jobs co-founded Apple Inc.in 1976 with Steve Wozniak."</p></li><li><p>微调的关系表示: 使用预先在 RE 任务上微调的 BERT模型提取关系表示。例如:</p></li></ol><ul><li>输入: [CLS] Steve Jobs [E1] co-founded [E2] Apple Inc. [/E2] in 1976with Steve Wozniak. [/E1]</li><li>提取 [E1] 和 [E2] 对应的隐藏表示，连接得到关系表示 Rel。</li></ul><p>使用这些表示进行最近邻搜索，找到最相关的示例。</p><h5 id="金标签诱导推理">金标签诱导推理</h5><p>为每个检索到的示例生成解释：</p><p>查询: "What are the clues that lead to the relation between SteveJobs and Apple Inc. to be FOUNDER in the sentence 'Steve Jobs co-foundedApple Inc. in 1976 with Steve Wozniak.'?"</p><p>GPT-3 生成的解释: "It is because the verb 'co-founded' directlyindicates that Steve Jobs is one of the founders of Apple Inc. The year1976 provides additional context, suggesting it was at the company'sinception."</p><p>将这个解释添加到示例中，增强模型的推理能力。</p><h5 id="最终预测">最终预测</h5><p>将构造好的提示输入 GPT-3，得到最终预测：</p><p>输出: "根据给定的句子，Steve Jobs 和 Apple Inc. 之间的关系是FOUNDER（创始人）。这是因为句子中使用了'co-founded'（共同创立）这个词，直接表明 Steve Jobs 是 Apple Inc.的创始人之一。1976年的时间信息进一步支持这一关系，暗示这是在公司成立时。"</p><h5 id="处理-null-类别">处理 NULL 类别</h5><p>为了缓解过度预测 NULL 的问题，GPT-RE 在检索时特别关注 NULL样本的表示。例如，可能会包含这样的 NULL 示例：</p><p>输入: "The iPhone was introduced by Apple in 2007."</p><ul><li>实体: iPhone, Apple</li><li>关系: NULL</li><li>解释: 虽然 iPhone 和 Apple有关联，但这个句子并没有表达出预定义的员工或创始人关系。产品和公司的关系不在我们的预定义类别中。</li></ul><p>通过包含这样的 NULL示例，模型能更好地理解何时不应预测预定义的关系。</p><h5 id="总结">总结</h5><p>GPT-RE 通过改进示例检索、增加推理解释，并特别关注 NULL类别的处理，显著提升了大语言模型在关系抽取任务上的表现。这个方法不仅提高了示例的相关性，还增强了模型的推理能力，同时有效缓解了过度预测的问题。</p><hr /><h3id="recall-retrieve-and-reason-towards-better-in-context-relation-extraction">Recall,Retrieve and Reason: Towards Better In-Context Relation Extraction</h3><h5 id="论文试图解决什么问题-9">1. 论文试图解决什么问题？</h5><p>论文试图解决关系抽取(RE)任务中大型语言模型(LLMs)的上下文学习(ICL)能力不足的问题。具体来说，它旨在改进从训练样例中检索好的演示的方法，并提升LLMs在RE任务中的ICL能力。</p><h5 id="这是否是一个新的问题-9">2. 这是否是一个新的问题？</h5><p>这不是一个全新的问题。关系抽取(RE)是一个长期存在的自然语言处理任务，而LLMs在RE任务中的表现一直是一个研究热点。然而，如何有效地利用LLMs的ICL能力来提升RE性能是一个相对较新的研究方向。</p><h5 id="这篇文章要验证一个什么科学假设-9">3.这篇文章要验证一个什么科学假设？</h5><p>这篇文章要验证的科学假设是：通过一个新颖的回忆-检索-推理框架(RE4)，结合本体知识指导和上下文推理优化，可以显著提高关系抽取任务的性能，特别是在使用开源的中等规模语言模型时。</p><h5 id="有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员-9">4.有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h5><p>相关研究可以归类为： - 基于分类的方法：如MTB、LUKE、IRE、KLG等。 -基于提示的方法：如KnowPrompt、NLI-DeBERTa。 -基于生成的方法：如REBEL、TANL、RELA、DeepStruct。 -基于上下文学习(ICL)的方法：如GPT-RE。在这一领域内，值得关注的研究员可能包括那些在关系抽取、大型语言模型和上下文学习方面有深入研究的学者，例如那些在顶级会议和期刊上发表相关研究成果的研究者。</p><h5 id="论文中提到的解决方案之关键是什么-9">5.论文中提到的解决方案之关键是什么？</h5><p>解决方案的关键是提出了一个名为RE4的新型关系抽取框架，它包含三个主要步骤：回忆(Recall)、检索(Retrieve)和推理(Reason)。通过从训练数据集中提取一致的本体知识来指导实体对生成，并利用检索到的演示通过指令调优来增强LLMs的上下文学习能力。</p><h5 id="论文中的实验是如何设计的-9">6. 论文中的实验是如何设计的？</h5><p>实验设计包括在不同的LLMs和RE数据集上进行广泛的实验。使用开源语言模型如T5、BART和LLaMA进行实验，并采用LoRA技术进行微调。实验细节包括设置训练轮数、批次大小、学习率等超参数。</p><h5 id="用于定量评估的数据集是什么代码有没有开源-9">7.用于定量评估的数据集是什么？代码有没有开源？</h5><p>用于定量评估的数据集包括SemEval 2010、TACRED、GoogleRE和SciERC。评估指标采用Micro-F1分数。至于代码是否开源，需要查看论文或其附录以获取具体信息。</p><h5 id="论文中的实验及结果有没有很好地支持需要验证的科学假设-9">8.论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><p>实验结果表明，RE4方法能生成相关且有效的实体对，并提升LLMs的ICL能力。在句子级RE任务上达到了与之前的监督微调方法和基于ICL方法相当或更好的性能。这些结果很好地支持了科学假设。</p><h5 id="这篇论文到底有什么贡献-9">9. 这篇论文到底有什么贡献？</h5><p>这篇论文的贡献包括： -提出了一个新颖的回忆-检索-推理RE框架，将LLMs与检索语料库(训练样例)结合。- 通过从训练数据集中提取一致的本体知识来指导实体对生成。 -提出了增强开源LLMs在RE任务中上下文推理能力的方法。</p><h5 id="下一步呢有什么工作可以继续深入-9">10.下一步呢？有什么工作可以继续深入？</h5><p>下一步可以继续深入的工作包括： -探索更多类型的数据集和更复杂的RE任务。 -研究如何进一步优化RE4框架的各个模块，以提高性能和效率。 -探索如何在其他自然语言处理任务中应用类似的框架。</p><h5 id="要了解深入一个模型为什么好-9">11.要了解深入，一个模型为什么好？</h5><p>一个模型之所以好，是因为它能够有效地解决特定问题，具有良好的泛化能力，并且在各种评估指标上表现出色。具体到RE4模型，它的好处在于结合了本体知识指导和上下文推理优化，能够生成相关且有效的实体对，并提升LLMs的ICL能力。</p><h5 id="以前的模型为什么不好-9">12. 以前的模型为什么不好？</h5><p>以前的模型可能在关系抽取任务中表现不佳，因为它们可能没有充分利用LLMs的ICL能力，或者在检索相关演示时效率不高。此外，以前的模型可能没有结合本体知识来指导实体对生成，导致生成的实体对相关性不高。</p><h5 id="哪个关键点对性能提升最大-9">13. 哪个关键点对性能提升最大？</h5><p>关键点对性能提升最大的可能是通过从训练数据集中提取一致的本体知识来指导实体对生成，以及利用检索到的演示通过指令调优来增强LLMs的上下文学习能力。</p><h5 id="编程怎么实现-9">14. 编程怎么实现？</h5><p>编程实现RE4框架可能涉及以下步骤： -实现召回模块，用于从训练数据集中提取一致的本体知识并生成相关实体对。 -实现检索模块，使用生成的实体对从训练语料中检索相关的训练样例作为演示。 -实现推理模块，利用检索到的演示，通过指令调优来增强LLMs的上下文学习能力，并对给定的测试样例进行关系推理。</p><h5 id="论文源代码和paper匹配度怎么样都覆盖了吗-9">15.论文源代码和paper匹配度怎么样、都覆盖了吗</h5><p>需要查看论文的附录或相关资源以获取源代码和paper的匹配度信息。通常，论文会提供源代码链接，并确保代码与论文描述的方法一致。</p><h5 id="哪些数学运算是关键的-9">16. 哪些数学运算是关键的？</h5><p>关键的数学运算可能包括： -本体知识的提取和表示，可能涉及图论和集合运算。 -实体对的生成，可能涉及概率模型和优化算法。 -检索相关演示，可能涉及信息检索和排序算法。 -上下文推理，可能涉及序列模型和概率推断。</p><h5 id="整个全流程是怎么走的-9">17. 整个全流程是怎么走的？</h5><p>整个全流程包括： - 测试样例输入。 - 召回模块生成相关实体对。 -检索模块使用生成的实体对检索相关演示。 -推理模块利用检索到的演示进行上下文推理，预测实体之间的关系。</p><h5 id="数据是怎样流动的其中是怎样变换的各个变换有什么实际意义-9">18.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</h5><p>数据流动和变换包括： - 输入测试样例。 -召回模块生成相关实体对，这个变换的意义在于指导LLMs生成有效的查询。 -检索模块使用生成的实体对检索相关演示，这个变换的意义在于提供相关的训练样例作为上下文。-推理模块利用检索到的演示进行上下文推理，这个变换的意义在于增强LLMs的ICL能力，提高关系抽取的准确性。</p><h5 id="既要关注具体实现思路也要关注上层抽象意义作者灵感从何而来-9">19.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</h5><p>作者的灵感可能来自于对LLMs在RE任务中表现不佳的深入分析，以及对如何有效利用LLMs的ICL能力的探索。具体实现思路可能受到本体知识在信息检索和自然语言处理中的应用启发，而上层抽象意义在于提出一个通用的框架来提升LLMs在RE任务中的性能。</p><h5 id="作者思考路线如何-9">20. 作者思考路线如何？</h5><p>作者的思考路线可能包括： - 分析LLMs在RE任务中的不足。 -探索如何结合本体知识来指导实体对生成。 -设计一个包含召回、检索和推理的框架来提升LLMs的ICL能力。 -进行实验验证框架的有效性，并根据实验结果进行优化。</p><h4 id="具体例子-4">具体例子</h4><p><strong>假设我们有一个测试句子:</strong> "Apple Inc., headquarteredin Cupertino, is a leading technology company."</p><p>我们的目标是确定"Apple Inc."和"Cupertino"之间的关系。</p><p><strong>RE4方法的步骤如下:</strong></p><h6 id="召回模块-recalling-module">召回模块 (Recalling Module):</h6><p>这个模块首先生成k个可能相关的实体对。假设k=5,它可能生成:</p><p>(Apple Inc., Cupertino) (Microsoft, Seattle) (Google, Mountain View)(Amazon, Seattle) (Facebook, Menlo Park)这些生成的实体对基于输入句子和模型对公司-总部关系的理解。</p><h6 id="检索模块-retrieving-module">检索模块 (Retrieving Module):</h6><p>使用生成的实体对作为查询,从训练集中检索相关的示例。例如:</p><p>"Apple Inc. is based in Cupertino, California." "Microsoft'sheadquarters is located in Seattle." "Google's main campus is inMountain View." "Amazon's headquarters is in Seattle, Washington.""Facebook's headquarters is situated in Menlo Park."</p><h6 id="推理模块-reasoning-module">推理模块 (Reasoning Module):</h6><p>这个模块将原始输入句子、检索到的示例,以及一个推理提示组合在一起。例如:</p><p>推理提示: "Based on the following examples, determine the relationbetween Apple Inc. and Cupertino in the given sentence."</p><p>示例1: "Apple Inc. is based in Cupertino, California." Relation:headquarters 示例2: "Microsoft's headquarters is located in Seattle."Relation: headquarters ...</p><p>测试句子: "Apple Inc., headquartered in Cupertino, is a leadingtechnology company."</p><p>Question: What is the relation between Apple Inc. and Cupertino?</p><p>模型会基于这些信息进行推理,得出结论:"The relation between Apple Inc.and Cupertino is headquarters."</p><p><strong>训练过程:</strong> RE4通过两个指令任务来训练模型:</p><ol type="a"><li><p>召回指令任务: 训练模型生成相关的实体对。 例如: "Generate 5 entitypairs that might have a similar relation as Apple Inc. andCupertino."</p></li><li><p>推理指令任务: 训练模型基于示例进行关系推理。使用类似上面推理模块中的格式。</p></li></ol><p>通过这种方式,模型学会了如何生成相关实体对和如何利用示例进行关系推理。</p><p><strong>推理过程:</strong>在测试时,模型会依次执行召回、检索和推理这三个步骤,最终得出关系预测结果。</p><p>这种方法的优势在于:</p><p>它结合了监督学习的任务特定性和上下文学习的灵活性。通过生成相关实体对,它可以检索到更相关的示例。推理模块允许模型利用检索到的示例进行更准确的关系判断。</p>]]></content>
    
    
    
    <tags>
      
      <tag>信息抽取</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>招生广告(北邮人工智能学院方全教授)</title>
    <link href="/2024/08/14/Lab/Team/%E6%8B%9B%E7%94%9F%E5%B9%BF%E5%91%8A(%E5%8C%97%E9%82%AE%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E9%99%A2%E6%96%B9%E5%85%A8%E6%95%99%E6%8E%88)/"/>
    <url>/2024/08/14/Lab/Team/%E6%8B%9B%E7%94%9F%E5%B9%BF%E5%91%8A(%E5%8C%97%E9%82%AE%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E9%99%A2%E6%96%B9%E5%85%A8%E6%95%99%E6%8E%88)/</url>
    
    <content type="html"><![CDATA[<p>【直博生/日常实习生招生】人工智能学院方全教授招收2025年直博生/日常实习生</p><p><strong>招生信息</strong></p><p>方全教授课题组现招收2025年9月入学直博生1名,日常实习生若干名。我们欢迎对<strong>大型语言模型</strong>、<strong>图机器学习</strong>、多媒体知识计算、知识图谱和社会媒体数据挖掘等方向感兴趣的优秀学生加入。</p><hr /><p><strong>【导师简介】</strong></p><p>方全，北京邮电大学特聘研究员，博士生导师，<strong>北京市杰青</strong>，多媒体计算组负责人。曾任<strong>中国科学院自动化研究所</strong>副研究员。CCF-多媒体技术专业委员会执行委员。研究方向为多媒体知识计算、知识图谱、大型语言模型、图机器学习和社会媒体数据挖掘与应用。主持和参与了国家自然科学面上青年基金、基金重点、国家重点研发计划、北京市杰青项目、CCF-腾讯犀牛鸟基金等项目。在多媒体领域相关的重要国际期刊如IEEETKDE/TMM，ACM TOIS/TIST和重要国际会议如ACM Multimedia,AAAI等上共发表论文60多篇。 获得CCF-A类 ACM Multimedia2019/2013<strong>最佳论文提名</strong>，获得2019年中国多媒体大会最佳论文奖，获得2016年中国科学院优秀博士论文和中国人工智能学会优秀博士学会论文；获得微软亚洲研究院学者奖。2018年中国多媒体大会多媒体前沿技术杰出展示奖。研究成果在中国航天科工二院、腾讯、快手、创维、民航得到了应用验证。更多信息请访问方全教授的个人主页：<ahref="https://teacher.bupt.edu.cn/fangquan/zh_CN/index.htm">点击进入</a></p><hr /><p><strong>【我们的优势】</strong></p><ul><li><p>提供优越的科研环境和丰富的资源支持</p></li><li><p>导师<strong>亲自指导</strong>，确保科研工作的高质量</p></li><li><p>与业界知名企业紧密合作，提供丰富的实习机会</p></li><li><p>丰富的国内外学术交流机会</p></li><li><p>定期的团队聚餐和团建活动，增进团队凝聚力</p></li></ul><hr /><p><strong>【直博生招生要求】</strong></p><ol type="1"><li><p>对人工智能和多媒体计算相关研究方向有浓厚兴趣</p></li><li><p>具有人工智能或计算机科学与技术专业背景</p></li><li><p>具有良好的编程能力和英语水平</p></li><li><p>有相关科研经历者优先</p></li></ol><p><strong>【实习生招生要求】</strong></p><ol type="1"><li><p>对人工智能和多媒体计算相关研究方向有浓厚兴趣</p></li><li><p>具有良好的编程能力和英语水平</p></li><li><p>在实习期间表现优秀，且符合接收推免保送直博、硕士研究生资格要求的同学，实验室将优先推荐接收保研；对有意向保研其他高校、出国留学的同学，实验室可提供科研推荐信。</p></li></ol><hr /><p><strong>【申请方式】</strong>有意向的同学请将个人简历、成绩单、研究计划等材料发送至<ahref="mailto:qfang@bupt.edu.cn">qfang@bupt.edu.cn</a>。邮件主题请注明"2025级直博生/实习生申请-姓名-学校"。我们将尽快联系。</p>]]></content>
    
    
    
    <tags>
      
      <tag>招生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型信息抽取学习</title>
    <link href="/2024/07/15/Skill/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%AD%A6%E4%B9%A0/"/>
    <url>/2024/07/15/Skill/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h3 id="大模型相关知识">大模型相关知识</h3><h4 id="什么是大模型">什么是大模型</h4><h6 id="大小模型的区别">大小模型的区别</h6><p>涌现能力（大模型由于scaling law才具有的能力）涌现能力是否存在——用户的体验本身就是离散的（选择已经能用的，而不是不能用的里面错误少的）##### 大模型和预训练语言模型任务的区别语言建模（PLM）——复杂任务求解（LLM）</p><p><imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407231044145.png"alt="image-20240723104401035" /> #### 大模型训练相关 ##### 数据的准备##### 如何进行数据的清洗： - 质量过滤：先启发式规则过滤，然后分类器级联- 敏感内容过滤：基于规则 - 数据去重：计算粒度；匹配去重</p><p>高质量数据对模型训练至关重要。Phi-1模型在高质量数据上训练，达到了HumanEval测试50.6%的pass@1准确率，而低质量数据会导致训练不稳定。GLaM模型的对比研究表明，高质量数据显著提升了自然语言处理任务的表现。预训练数据的准确性和多样性对于减少模型输出错误至关重要。例如，“灯泡是爱迪生发明的”是常见误解，训练模型需避免这种错误数据，以提升模型的准确性和基础能力。如果模型在包含事实性错误或过时的数据上进行训练，会在处理相关主题时产生不准确或虚假的信息，这种现象被称为“幻象”。</p><h5 id="如何对语料进行分词">如何对语料进行分词</h5><h5 id="bpe算法详解与示例">BPE算法详解与示例</h5><p><strong>背景</strong>：BPE（Byte PairEncoding）算法最早在1994年被提出用于通用数据压缩，后来被引入自然语言处理领域用于文本分词。BPE算法从一组基本符号（例如字母和边界字符）开始，迭代地寻找语料库中两个相邻词元，将它们合并为新的词元，过程一直持续到预定义的词表大小为止。##### BPE算法实现步骤 1. <strong>初始化词汇表</strong>：开始时，词汇表由所有单独的字母和一个边界字符组成。 2.<strong>计算词频</strong>： 统计每个单词在语料库中的频率。 3.<strong>计算字符对频率</strong>：计算所有相邻字符对在词频字典中的共现频率。 4.<strong>合并字符对</strong>：每次迭代选择频率最高的字符对进行合并，并更新词汇表和词频字典。 #####BPE算法示例 假设语料库包含以下五个单词及其频率： <figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ada">“<span class="hljs-keyword">loop</span>”：<span class="hljs-number">15</span>次  <br>“pool”：<span class="hljs-number">10</span>次  <br>“loot”：<span class="hljs-number">10</span>次  <br>“tool”：<span class="hljs-number">5</span>次  <br>“loots”：<span class="hljs-number">8</span>次<br></code></pre></td></tr></table></figure>初始词汇表为： <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[<span class="hljs-string">&quot;l&quot;</span>, <span class="hljs-string">&quot;o&quot;</span>, <span class="hljs-string">&quot;p&quot;</span>, <span class="hljs-string">&quot;t&quot;</span>, <span class="hljs-string">&quot;s&quot;</span>]</span><br></code></pre></td></tr></table></figure> ###### 初始状态 1.<strong>词频统计</strong>： "loop"：15次<br />"pool"：10次<br />"loot"：10次<br />"tool"：5次<br />"loots"：8次 2. <strong>初始词频字典</strong>： {"l o o p </w>": 15, "po o l </w>": 10, "l o o t </w>": 10, "t o o l </w>": 5, "l o o t s</w>": 8} ###### 第一次迭代 1. <strong>计算字符对频率</strong>： ("l","o")：33次<br />("o", "o")：48次<br />("o", "p")：15次<br />("p", "l")：10次<br />("o", "t")：18次<br />("t", "s")：8次 2. <strong>合并频率最高的字符对</strong>： 合并 ("o","o")，新词汇表和词频字典为： 词汇表：["l", "o", "p", "t", "s","oo"]<br />词频字典：{"l oo p </w>": 15, "p oo l </w>": 10, "l oo t </w>": 10, "too l </w>": 5, "l oo t s </w>": 8} ###### 第二次迭代 1.<strong>计算新字符对频率</strong>： ("l", "oo")：33次<br />("oo", "p")：15次<br />("p", "oo")：10次<br />("oo", "l")：10次<br />("oo", "t")：18次<br />("t", "s")：8次 2. <strong>合并频率最高的字符对</strong>： 合并 ("l","oo")，新词汇表和词频字典为： 词汇表：["l", "o", "p", "t", "s", "oo","loo"]<br />词频字典：{"loo p </w>": 15, "p oo l </w>": 10, "loo t </w>": 10, "t ool </w>": 5, "loo t s </w>": 8} ##### Tips为了训练出高效的分词器，需重点关注以下因素： 1.<strong>无损重构</strong>：确保分词结果能准确重构为原始输入文本。 2.<strong>高压缩率</strong>：在分词后生成的词元数量尽可能少，提高编码和存储效率。</p><p>此外，针对特定需求设计分词器，如处理多语言数据或提升特定能力（如数学能力），可以显著提高大语言模型在实际应用中的效果。综上所述，在设计和训练分词器时，需综合考虑这些因素，以确保其在实际应用中发挥最佳效果。#### 预训练数据准备流程概述：以YuLan模型为例在大语言模型预训练过程中，数据的准备是至关重要的一步。以下是YuLan模型在预训练阶段的一般流程和关键要点：##### 1. 数据收集<strong>目标</strong>：确保预训练数据来源的多样化，以增强模型的广泛适应能力和特定任务能力。<strong>步骤</strong>： -<strong>多样化数据来源</strong>：收集大规模网页数据（如CommonCrawl）、书籍数据（如Books3和Gutenberg）、高质量知识密集型语料（如知乎和维基百科）。-<strong>特定任务数据</strong>：根据需求引入特定任务的数据，如数学数据（Proof-Pile）和代码数（GitHub），以优化模型的特定能力。<strong>YuLan模型的实践</strong>： -首先收集了大量通用预训练语料，包括网页数据和书籍数据。 -为增加数据多样性，收集了知乎、维基百科等高质量语料。 -在训练后期，引入了数学和代码等专用文本数据，以增强特定任务能力。 #### 2.数据清洗<strong>目标</strong>：提高数据质量，确保模型在预训练过程中能够学到有用的信息。<strong>步骤</strong>： -<strong>通用数据清洗</strong>：进行质量过滤、去重、隐私数据去除和词元化。-<strong>针对性清洗</strong>：根据具体数据特点和应用场景设计清洗规则，例如过滤掉网页数据中的HTML标签。<strong>YuLan模型的实践</strong>： -采用启发式方法进行文档级别和句子级别的低质量及有害数据过滤。 -使用MinHash算法在多个数据源之间识别并去除重复数据。 -基于LLaMA的词表，并加入在中文预训练数据上得到的BPE词元，构成YuLan模型的词表（词表大小为51,200），用于对预训练数据进行词元化。#### 3. 数据调度<strong>目标</strong>：确定训练大语言模型的数据混合配比及数据训练顺序，以优化模型能力。<strong>步骤</strong>： -<strong>代理方法</strong>：使用多个候选策略训练多个小型语言模型，从中选择最优的训练策略。-<strong>确定混合比例</strong>：首先确定语言配比，再确定不同数据类型配比，通过下游任务测试效果来调整比例。-<strong>动态调整</strong>：根据模型各项能力的测试结果，动态调整数据混合比例。<strong>YuLan模型的实践</strong>： -预训练了一个1.3B的小模型，测试不同类型数据和中英文数据的混合配比。 -根据下游任务测试效果确定中英文语料比例为1:8。 -维持该比例不变，并使用控制变量法，每次仅调整某一类型数据的比例进行实验。-根据各项能力的测试结果手动调整数据混合比例，最终使用了1,680B词元，包括1,380B英文数据、280B中文数据以及20B多语数据。#### 数据课程<strong>目标</strong>：通过特定顺序安排预训练数据，优化模型的学习效果。<strong>步骤</strong>： -从简单/通用数据开始，逐渐引入更具挑战性/专业化的数据。 -在训练期间动态调整数据混合比例。 <strong>YuLan模型的实践</strong>： -例如，为提升代码生成能力，首先使用2T通用词元进行训练，然后用500B代码数据词元进行训练。-为提升数学能力，选择CodeLLaMA作为基座模型，在包含科学论文、数学和代码的混合数据集合上进行继续预训练。#### 总结YuLan模型的预训练数据准备流程包括数据收集、数据清洗和数据调度三个主要步骤。在数据收集中注重多样化和特定任务数据的引入；在数据清洗中进行全面细致的质量过滤、去重和词元化；在数据调度中，通过小模型测试和动态调整确定最优的数据混合配比和训练顺序。通过这些步骤，确保了YuLan模型在预训练阶段能够获得高质量的数据支持，从而提升模型的各项能力。</p><h3 id="位置编码">位置编码</h3><h4 id="旋转矩阵计算">旋转矩阵计算</h4><p>假设我们有一个简单的输入序列：“Hello”, “world”,“AI”。假设词向量的维度为 (H = 4)。 ##### 步骤 1: 生成词向量</p><p><strong>词嵌入（Word Embedding）</strong>: - ( ) - ( ) - ( ) #####步骤 2: 旋转矩阵的计算 <strong>旋转矩阵 ( R_{, t} )</strong>: - 基数 ( b= 10000 ) - 旋转角度 ( _1 = 0.01 ) 弧度 对每个位置 ( t ):</p><p><span class="math display">\[  R_{\theta, 0} = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}  \]</span></p><p><span class="math display">\[  R_{\theta, 1} = \begin{bmatrix} \cos(0.01) &amp; -\sin(0.01) \\\sin(0.01) &amp; \cos(0.01) \end{bmatrix} \approx \begin{bmatrix}0.99995 &amp; -0.00999983 \\ 0.00999983 &amp; 0.99995 \end{bmatrix}  \]</span> <span class="math display">\[  R_{\theta, 2} = \begin{bmatrix} \cos(0.02) &amp; -\sin(0.02) \\\sin(0.02) &amp; \cos(0.02) \end{bmatrix} \approx \begin{bmatrix} 0.9998&amp; -0.0199987 \\ 0.0199987 &amp; 0.9998 \end{bmatrix}  \]</span> ##### 步骤 3: 应用旋转矩阵到词向量<strong>应用旋转矩阵</strong>: <span class="math display">\[  \text{Hello\_rot} = [1.0, 2.0, 3.0, 4.0]  \]</span></p><p><span class="math display">\[  \text{world\_rot} = [1.9998, 2.98002, 3.9994, 4.9801]  \]</span></p><p><span class="math display">\[  \text{AI\_rot} = [2.9994, 3.95998, 4.9988, 5.9596]  \]</span> ##### 总结旋转位置编码（RoPE）通过应用位置特定的旋转矩阵到每个词向量的维度上，有效地融合了词的语义息和它在句子中的</p><p>位置信息。这种方法不仅保留了原始词向量的语义特征，还增加了位置敏感性，从而使模型能够更好地理解和处理序列数据。### SFT和RLHF对比 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407250945768.png"alt="image-20240725094521712" /> ### ICL和CoT对比 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407251014182.png"alt="image-20240725101414135" /> ####上下文学习（ICL）和思维链提示（CoT）的关键区别：</p><h5 id="上下文学习in-context-learning-icl">上下文学习（In-contextLearning, ICL）</h5><ul><li><strong>示例内容</strong>：示例里仅包含问题和最终答案。</li><li><strong>主要特点</strong>：模型基于任务描述和示例问题-答案对进行学习，并直接生成答案。</li><li><strong>适用场景</strong>：适用于简单的、示例明确的任务。 #####思维链提示（Chain-of-Thought, CoT）</li><li><strong>示例内容</strong>：示例里不仅包含问题和答案，还包括详细的推理过程。</li><li><strong>主要特点</strong>：通过展示每一步的推理过程，帮助模型理解和解决复杂任务。</li><li><strong>适用场景</strong>：适用于需要多步骤推理的复杂任务，增强模型的推理能力。##### 具体例子对比： ###### 上下文学习（ICL）示例： 任务描述: Answer thefollowing mathematical reasoning questions:</li></ul><p>示例1:<br />Q: If you have 12 candies and you give 4 candies to your friend, howmany candies do you have left?<br />A: The answer is 8.<br />​示例2:<br />Q: If a rectangle has a length of 6 cm and a width of 3 cm, what is theperimeter of the rectangle?<br />A: The answer is 18cm.<br />​<br />测试样本:<br />Q: Sam has 12 marbles. He gives 1/4 of them to his sister. How manymarbles does Sam have left?</p><p>模型基于示例直接生成答案：</p><p>A: The answer is 9. ###### 思维链提示（CoT）示例： 任务描述: Answerthe following mathematical reasoning questions:<br />​示例1:<br />Q: If a rectangle has a length of 6 cm and a width of 3 cm, what is theperimeter of the rectangle?<br />A: For a rectangle, you add up the length and width and double it. So,the perimeter of this rectangle is (6 + 3) x 2 = 18 cm. The answer is18cm.<br />​<br />测试样本:<br />Q: Sam has 12 marbles. He gives 1/4 of them to his sister. How manymarbles does Sam have left?</p><p>模型基于示例中的推理步骤进行详细推理并生成答案：</p><p>A: He gives (1/4) x 12 = 3 marbles. So Sam is left with 12 - 3 = 9marbles. The answer is 9. #### 总结： -<strong>ICL</strong>：示例中仅有问题和答案，适用于简单任务。 -<strong>CoT</strong>：示例中包含详细推理过程，适用于复杂任务，需要多个推理步骤。</p><h3 id="retrieval-aug">retrieval aug</h3><h3 id="prompt-ie">Prompt IE</h3><h4 id="问答question-answerqa">1. 问答（Question Answer，QA）</h4><p>LLMs通常通过对话方法进行指令微调，这与IE任务的结构化预测要求存在差距。因此，最近的一些研究尝试使用QA提示方法来增强LLMs，并促进生成所需的结果。例如：- <strong>QA4RE</strong>发现LLMs在RE任务上表现不佳，因为用于训练它们的指令微调数据集中RE任务的出现频率较低。因此，它提出将RE重新表述为多选QA，以利用指令微调数据集中QA任务的高出现率。- <strong>Li等人</strong>分析了现有RE提示的局限性，提出了一种新的方法，称为“总结和提问”（summarize-and-ask）提示，通过递归地使用LLMs将零样本RE输入转换为有效的QA格式。- <strong>ChatIE</strong>提出了一种两阶段框架，将零样本IE任务转换为多轮QA问题。该框架首先识别不同类型的元素，然后针对每种元素类型执行顺序IE过程。</p><h4 id="思维链提示chain-of-thoughtcot">2.思维链提示（Chain-of-Thought，CoT）</h4><p>思维链（CoT）是一种通过提供逐步和连贯的推理链作为提示来指导模型生成响应的策略。这种提示在近年来受到了关注，并且有研究正在探索其在IE任务中的有效性。例如：- <strong>PromptNER</strong>结合LLMs和基于提示的启发式方法及实体定义，促使LLMs根据提供的实体类型定义生成潜在实体及其解释的列表。- <strong>Bian等人</strong>提出了一种两步法，通过使用CoT逐步解决生物医学NER任务，首先进行实体范围提取，然后确定实体类型。- <strong>Yuan等人</strong>提出了CoT提示作为一种两阶段方法，指导ChatGPT执行时间关系推理任务。</p><h3 id="prompt设计">Prompt设计</h3><p>请根据以下示例和格式要求，从给定的航空通告（NOTAM）文本中提取相关信息：</p><p>示例1： 输入： D) MAR 16 17 20-31 APR 01-15 0030-1030 E)DUE TOUNMANNED ACFT, ONLY USE ATS RTE Q14 FOR FLT OPERATIONS EQUAL TO, ORABOVE FL100 (SEE NOTAM VVVV A0355/24) RMK: PILOTS ARE REQ TO FLW ATCINSTRUCTIONS STRICTLY.</p><p>输出： { "type": "禁航", "atc": null, "fpl": null, "height_detail": {"upper": "UNL", "lower": "FL100" }, "area_id": null, "change_info":null, "directional": null, "route": "Q14", "start": null, "end": null,"exclude_info": null }</p><p>示例2： 输入： D) E)ATS RTE SEGMENTS CLSD: A100 KRASNYY SULINNDB(KL)- ARNAD A102 BABUR-NALEM A225 GUKOL-TIKNA</p><p>输出： { "type": "禁航", "atc": null, "fpl": null, "height_detail":null, "area_id": null, "change_info": null, "directional": null,"route": ["A100", "A102", "A225"], "start": ["KL", "BABUR", "GUKOL"],"end": ["ARNAD", "NALEM", "TIKNA"], "exclude_info": null }</p><p>请注意：</p><ol type="1"><li><p>输出应为JSON格式。</p></li><li><p>如果某个字段在给定文本中没有相关信息，请将其值设为null。</p></li><li><p>对于route、start和end字段，如果有多个值，请使用数组格式。</p></li><li><p>请仔细分析文本，提取所有可能的相关信息。</p></li><li><p>如果文本中包含多条信息，请尽可能提取所有相关内容。</p></li></ol><p>现在，请根据以上要求和示例，从下面给出的NOTAM文本中提取相关信息：</p><p>D)19-22 0430-1700 E)ATS RTE SEGMENT CLSD: KR395 LYSKOVONDB(HD)-OSVUP.</p>]]></content>
    
    
    <categories>
      
      <category>Skill</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信息抽取</tag>
      
      <tag>大模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>多模态融合论文阅读</title>
    <link href="/2024/07/15/Paper/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2024/07/15/Paper/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p>在前向传播中，图像和文本输入首先被嵌入为连续的令牌序列，并送入单模态变换器层进行基础特征提取。两种模态的基础特征随后通过多个基于提示的多模态融合层进行处理，以获取两个CLS令牌的特征，用于最终的分类。在反向传播中，只有多模态融合层参与梯度的计算，这在训练期间大大节省了内存使用量。训练期间，两个变换器中的所有预训练参数都被冻结。根据之前的讨论，数据在多模态融合模型中的流动和变换可以按以下步骤详细描述：</p><h3 id="数据流动与变换的步骤">数据流动与变换的步骤：</h3><ol type="1"><li><strong>输入处理</strong>：<ul><li><strong>图像和文本输入</strong>：首先，图像和文本输入被预处理并嵌入为连续的令牌序列。</li><li><strong>单模态变换器层</strong>：这些嵌入序列接着被送入相应的单模态变换器层（例如，一个专门处理文本的变换器和一个处理图像的变换器），在这里它们被转换为基础特征向量。</li></ul></li><li><strong>查询阶段</strong>：<ul><li><strong>连接查询提示和上下文提示</strong>：特定的查询提示（QP）和查询上下文提示（QCP）与基础特征向量连接，形成一个扩展的特征序列。</li><li><strong>单模态处理</strong>：这个扩展的序列通过相应的单模态变换器层进一步处理，以提取和强化模态内的关键信息。</li><li><strong>非线性映射</strong>：从查询阶段得到的特征（主要是来自QP的输出）通过非线性映射转换到另一模态的表示空间，为跨模态融合做准备。</li></ul></li><li><strong>融合阶段</strong>：<ul><li><strong>融合上下文提示</strong>：在融合阶段，融合上下文提示（FCP）与映射后的交叉模态中间体（来自查询阶段的输出）以及另一模态的原始输入连接。</li><li><strong>跨模态单模态处理</strong>：这个连接后的序列被送入另一模态的单模态变换器层，进行最终的融合处理。</li><li><strong>输出合并</strong>：两个模态的变换器层的输出合并，形成融合后的特征向量，这将被送入更高层或用于最终分类。</li></ul></li></ol><h3 id="各变换的实际意义">各变换的实际意义：</h3><ul><li><strong>查询提示（QP）</strong>：主要用于从一个模态中提取对另一模态有用的信息，起到“提问”或“索引关键信息”的作用。</li><li><strong>查询上下文提示（QCP）</strong>：为查询过程提供上下文支持，帮助改善和指导查询操作的准确性和效率。</li><li><strong>融合上下文提示（FCP）</strong>：在融合阶段使用，提供必要的上下文以促进两种模态信息的有效融合。</li><li><strong>非线性映射</strong>：允许将一个模态的输出转换成另一模态能够理解和进一步处理的形式，是实现模态间翻译和理解的关键步骤。</li><li><strong>跨模态融合</strong>：最终目的是合成一个综合的、跨越语言和视觉界限的表示，用于提高决策或分类的性能。</li></ul><p>这种基于提示的多模态融合策略（PMF）利用了深层学习的强大能力，通过精心设计的提示和变换器层来处理和融合不同种类的数据，旨在提高多模态学习任务中的效率和效果。</p><p>特定的查询提示（QP）和查询上下文提示（QCP）通常是在模型训练过程中学习得到的。它们作为模型参数的一部分，通过训练数据和反向传播算法进行优化，以达到最佳效果。以下是详细的来源和学习过程：</p><ol type="1"><li><strong>设计和初始化</strong>：<ul><li>在模型设计阶段，研究人员或工程师会定义QP（查询提示）和QCP（查询上下文提示）的结构和初始形式。这些提示可以被初始化为随机向量，或者可能使用某种预训练嵌入（如词嵌入）作为起点。</li></ul></li><li><strong>模型训练</strong>：<ul><li><strong>数据输入</strong>：在训练期间，大量的标注数据（如图像-文本对）被用于教导模型如何处理和理解不同模态的信息。</li><li><strong>前向传播</strong>：输入数据通过模型的各层前向传播，其中包括将QP和QCP插入到相应的序列中。</li><li><strong>损失计算</strong>：模型输出与真实标签比较，计算损失函数，这通常涉及到分类准确性、信息检索效率等多模态交互指标。</li><li><strong>反向传播</strong>：损失函数关于各参数（包括QP和QCP）的梯度被计算并用于更新这些参数。这个过程反复执行，逐渐优化QP和QCP，使其能够更有效地在模态之间查询和传递信息。</li></ul></li><li><strong>优化和调整</strong>：<ul><li>随着训练的进行，QP和QCP会被优化为能够捕捉关键信息和上下文的表示形式，这对于改进跨模态理解和交互至关重要。</li><li>这些提示的优化直接关系到模型在多模态任务中的表现，如图像标注、视频理解或其他需要细致理解和处理多种信息类型的任务。</li></ul></li></ol><p>总之，特定的查询提示（QP）和查询上下文提示（QCP）是通过模型的学习过程自动学到的，它们不是预设的固定参数，而是随着模型训练逐渐调整和优化的动态元素。这使得它们能够在具体的应用场景中表现出高度的适应性和效率。</p><p>根据提供的额外内容，下面是对前述回答的完善和补充，重点放在消融研究、模块化、灵活性和使用神经架构搜索（NAS）优化模型结构上：</p><h3 id="消融研究">消融研究</h3><ul><li><p><strong>组件消融</strong>：研究验证了三种提示和非线性映射功能的有效性。结果表明，仅在两个变换器的顶层使用提示并不能实现多模态融合，反而会扰乱特征空间，从而降低性能。尽管映射函数显著提升了性能，但映射函数不能单独工作，必须与查询提示（QP）配合使用来查询融合中间体。</p></li><li><p><strong>提示解耦</strong>：将提示解耦为具有不同学习目标的三个独立模块显示出性能提升。此外，扩展的查询提示（QP）不能替代查询上下文提示（QCP），替换后不仅增加了计算量，还导致性能下降。</p></li><li><p><strong>融合层影响</strong>：不同的融合层 ( L_f )对性能和内存效率的影响显示，随着融合开始的层次越晚，训练内存使用量持续减少。然而，当( L_f ) 时，融合模型的性能相对一致，因此在深层（( 10 &lt; l &lt; L)）添加提示对性能与内存效率之间的折衷更为有利。</p></li><li><p><strong>提示长度</strong>：提示长度的消融研究表明，当提示长度 ( M) 时，性能随提示长度增加而提升，而过长的提示（( M = 32)）则导致性能下降。训练内存使用量的增加主要由融合层 ( L_f )而非提示长度引起。</p></li></ul><h3 id="模块化与灵活性">模块化与灵活性</h3><ul><li><strong>模块化设计</strong>：PMF高度模块化，可以轻松替换单模态变换器，以适应更好的模型。这一灵活性允许在使用更大的预训练模型进行实验时，以非常有限的训练内存使用增量来增强PMF。</li></ul><h3 id="神经架构搜索nas">神经架构搜索（NAS）</h3><ul><li><strong>PMF结构搜索</strong>：尽管PMF在未经过深入超参数调优的情况下表现良好，但对于不同的任务和数据分布，最优的融合结构和提示长度设置可能有所不同。通过AutoFormer自动搜索融合结构，减轻了寻找最佳融合结构的工作量，NAS应用的PMF在三个数据集上的性能优于常规PMF，同时增加了训练内存使用量。</li></ul><h3 id="总结">总结</h3><p>这些补充内容展示了PMF在多模态学习任务中的高效性、灵活性和可调整性。通过详细的消融研究和模块化设计，PMF能够在保持高性能的同时，有效管理资源消耗。此外，通过利用NAS，PMF能够进一步优化其结构，以适应各种复杂的实际应用场景。</p>]]></content>
    
    
    <categories>
      
      <category>Paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>多模态</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>持续学习论文阅读</title>
    <link href="/2024/07/05/Paper/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2024/07/05/Paper/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="综述">综述</h2><h3 id="continual-learning-scenarios">Continual Learning Scenarios</h3><h4 id="instance-incremental-learning-iil">Instance-Incremental Learning(IIL)</h4><ul><li><strong>定义</strong>: 所有训练样本属于相同任务，以批次到达。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141840849.png" /></li></ul><h4 id="domain-incremental-learning-dil">Domain-Incremental Learning(DIL)</h4><ul><li><strong>定义</strong>:任务具有相同的数据标签空间但不同的输入分布。任务标识不是必须的。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141840293.png"alt="image.png" /></li></ul><h4 id="task-incremental-learning-til">Task-Incremental Learning(TIL)</h4><ul><li><strong>定义</strong>:任务具有不相交的数据标签空间。在训练和测试中提供任务标识。</li><li><strong>训练</strong>: {Dt, t}t∈T；p(Xi) ̸= p(Xj) 且 Yi ∩ Yj = ∅对于 i ̸= j</li><li><strong>测试</strong>: {p(Xt)}t∈T；提供任务标识</li></ul><h4 id="class-incremental-learning-cil">Class-Incremental Learning(CIL)</h4><ul><li><strong>定义</strong>:任务具有不相交的数据标签空间。仅在训练中提供任务标识。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141840752.png"alt="image.png" /></li></ul><h4 id="task-free-continual-learning-tfcl">Task-Free Continual Learning(TFCL)</h4><ul><li><strong>定义</strong>:任务具有不相交的数据标签空间。在训练和测试中均不提供任务标识。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141841203.png" /></li></ul><h4 id="online-continual-learning-ocl">Online Continual Learning(OCL)</h4><ul><li><strong>定义</strong>:任务具有不相交的数据标签空间。每个任务的训练样本以一次性数据流形式到达。<imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141842687.png"alt="image.png" /></li></ul><h4 id="blurred-boundary-continual-learning-bbcl">Blurred BoundaryContinual Learning (BBCL)</h4><ul><li><strong>定义</strong>: 任务边界模糊，具有不同但重叠的数据标签空间。<imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141842009.png"alt="image.png" /></li></ul><h4 id="continual-pre-training-cpt">Continual Pre-training (CPT)</h4><ul><li><strong>定义</strong>:预训练数据按顺序到达。目标是改进知识传递到下游任务。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407141842218.png"alt="image.png" /></li></ul><h4 id="其他学习场景">其他学习场景</h4><p>除非特别说明，每个任务通常假定有足够数量的标记训练样本，即监督连续学习。根据每个Dt 中提供的 Xt 和Yt，连续学习进一步扩展到零样本学习、少样本学习、半监督学习、开放世界学习（识别未知类别并整合其标签）和无监督/自监督学习场景。此外，还考虑并纳入了其他实际挑战，例如多标签、噪声标签、层次粒度和子群体、任务相似性的混合、长尾分布、域对齐、域迁移、随时推理、新类别发现、多模态等。一些最新的工作集中在这些场景的各种组合上，以更好地模拟现实世界的复杂性。</p><h3 id="连续学习的性能评估">连续学习的性能评估</h3><p>通常，连续学习的性能可以从三个方面进行评估：已经学习任务的总体性能、旧任务的记忆稳定性和新任务的学习可塑性。以下是常见的评估指标，使用分类作为示例。</p><h4 id="总体性能">总体性能</h4><p>总体性能通常通过平均准确率 (AA) 和平均增量准确率 (AIA) 来评估。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142104562.png"alt="image.png" /></p><h4 id="记忆稳定性">记忆稳定性</h4><p>记忆稳定性可以通过遗忘度量 (FM) 和向后传递 (BWT) 来评估。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142105409.png"alt="image.png" /></p><h4 id="学习可塑性">学习可塑性</h4><p>学习可塑性可以通过不易学习度量 (IM) 和向前传递 (FWT) 来评估。 <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142105862.png"alt="image.png" /></p><h4 id="其他评估指标">其他评估指标</h4><p><imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142105799.png"alt="image.png" /> ### 理论基础</p><p>在本节中，我们总结了关于连续学习的理论工作，涉及稳定性-可塑性权衡和可推广性分析，并将其与各种连续学习方法的动机联系起来。</p><h4 id="稳定性-可塑性权衡">稳定性-可塑性权衡</h4><p><imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142106342.png"alt="image.png" /> <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142106952.png"alt="image.png" /> <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142107288.png"alt="image.png" /> <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142107435.png"alt="image.png" /> <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142108870.png"alt="image.png" /> <imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142108724.png"alt="image.png" /></p><h3 id="可推广性分析">可推广性分析</h3><p>当前的理论工作主要在增量任务的训练集上进行，假设它们的测试集遵循相似的分布，并且候选解决方案具有相似的可推广性。然而，由于学习多个任务的目标通常是高度非凸的，在每个训练集上表现相似但在测试集上具有显著不同可推广性的局部最优解很多[313],[443]。对于连续学习，理想的解决方案不仅需要从训练集到测试集的任务内可推广性，还需要适应其分布增量变化的任务间可推广性。</p><p>图2显示了连续学习的关键因素分析。a和b中，连续学习需要在学习可塑性和记忆稳定性之间保持适当的平衡，其中任一方面的过剩都会影响总体性能（改编自[443]）。c和d中，当收敛的损失景观更平坦且观察到的数据分布更相似时，适当平衡的解决方案可以更好地推广到任务序列（改编自[443]）。e中，参数空间的结构决定了找到理想解决方案的复杂性和可能性（改编自[225]）。黄色区域表示单个任务共享的可行参数空间，随着更多增量任务的引入，该空间往往变窄且不规则。<imgsrc="https://picoflmq.oss-cn-beijing.aliyuncs.com/typora/202407142109949.png"alt="image.png" /></p><p>直观地，收敛到具有更平坦损失景观的局部极小值对适度的参数变化不太敏感，因此有利于旧任务和新任务（见图2，c）。为了找到这样的平坦极小值，连续学习中有三种广泛使用的策略。</p><p>第一种来源于其定义，即平坦性指标。具体来说，可以将 <spanclass="math inline">\(\ell_t(\theta; D_t)\)</span>的最小化替换为鲁棒的任务特定损失 <spanclass="math inline">\(\ell_{tb}(\theta; D_t) := \max_{\|\delta\|\leq b}\ell_t(\theta + \delta;D_t)\)</span>，因此获得的解不仅在特定点而且在其邻域内具有“半径” <spanclass="math inline">\(b\)</span> 的低误差。然而，由于 <spanclass="math inline">\(\theta\)</span> 的高维性，<spanclass="math inline">\(\ell_{tb}(\theta; D_t)\)</span>的计算无法覆盖所有可能的 <spanclass="math inline">\(\delta\)</span>，只能覆盖少数方向[387]，类似于公式(19)中计算海森矩阵的复杂性问题。替代方法包括使用海森矩阵的近似[90]，[313]或仅沿前向和后向参数变化的轨迹计算 <spanclass="math inline">\(\delta\)</span>[58]，[174]，[183]，[300]，[312]。</p><p>第二种是在模式连通性的限制下，通过构建集成模型来操作损失景观，即沿低误差路径在参数或函数空间中集成多个极小值，因为连接它们可以确保该路径上的平坦性[60]，[131]，[183]，[312]，[443]，[462]。这两种策略与基于优化的方法密切相关。</p><p>第三种是获得分布良好的表示，这些表示在函数空间中的分布差异上更具鲁棒性，例如通过使用预训练[168]，[300]，[360]，更宽的网络架构[309]，[359]，[360]和自监督学习[57]，[168]，[286]，[343]。观察到对大规模预训练和自监督学习的高度关注，我们将这一方向归为第4.4节中的基于表示的方法。</p><p>还有许多其他因素对连续学习的性能很重要。如公式(20)所示，性能退化的上限还取决于每个任务的经验最优解<span class="math inline">\(\theta^*_t = \arg \min_\theta \ell_t(\theta;D_t)\)</span>的差异，即任务分布的差异（见图2，d），这一点通过遗忘-泛化权衡的理论分析[358]和泛化误差的PAC-Bayes界[338]，[443]进一步验证。因此，如何利用任务相似性与连续学习的性能直接相关。每个任务的泛化误差可以通过协同任务提高，但在竞争任务中恶化[361]，其中在共享解决方案中同等学习所有任务往往会在性能上妥协每个任务[361]，[443]。</p><p>另一方面，当模型参数不被所有任务共享（例如，使用多头输出层）时，任务相似性对连续学习的影响将会复杂。一些使用神经切线核（NTK）的理论研究[33]，[95]，[207]，[243]表明，任务相似性的增加可能导致更多的遗忘。由于输出头是独立的，因此更难区分两个相似的解决方案[207]，[243]。具体来说，在NTK体制下，从第<span class="math inline">\(t\)</span> 个任务到第 <spanclass="math inline">\(k\)</span> 个任务，旧任务的遗忘有界于： <spanclass="math display">\[\|p(D_k |\theta^*_k) - p(D_k|\theta^*_t )\|_F^2 \leq \sigma^2_{t,|rep|}+ \sum_{i=t+1}^{k} \left( \Theta_{t \to S(i,|rep|)} \right)^2\|\text{RES}_i\|_2^2。\]</span> <span class="math inline">\(\Theta_{t \to k}\)</span>是一个对角矩阵，其中每个对角元素 <spanclass="math inline">\(\cos(\theta_{t,k})_r\)</span> 是特征空间中第 <spanclass="math inline">\(t\)</span> 和第 <spanclass="math inline">\(k\)</span> 个任务之间第 <spanclass="math inline">\(r\)</span> 个主角的余弦。 <spanclass="math inline">\(\sigma_{t,\cdot}\)</span> 是第 <spanclass="math inline">\(t\)</span> 个任务的 <spanclass="math inline">\(\cdot\)</span> 的奇异值。 <spanclass="math inline">\(\text{RES}_i\)</span> 是需要学习的旋转残差， <spanclass="math inline">\(S(i, \cdot)\)</span> 表示直到第 <spanclass="math inline">\(i\)</span> 个任务的残差子空间的阶数。 <spanclass="math inline">\(|rep|\)</span>是重放数据的样本数。任务相似性的复杂影响表明了模型架构在协调任务共享和任务特定组件方面的重要性。</p><p>此外，找到连续学习理想解决方案的复杂性在很大程度上取决于参数空间的结构。用共享解决方案学习所有增量任务等同于在受限参数空间中学习每个新任务，以防止所有旧任务的性能退化。这样的经典连续学习问题已被证明在一般情况下是NP难的[225]，因为随着更多任务的引入，可行参数空间往往变得狭窄且不规则，因此难以识别（见图2，e）。这一具有挑战性的问题可以通过重放代表性的旧训练样本[225]，将可行参数空间限制在超矩形[459]，或使用多个连续学习模型替代单个参数空间的模型架构（例如，使用多个连续学习模型）来缓解[96]，[361]，[443]。</p><p>为了协调连续学习中的重要因素，最近的工作提出了一种类似的学习和遗忘的广义界形式。例如，在假设所有任务共享具有统一收敛性的全局极小化器（即公式(20)中对于<span class="math inline">\(\forall t = 1, \cdot \cdot \cdot,k\)</span>，<span class="math inline">\(\lambda_{\max i} =\lambda\)</span>）下的理想连续学习者[337]，其泛化界为： <spanclass="math display">\[c^*_t \leq \mathbb{E}_{D_t \sim D_t} \ell_t(\theta; D_t) \leq c^*_t +\zeta(N_t, \delta), \forall t = 1, \cdot \cdot \cdot, k,\]</span> 其中 <span class="math inline">\(c^*_t = \ell_t(\theta^*_t;D_t)\)</span> 是第 <span class="math inline">\(t\)</span>个任务的最小损失，<span class="math inline">\(\theta\)</span>是通过经验风险最小化连续学习 <span class="math inline">\(1 : k\)</span>任务的全局解。 $= O( )，并且 <span class="math inline">\(\|\theta\|_2\leq B\)</span>)。</p><p>考虑到许多不同任务的共享参数空间可能是一个空集（见图2，e），即 <spanclass="math inline">\(\bigcup_{t=1}^{k} \theta_t =\emptyset\)</span>，泛化界通过假设 <spanclass="math inline">\(K\)</span> 个参数空间（通常 <spanclass="math inline">\(K \geq1\)</span>）来捕获所有任务而进一步细化[442]，[443]。对于新旧任务的泛化误差：<span class="math display">\[\mathbb{E}_{D_t \sim D_t} \ell_t(\theta; D_t) \leq c^*_t +R\left(\sum_{i=1}^{t-1} \ell^b_i\right) + \sum_{i=1}^{t-1}\text{Div}(D_i, D_t) + \zeta\left(\sum_{i=1}^{t-1} N_i, K/\delta\right),\]</span> <span class="math display">\[\sum_{i=1}^{t-1} \mathbb{E}_{D_i \sim D_i} \ell_i(\theta; D_i) \leq\sum_{i=1}^{t-1} c^*_i + R(\ell^b) + \sum_{i=1}^{t-1} \text{Div}(D_t,D_i) + \zeta(N_t, K/\delta)，\]</span> 其中 <span class="math inline">\(R(\cdot)\)</span> 和 <spanclass="math inline">\(\text{Div}\)</span>分别是损失平坦性和任务差异的函数。 <span class="math inline">\(\delta,\theta 和 c^*_t\)</span> 的定义与公式(22) 相同。</p><p>这些理论工作表明，理想的连续学习解决方案应提供适当的稳定性-可塑性权衡和足够的任务内/任务间可推广性，这激发了下一节中详细介绍的各种代表性方法。</p><h3 id="方法">方法</h3><p>在本节中，我们详细介绍了代表性连续学习方法的分类（见图3和图1，c），深入分析了它们的主要动机、典型实现和经验特性。</p><h4 id="基于正则化的方法">基于正则化的方法</h4><p>这一方向的特点是通过添加显式的正则化项来平衡旧任务和新任务，通常需要存储旧模型的冻结副本以供参考（见图4）。根据正则化的目标，这些方法可以分为两个子方向。</p><h5 id="权重正则化">权重正则化</h5><p>权重正则化通过选择性地正则化网络参数的变化来实现。一个典型的实现是在损失函数中添加二次惩罚，根据每个参数对执行旧任务的贡献或“重要性”来惩罚其变化，例如公式(12)，这种形式最初源自贝叶斯框架下后验的在线拉普拉斯近似。重要性可以通过费舍尔信息矩阵（FIM）计算，如EWC[222]和一些更先进的版本[371]，[382]。同时，许多工作致力于设计更好的重要性度量。SI[497]在线近似每个参数的重要性，通过其对总损失变化的贡献和整个训练轨迹上的更新长度来计算。MAS[12]基于对参数变化的预测结果敏感性累积重要性度量，这既是在线的也是无监督的。RWalk[63] 结合了SI [497] 和 EWC [222]的正则化项以整合它们的优势。有趣的是，这些重要性度量被证明都相当于FIM的近似[34]，尽管它们的动机不同。</p><p>图4.基于正则化的方法。该方向的特点是通过添加显式的正则化项来模拟旧模型的参数（权重正则化）或行为（功能正则化）。</p><p>还有一些工作改进了二次惩罚的实现。由于EWC中FIM的对角近似可能会丢失旧任务的信息，R-EWC[272] 对参数空间进行了因子化旋转以对角化FIM。XK-FAC [239]在近似FIM时进一步考虑了样本间的关系，以更好地适应批量归一化。观察到参数变化对旧任务的不对称影响，ALASSO[329]设计了一个不对称的二次惩罚，其中一侧被高估。与在旧模型约束下学习每个任务相比，这通常会加剧不易学习性，通过分别获取新任务解决方案并使用旧模型重新归一化的扩展-重新归一化过程显示出更好的稳定性-可塑性权衡[240]，[245]，[258]，[382]，[441]。</p><p>IMM [245]是一个早期尝试，通过增量匹配旧任务和新任务后验分布的时刻，即它们解决方案的加权平均。ResCL[240] 扩展了这一思想，具有可学习的组合系数。P&amp;C [382]通过额外的网络单独学习每个任务，然后使用EWC的广义版本将其回流到旧模型中。AFEC[441] 引入了遗忘率，以消除公式(8)中原始后验 (p(|D_{1:k-1}))的潜在负迁移，并推导出二次项以惩罚网络参数 ()与旧任务和新任务解决方案的差异。为了可靠地平均旧任务和新任务解决方案，通过在低误差路径上约束它们来构建线性连接器[258]。</p><p>其他针对网络本身的正则化形式也属于这一子方向。如前所述，后验分布的在线变分推理可以作为参数变化的隐式正则化，例如VCL [318], [410], NVCL [420], CLAW [7], GVCL [280], KCL [91] 和 VAR-GPs[206]。而不是巩固参数，NPC [325]估计每个神经元的重要性，并选择性地降低其学习率。UCL [9] 和 AGS-CL [196]冻结连接重要神经元的参数，相当于权重正则化的硬版本。</p><h5 id="功能正则化">功能正则化</h5><p>功能正则化针对预测函数的中间或最终输出。该策略通常采用先前学习的模型作为教师，当前训练的模型作为学生，同时实施知识蒸馏（KD）[141]以减轻灾难性遗忘。理想情况下，KD的目标应该是所有旧训练样本，但在连续学习中这是不可用的。替代方案可以是新训练样本[93]，[181]，[255]，[362]，一小部分旧训练样本[53]，[102]，[165]，[365]，外部未标记数据[241]，生成数据[464]，[500]等，存在不同程度的分布偏移。</p><p>作为开创性工作，LwF [255] 和 LwF.MC [365]学习新训练样本，同时使用其来自旧任务输出头的预测来计算蒸馏损失。LwM [93]利用新训练样本的注意力图进行 KD。EBLL [362]学习任务特定的自动编码器并防止特征重构的变化。GD [241]进一步从野外大量未标记数据中蒸馏知识。当旧训练样本被忠实恢复时，功能正则化的潜力可以得到极大释放。因此，功能正则化通常与重放一些旧训练样本结合使用，如iCaRL [365]，EEIL [53]，LUCIR [165]，PODNet [102]，DER [46]等，在第4.2节中讨论。此外，功能空间上的顺序贝叶斯推理可以视为功能正则化的一种形式，通常需要存储一些旧的训练样本（文献中称为“核心集”），如FRCL [417], FROMP [326] 和 S-FSVI [378]。</p><p>对于条件生成，先前学习条件的生成数据及其输出值在旧模型和新模型之间保持一致性进行正则化，如MeRGANs [464]，DRI [452] 和 LifelongGAN [500]。以下是调整了标题级数的内容，使其与前面的内容对应：</p><h3 id="基于重放的方法">基于重放的方法</h3><p>我们将近似和恢复旧数据分布的方法归入这一类（见图5）。根据重放内容的不同，这些方法可以进一步分为三个子方向，每个子方向都有其目标和挑战。</p><h4 id="经验重放">经验重放</h4><p>经验重放通常在一个小内存缓冲区中存储一些旧的训练样本。由于存储空间极其有限，关键挑战在于如何构建和利用内存缓冲区。</p><p><strong>构建</strong>方面，保存的旧训练样本应该经过精心选择、压缩、增强和更新，以便自适应地恢复过去的信息。早期工作采用固定原则进行样本选择。例如，ReservoirSampling [67], [369], [430]随机保留从每个训练批次中获得的固定数量的旧训练样本。Ring Buffer[281]进一步确保每个类别的旧训练样本数量相等。Mean-of-Feature[365]选择最接近每个类别特征均值的等数量旧训练样本。还有许多其他固定原则，例如k-means [67]，平面距离 [369] 和熵 [369]，但表现一般[67], [369]。</p><p>更高级的策略通常是基于梯度或可优化的，通过最大化参数梯度方面的样本多样性（GSS[16]），带有基数约束的对应任务的性能（CCBO[40]），小批量梯度相似性和跨批次梯度多样性（OCS[491]），优化潜在决策边界的能力（ASER [391]），对扰动的鲁棒性多样性（RM[27]），当前参数下旧训练样本梯度的相似性（GCR[418]）等。为了提高存储效率，AQM[48]基于VQ-VAE框架[424]执行在线连续压缩并保存压缩数据进行重放。MRDC[444]将数据压缩的经验重放公式化为行列式点过程（DPPs）[231]，并推导出在线确定适当压缩率的高效方法。RM[27]采用传统和基于标签混合的数据增强策略，以提高旧训练样本的多样性。RAR[234]在遗忘边界附近合成对抗样本，并进行MixUp[504]进行数据增强。低存储成本的辅助信息，如类别统计（IL2M [31]，SNCL[139]）和注意力图（RRR [110]，EPR[380]），可以进一步结合以保持旧知识。此外，旧训练样本可以不断修改以适应增量变化，例如通过使它们更具代表性（Mnemonics[276]）或更具挑战性（GMED [192]）。</p><p><strong>利用</strong>方面，经验重放需要充分利用内存缓冲区以恢复过去的信息。有许多不同的实现，紧密相关于其他连续学习策略。首先，可以约束优化中旧训练样本的效果以避免灾难性遗忘并促进知识迁移。例如，GEM[281]为每个任务基于旧训练样本构建个体约束，以确保它们的损失不增加。A-GEM[66]用所有任务的全局损失代替个体约束，以提高训练效率。LOGD[411]将每个任务的梯度分解为任务共享和任务特定的组件，以利用任务间信息。为了在干扰-迁移（即遗忘-泛化）[369]（即遗忘-泛化[358]）中取得良好的权衡，MER[369]采用元学习进行梯度对齐。BCL[358]明确追求旧训练样本和新训练样本的成本的鞍点。MetaSP[407]利用样本影响的帕累托最优来控制模型和存储更新。为了选择性利用内存缓冲区，MIR[13]优先考虑更多遗忘的旧训练样本，而HAL[64]将它们用作“锚点”并稳定其预测。</p><p>另一方面，经验重放可以自然地与知识蒸馏（KD）结合，额外结合旧模型的过去信息。iCaRL[365]和EEIL[53]是两个早期的工作，在旧训练样本和新训练样本上执行KD。一些后续改进专注于经验重放中的不同问题。为了缓解有限旧训练样本的数据不平衡，LUCIR[165]鼓励旧模型和新模型的特征方向相似，同时执行最后一层的余弦归一化和当前任务的难负样本挖掘。BiC[468]和WA[512]将此问题归因于最后一个全连接层的偏差，并通过学习带有平衡验证集的偏差校正层[468]或归一化输出权重[512]来解决。SS-IL[10]在最后一层采用分离的softmax并执行逐任务KD以减轻偏差。DRI[452]训练生成模型以补充旧训练样本的额外生成数据。为了减轻剧烈的表示变化，PODNet[102]采用空间蒸馏损失以保持整个模型的表示。Co2L[57]引入自监督蒸馏损失，以获得对灾难性遗忘具有鲁棒性的表示。GeoDL[396]沿着连接旧特征空间和新特征空间的低维投影路径执行KD，以在它们之间实现平滑过渡。ELI[193]学习旧模型和新模型的能量流形，以重新调整表示变化以优化增量任务。为了充分利用过去的信息，AU[236]在蒸馏损失中结合了不确定性和自注意力，而CSC[21]则额外利用特征空间的结构。DDE[172]从新训练样本的特征中提炼碰撞效应，这在因果上等效于重放更多旧训练样本。TAMiL[36]在特征空间中添加任务特定的注意力并执行一致性正则化，以更好地保持任务相关信息。为了进一步增强学习可塑性，D+R[164]从一个额外模型中执行KD，该模型专用于每个新任务。FOSTER[435]动态扩展新模块以适应旧模型的残差，然后将它们蒸馏到单一模型中。此外，权重正则化方法可以与经验重放结合，以实现更好的性能和通用性[63]，[441]。</p><p>值得注意的是，经验重放的优点和潜在局限性仍然很大程度上是开放的。除了直观的旧任务低损失区域的好处外[428]，理论分析表明其对解决最优连续学习的NP难问题的贡献[225]。然而，它有可能过拟合于保存在内存缓冲区中的少量旧训练样本，这可能影响可推广性[428]。为了缓解过拟合，LiDER[39]从对抗鲁棒性中获得灵感，强制模型对输入的Lipschitz连续性。MOCA[493]扩大表示的变化，以防止旧表示在其空间中收缩。有趣的是，几个简单的经验重放基线可以实现相当的性能。DER/DER++[46]和X-DER[41]保存旧训练样本及其logits，并在优化轨迹中执行logit匹配。GDumb[348]贪婪地在内存缓冲区中收集传入的训练样本，然后从头开始使用它们训练模型以进行测试。这些工作可以作为该子方向中更高级策略的评估标准。</p><h4 id="生成重放">生成重放</h4><p>生成重放或伪复习通常需要训练一个额外的生成模型以重放生成的数据。这与生成模型本身的连续学习密切相关，因为它们也需要增量更新。DGR[392]提供了一个初始框架，其中每个生成任务的学习伴随着从旧生成模型中采样生成数据进行重放，以继承先前学习的知识。MeRGAN[464]进一步采用重放对齐，通过相同随机噪声采样的生成数据在旧生成模型和新生成模型之间强制一致性，类似于功能正则化的作用。此外，其他连续学习策略可以结合到生成重放中。权重正则化[318],[383], [438], [440]和经验重放[158],[440]已被证明在减轻生成模型的灾难性遗忘方面是有效的。DGMa/DGMw[322]采用二进制掩码分配任务特定参数以克服任务间干扰，并采用可扩展网络以确保可扩展性。如果预训练可用，它可以为连续学习提供相对稳定和强大的参考模型。例如，FearNet[211]和ILCAN[472]额外保存从预训练特征提取器获取的旧特征的统计信息，而GAN-Memory</p><p>[81]则不断调整带有任务特定参数的预训练生成模型。</p><p>用于伪复习的生成模型可以是多种类型的，例如生成对抗网络（GANs）和（变分）自动编码器（VAE）。大多数最先进的方法都集中在GANs上，以享受其在细粒度生成方面的优势，但通常在连续学习中遭受标签不一致的困扰[25],[322]。相比之下，基于自动编码器的策略，例如FearNet [211]，SRM[370]，CLEER [375]，EEC [25]，GMR [342]和Flashcards[140]，可以显式控制生成数据的标签，尽管粒度相对模糊。L-VAEGAN[483]则采用混合模型来同时实现高质量生成和精确推理。然而，由于生成模型的连续学习极其困难且需要大量资源开销，生成重放通常限于相对简单的数据集[422],[438]。</p><h4 id="特征重放">特征重放</h4><p>一种替代方法是将生成重放的目标从数据级别转换到特征级别，这可以大大减少条件生成的复杂性，并更充分地利用语义信息。例如，GFR[273]训练条件GANs在特征提取器之后重放生成的特征。BI-R[422]在标准VAE中结合上下文调制的反馈连接，以重放内部表示。实际上，维护特征级别而非数据级别的分布在效率和隐私方面具有许多优势。我们将这一子方向称为特征重放。然而，一个核心挑战是特征提取器的顺序更新引起的表示变化，这反映了特征级别的灾难性遗忘。为了解决这个问题，GFR[273]，FA [181] 和 DSR [525] 在旧模型和新模型之间执行特征蒸馏。IL2M[31]和SNCL [139]基于经验重放恢复特征表示的统计信息（例如均值和协方差）。RER[419]显式估计表示变化以更新保存的旧特征。REMIND [156] 和 ACAE-REMIND[437]则固定特征提取器的早期层并重构中间表示以更新后续层。FeTrIL[341]采用从初始任务中学习的固定特征提取器，并在之后重放生成的特征。对于从头开始的连续学习，表示的变化通常是剧烈的，而稳定特征提取器可能会干扰适应新表示。相比之下，使用强预训练可以提供对下游任务具有鲁棒性且在连续学习中相对稳定的表示。一项经验研究[321]系统地研究了大规模预训练的连续学习中特征重放。关于这一主题的更深入讨论将在第4.4节中提出。</p><h3 id="基于优化的方法">基于优化的方法</h3><p>连续学习不仅可以通过向损失函数添加额外项（例如正则化和重放）来实现，还可以通过显式设计和操作优化程序来实现。一个典型的想法是执行梯度投影。一些基于重放的方法，如GEM [281]、A-GEM [66]、LOGD [411] 和 MER[369]，通过使用一些旧训练样本来保持先前输入空间和梯度空间，限制参数更新以与经验重放方向对齐。与保存旧训练样本不同，OWM[496] 和 AOP [146] 修改参数更新，使其与先前输入空间的正交方向对齐。OGD[115] 保持旧梯度方向并使当前梯度方向与其正交。Orthog-Subspace [65]通过正交低秩向量子空间执行连续学习，使不同任务的梯度彼此正交。GPM [380]维护对旧任务重要的梯度子空间（即核心梯度空间的基）以进行参数更新的正交投影。CGP[68] 从各个类中计算这种梯度子空间，以进一步减轻类间干扰。FS-DGPM [90]动态释放 GPM [380]的不重要基，以提高学习可塑性并鼓励收敛到平坦的损失景观。CUBER [261]选择性地投影梯度以更新与当前任务正相关的旧任务知识。TRGP [260]通过将梯度投影到先前输入子空间的范数上定义“信任区域”，从而选择性地重用旧任务的冻结权重。Adam-NSCL[448]则将候选参数更新投影到当前通过旧任务无中心特征协方差近似的零空间，而AdNS [227] 则考虑了先前和当前零空间的共享部分。NCL [202]统一了贝叶斯权重正则化和梯度投影，鼓励参数更新在旧任务的零空间中，同时收敛到贝叶斯近似后验的最大值。在贝叶斯权重正则化的二次惩罚上限下，RGO[266]通过递归优化程序修改梯度方向以获得最优解。因此，正则化和重放最终是通过修正当前梯度方向实现的，而梯度投影则是显式地在参数更新中进行类似的修改。</p><p>图6.基于优化的方法。该方向的特点是显式设计和操作优化程序，例如参考旧任务的梯度空间或输入空间进行梯度投影（改编自[115]），在内循环中对顺序到达的任务进行元学习，以及利用模式连通性和损失景观中的平坦极小值（改编自[258],[312]）。θ∗A、θ∗B 和 θ∗A,B 分别是任务A、任务B 和两者的理想解决方案。</p><p>另一个有吸引力的想法是元学习或学习如何学习连续学习，它试图为各种场景获得数据驱动的归纳偏置，而不是手动设计[150]。OML[186]提供了一种元训练策略，对顺序到达的输入进行在线更新，并最小化它们的干扰，从而自然获得适合连续学习的稀疏表示。ANML[30]通过元学习一个上下文依赖的门控函数来选择性激活与增量任务相关的神经元，扩展了这一思想。AIM[238] 学习专家混合体，以 OML [186] 或 ANML [30]的表示进行预测，进一步在架构层面稀疏化表示。同时，元学习可以与经验重放结合，以更好地利用旧的和新的训练样本。例如，MER[369] 使它们的梯度方向对齐，而 iTAML [357]应用元更新规则以保持它们的平衡。在经验重放的帮助下，La-MAML [148]以自适应调整的学习率在线优化 OML [186] 目标。OSAKA [49]提出了一种混合目标，结合知识积累和快速适应，通过元训练获得良好的初始化，然后将增量任务的知识纳入初始化。元学习还可以用于优化专门的架构。MERLIN[223]在每个任务的表示下巩固模型参数的元分布，允许采样任务特定的模型并集成它们进行推理。类似地，PR[161] 采用贝叶斯策略学习具有共享元模型的任务特定后验。MARK [176]维护一组共享权重，通过元学习进行增量更新，并选择性掩码以解决特定任务。ARI[446]将对抗攻击与经验重放结合，获得任务特定模型，然后通过元训练将它们融合在一起。</p><p>此外，还有一些其他工作从损失景观的角度优化过程。例如，不是专门设计一个算法，Stable-SGD[313] 通过调整训练方案中的因素（如 dropout、学习率衰减和批量大小），使SGD 找到一个平坦的局部极小值。MC-SGD [312]实验证明，多任务学习（即联合训练所有增量任务）和连续学习获得的局部极小值可以通过低误差的线性路径连接起来，并应用经验重放沿着该路径找到更好的解决方案。LinearConnector [258] 采用 Adam-NSCL [448]和特征蒸馏，获得通过低误差线性路径连接的旧任务和新任务的各自解决方案，然后进行线性平均。此外，无监督/自监督学习（比传统的监督学习）[127],[168], [286] 和大规模预训练（比随机初始化）[84], [168], [300], [360],[467]被证明在减轻灾难性遗忘方面更少。经验上，两者都归因于获得更鲁棒（例如正交、稀疏和均匀分散）的表示[168],[286], [360], [389]，并收敛到更宽的损失盆地[152], [168], [286], [300],[317]，这表明表示、参数和任务特定误差的敏感性之间可能存在潜在联系。许多努力寻求在连续学习中利用这些优势，正如我们接下来讨论的那样。以下是调整了标题级数的内容，使其与前面的内容对应：</p><h3 id="基于表示的方法">基于表示的方法</h3><p>我们将创建和利用表示优势的连续学习方法归为这一类。除了早期通过元训练获取稀疏表示的工作[186]，最近的研究尝试结合自监督学习（SSL）[127],[286], [343] 和大规模预训练 [300], [389], [467]的优势，以改善初始化和连续学习中的表示。需要注意的是，这两种策略密切相关，因为预训练数据通常数量巨大且没有显式标签，而SSL本身的性能主要通过在下游任务（或任务序列）上微调来评估。以下我们将讨论代表性的子方向。</p><h4 id="自监督学习">自监督学习</h4><p>自监督学习（基本上使用对比损失）用于连续学习。观察到自监督表示对灾难性遗忘更具鲁棒性，LUMP[286] 通过在旧任务和新任务实例之间插值获得进一步改进。MinRed [349]通过去相关存储的旧训练样本来进一步促进经验重放的多样性。CaSSLe [118]通过将表示的当前状态映射到其之前状态，将自监督损失转换为蒸馏策略。Co2L[57]采用监督对比损失来学习每个任务，并采用自监督损失在旧模型和新模型之间蒸馏知识。DualNet[343]使用监督损失训练一个快速学习者，并使用自监督损失训练一个慢速学习者，后者帮助前者获取可推广的表示。</p><h4 id="预训练">预训练</h4><p>预训练用于下游连续学习。若干实证研究表明，预训练不仅带来了强大的知识转移，还提高了对灾难性遗忘的鲁棒性，从而明显有利于下游连续学习[127],[300], [321], [360]。特别是，当使用更大规模的数据[321],[360]，更大规模的模型[360] 和对比损失[84], [127]进行预训练时，下游连续学习的收益更加明显。然而，一个关键挑战是需要自适应地利用预训练知识以适应当前任务，同时保持对未来任务的可推广性。对于这个问题的各种策略取决于预训练的骨干网络是否固定。</p><p>图7.基于表示的方法。该方向的特点是创建和利用表示的优势进行连续学习，例如通过使用自监督学习和预训练。特别是，上游预训练和下游微调都需要进行连续学习，而预训练表示在学习特定下游任务时可选择性固定。</p><h4 id="适应固定的骨干网络">适应固定的骨干网络</h4><p>Side-Tuning [506] 和 DLCFT [394]训练一个轻量级网络与骨干网络并行，并线性融合它们的输出。TwF [42]也训练一个兄弟网络，但在层级方式上从骨干网络中蒸馏知识。GAN-Memory [81]利用 FiLM [339] 和 AdaFM [515]为预训练生成模型的每一层学习任务特定参数，而 ADA [113] 采用 Adapters[166]与知识蒸馏来调整预训练转换器。最近的基于提示的方法通过少量提示参数来指导预训练转换器的表示。此类方法通常涉及构建任务自适应提示和推理合适提示以进行测试，通过探索提示架构来适应任务共享和任务特定知识。代表性策略包括从提示池中选择最相关的提示（L2P[458]），使用注意力因子对提示池进行加权求和（CODAPrompt[400]），使用明确的任务共享和任务特定提示（DualPrompt[457]）或仅任务特定提示（S-Prompts [450], HiDe-Prompt[439]），任务特定提示的逐步扩展（Progressive Prompts[364]）等。此外，通过保存原型，在骨干网络后附加最近类均值（NCM）分类器已被证明是一个强大的基线[185],[332]，可以通过传递学习技术（如 FiLM 适配器[327]）进一步增强。</p><h4 id="优化可更新的骨干网络">优化可更新的骨干网络</h4><p>F2M [387]在预训练阶段搜索平坦的局部极小值，然后在平坦区域内学习增量任务。CwD[389] 规范初始阶段的表示均匀散布，可以经验性地模拟联合训练的表示。SAM[122], [300] 鼓励通过优化平坦度指标在下游连续学习中找到宽广的盆地。SLCA[503]观察到缓慢微调预训练转换器的骨干可以在连续学习中取得出色表现，并进一步保留原型统计以纠正输出层。</p><h4 id="连续预训练cpt或连续元训练">连续预训练（CPT）或连续元训练</h4><p>由于预训练所需的数据量通常以增量方式收集，执行上游连续学习以提高下游性能尤为重要。例如，一项实证研究发现，自监督预训练比监督协议更适合视觉-语言模型的连续学习[82]，这与仅视觉任务的结果一致[168]。由于文本通常比图像更高效，IncCLIP[478] 根据图像重放生成的难负样本文本，并执行多模态知识蒸馏以更新CLIP[355]。对于语言模型的CPT，ECONET [151]设计了一个带有生成重放的自监督框架。同时，连续元训练需要解决类似的问题，即基础类的预训练知识以增量方式丰富和适应。IDA[268] 施加新旧模型相对于旧中心的判别对齐，并使嵌入自由适应新任务。ORDER[456]采用无标签的OOD数据与经验重放和特征重放相结合，以应对任务间的巨大差异。以下是调整了标题级数的内容，使其与前面的内容对应：</p><h3 id="基于架构的方法">基于架构的方法</h3><p>上述策略主要集中于使用共享参数集（即单个模型和一个参数空间）来学习所有增量任务，这是任务间干扰的主要原因。相反，构建任务特定的参数可以明确解决这个问题。之前的工作通常将这一类别分为参数隔离和动态架构，取决于网络架构是否固定。在这里，我们集中讨论实现任务特定参数的方法，将上述概念扩展到参数分配、模型分解和模块化网络（见图8）。</p><h4 id="参数分配">参数分配</h4><p>参数分配特点是通过网络为每个任务分配一个独立的参数子空间，架构可以是固定的也可以是动态的。在固定的网络架构中，Piggyback[290], HAT [384], SupSup [463], MEAT [477], WSN [199] 和 H2 [190]通过优化二进制掩码来选择每个任务的专用神经元或参数，同时冻结旧任务的掩码区域以防止灾难性遗忘。PackNet[291], UCL [9], CLNP [138], AGS-CL [196] 和 NISPA [149]明确识别当前任务的重要神经元或参数，然后释放不重要部分给后续任务，这可以通过迭代修剪[291]、激活值[138],[149],[196]、不确定性估计[9]等实现。由于网络容量有限，随着引入更多增量任务，“空闲”参数往往会饱和。因此，这些方法通常需要在参数使用上施加稀疏性约束，并选择性地重用冻结的旧参数，这可能会影响每个任务的学习。为缓解这一困境，如果网络容量不足以良好学习新任务，网络架构可以动态扩展，如DEN[492], CPG [175] 和 DGMa/DGMw [322]。动态架构还可以通过强化学习（RCL[475], BNS [352]）、架构搜索（LtG [254], BNS [352]）、变分贝叶斯（BSA[232]）等优化，以提高参数效率和知识转移。由于网络扩展速度应远慢于任务增加速度以确保可扩展性，稀疏性和可重用性约束仍然重要。</p><p>图8.基于架构的方法。该方向的特点是通过适当设计的架构构建任务特定/自适应参数，例如为每个任务分配专用参数（参数分配）、构建任务自适应子模块或子网络（模块化网络）、将模型分解为任务共享和任务特定组件（模型分解）。这里展示了两种类型的模型分解，对应参数（低秩分解，改编自[178]）和表示（中间特征的掩码）。</p><h4 id="模型分解">模型分解</h4><p>模型分解明确将模型分为任务共享和任务特定组件，任务特定组件通常是可扩展的。对于常规网络，任务特定组件可以是并行分支（ACL[109], ReduNet [470], EPIE-Net [106]）、自适应层（GVCL [280], DyTox[103]）、中间特征的掩码或掩码生成器（CCLL [398], CCG [1], MARK[176]）。注意，模型分解的特征掩码不在参数空间中操作，并且不是每个任务的二进制掩码，因此与参数分配的二进制掩码本质上不同。此外，网络参数本身可以分解为任务共享和任务特定元素，例如通过加法分解（APD[490]）、奇异值分解（RCM [198]）、滤波器原子分解（FAS[304]）和低秩分解（IBP-WF [299], IRU[178]）。由于任务特定组件的数量通常随增量任务线性增长，它们的资源效率决定了这一子方向的可扩展性。</p><h4 id="模块化网络">模块化网络</h4><p>模块化网络利用并行子网络或子模块以区分的方式学习增量任务，而不预定义任务共享或任务特定组件。作为早期工作，ProgressiveNetworks [379]为每个任务引入一个相同的子网络，并通过适配器连接允许知识转移。ExpertGate [14] 和后续工作[80]使用专家混合体[184]学习增量任务，每引入一个任务就扩展一个专家。PathNet[117] 和 RPSNet [356]预先分配多个并行网络以构建一些候选路径，即网络模块的分层组合，并为每个任务选择最佳路径。MNTDP[427] 和 LMC [323]尝试从先前的子模块和潜在的新子模块中找到最佳布局。与参数分配类似，这些努力有意构建任务特定模型，同时子网络或子模块的组合允许明确的知识重用。此外，可以鼓励子网络并行学习增量任务。ModelZoo [361]扩展子网络以通过经验重放学习每个新任务，并集成所有子网络进行预测。CoSCL[443] 和 CAF [442]集成多个连续学习模型并调节它们之间的预测相似性，证明在解决任务分布差异和改善损失景观平坦性方面有效。</p><h4 id="任务特定自适应参数">任务特定/自适应参数</h4><p>从广义上讲，从任务条件参数分布中采样参数（MERLIN [223], PR [161],PGMA [170], HNET[431]），以及通过权重正则化稳定重要参数，可以视为导出任务特定/自适应参数的一种形式。与其他方向相比，大多数基于架构的方法相当于在网络参数中使增量任务去相关，这几乎可以避免灾难性遗忘，但影响可扩展性和任务间可推广性。特别是，任务标识通常需要确定使用哪组参数，从而大大限制其应用。为克服这一限制，可以从每个任务特定模型的响应（例如预测不确定性）中推断任务标识[14],[161],[218]。任务标识预测的功能还可以通过增量任务显式学习，使用其他连续学习策略来减轻灾难性遗忘[1],[80], [109], [161], [190], [223], [299]。</p><p>此外，基本架构的设计和选择对连续学习性能有很大影响。例如，由于梯度方向中更多的正交性和稀疏性以及较慢的训练机制，较宽的网络往往对灾难性遗忘更具鲁棒性[309],[310]。批量归一化（BN）层[180]往往引入对当前任务的偏差矩，这导致先前任务的次优性能[59],[284],[345]。在稳定网络中的Dropout[403]表现得像一个门控机制，创建任务特定路径，从而减轻灾难性遗忘[311]。</p>]]></content>
    
    
    <categories>
      
      <category>Paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>持续学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BUPT AI大三下生存指南</title>
    <link href="/2024/07/04/Talk/BUPT%20AI%E5%A4%A7%E4%B8%89%E4%B8%8B%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97/"/>
    <url>/2024/07/04/Talk/BUPT%20AI%E5%A4%A7%E4%B8%89%E4%B8%8B%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>主要内容是AI大三下各个选修课和必修课的主观感受，so仅供参考。</p><p>从必修课开始讲起</p><h3 id="nlp">NLP</h3><h6 id="教师王小捷老师">教师：王小捷老师</h6><h4 id="考核方式">考核方式：</h4><h5 id="教材阅读-4x624分">教材阅读 (4x6=24分)</h5><ul><li><p>阅读JMBook的其中4章:chap6\7\9\10，在教学云平台上规定的时间点。</p></li><li><p>阅读报告内容:</p><ul><li><p>章节内容综述</p></li><li><p>提出至少1个问题</p></li><li><p>全文至少1页 (A4纸，5号单倍行距编码作业)</p></li></ul></li></ul><h5 id="编码作业2-x-16分">编码作业（2 x 16分）</h5><ul><li>SGNS词向量实现与评估、Transformer序标实现与评估 (2次*16分/次 =32分</li></ul><p>课程参与 (4分)</p><ul><li>课堂、课下交流，各种对课程的反馈等参与度</li></ul><h5 id="课程大作业-40分-3人一组">课程大作业 (40分, 3人一组)</h5><ul><li><p>从某个研究问题(或应用需求)出发，基于<strong>三种课上讲的NLP技术进行</strong>解决方案的设计和实现</p></li><li><p>任务需求分析 (5分)</p></li><li><p>技术方案设计 (10分)</p></li><li><p>课程作业报告:</p><ul><li>实现、结果及分析 (25分)</li></ul></li></ul><h4 id="课程感受">课程感受：</h4><p><strong>授课水平</strong>：王老师是AI比较知名的科研牛导，讲课很细致，如果基础不是很牢固的话还是很建议听的，尤其是和自己目前学习方向如果有重合的内容王老师的课程可以帮助你节省不少时间。</p><p><strong>如何拿分</strong>：这门课以前好像是考试课，现在改成考察后相对应的各种大小作业占比很高。</p><ul><li><p><strong>阅读作业</strong>，建议从长远角度出发还是认真看JMBook，但是想要稳定的中上的分数可以：从每个章节挑点话翻译，然后拼凑出来不短的篇幅即可。我的分数是两次算是中上，两次中。前面提到的技巧是后来从舍友哪里学到的，还有就是用latex卷格式意义不大，当然只是身边案例。</p></li><li><p><strong>编码作业</strong>，我们是一个班配置8个助教，所以你的代码是会被上机跑的，so首先<strong>不要抄袭</strong>。其次拿报告来说这个卷格式就是有用的了，latex或者markdown都行，按照发的材料要求的每条内容都撰写清楚，还有就是在开头最好给出任务的拆解（助教讲作业说的，画图标清曲线对应的参数模型等）。最后说说具体的实现代码，良好的注释自然是不必说的（如果是gpt给你生的注意统一中英文，别注释的语言都不统一），其次就是性能，优秀代码的必要条件就是抛出来的result得分高，当然老师是不会给测试集的。第二份作业拿了优秀，放在对应的文件夹里了。</p></li><li><p><strong>大作业</strong>，这个应该很重要的。本来以为nlp没法上90，最终课程出分<strong>91</strong>，感觉就是大作业验收效果比较好。我分到的是两个助教学姐，我讲的很多她们就基本问不出什么问题。</p></li><li><p><strong>签到</strong>，按班级的学号顺序点人回答问题，只要在场就行。</p></li></ul><p><strong>课程小结</strong>：48学时本来应该只有32的授课学时，但是老师都用来讲课了，这就导致你想保质保量完成作业压力不算小，在课上经常看到很多同学赶作业。而且保研提上进程，不少同学都忙着进组或者夏令营。种种因素下课程听课的人不多，前半学期事不多的时候每节课前我都会学一下cs224n的对应部分，课上再做做笔记，后半期课听的也就不多了。但是平心而论这门课整体质量算是中上，值得一听，如果阅读至此的诸君在平日学习游刃有余的话还是建议听课同时学一下cs224n的内容的。</p><hr /><h3 id="计算机视觉">计算机视觉</h3><h6 id="教师鲁鹏老师">教师：鲁鹏老师</h6><h4 id="考核方式-1">考核方式：</h4><ul><li><p>平时成绩: 30%(2次作业+出勤)</p></li><li><p>课程设计: 30%</p></li><li><p>期末考试: 40% #### 课程感受：</p></li></ul><p><strong>授课水平</strong>：鲁鹏老师的课程放到B站还有很多同学去看，其水平可见一斑。上了三年学，毫不夸张的说鲁鹏老师的课是目前唯一让我知道我在学习什么，我为什么要学习这些内容，学习这些内容有什么用，而非许多课只会重复人工智能的三起三落。</p><p><strong>如何拿分</strong>： <strong>更新：</strong>最终出分<strong>90</strong>，没之前学长学姐说的85那么低，应该认真做作业（尤其是大作业），考试好好准备就不低。</p><p>非常遗憾，这门课给分不高，所以我仅能从个人经验提一些建议：</p><p>小作业svm分类那个用老师讲的特征指标大概是不用的两倍（给的参考论文就是这个东西），这个作业截止了我和同学才发现这个东西，不知道是否影响判分，但是想必多少是有影响的。</p><p>签到的话只有人比较少才会点名。</p><p>大作业的话就是各显神通，注意要做出来完整的系统，还有就是目标追踪有拿较高分数的。</p><h5id="春考试题目考完第二天回忆的有差错别怪我">24春考试题目（考完第二天回忆的，有差错别怪我）：</h5><p><strong>简答题：</strong></p><p>第一题是计算机视觉的定义和难点（很多同学会发现学了一学期说不出来什么是计算机视觉，难点的话我写的是鲁鹏老师线下课程总结说的无法像nlp一样自监督进行训练），其他都是好找的，比如hough流程以及优缺点，相机标定过程等。</p><p><strong>设计题：</strong></p><p>1.传菜机器人（双目立体视觉系统），不是平行视图，相机为标定</p><p>2.乒乓球陪练，房间四角四个未标定的相机重建乒乓球位置</p><p>3.作业题那个圆检测</p><p>4.作业题图像分类</p><p>5.角点检测系统设计</p><p>6.目标检测，给一张图片，标出道路，行人，车辆等bounding box</p><p>7.相机对准一个禁止停车的地方，要求实现有违规停车时给出提醒</p><p>tips：1.资料一定要装订好，我的资料散了，canny的那页内容找不到了，还好记了大概</p><p><strong>课程小结</strong>：48学时本来应该只有32的授课学时，但是老师都用来讲课了，这就导致你想保质保量完成作业压力不算小，在课上经常看到很多同学赶作业。而且保研提上进程，不少同学都忙着进组或者夏令营。种种因素下课程听课的人不多，前半学期事不多的时候每节课前我都会学一下cs224n的对应部分，课上再做做笔记，后半期课听的也就不多了。但是平心而论这门课整体质量算是中上，值得一听，如果阅读至此的诸君在平日学习游刃有余的话还是建议听课同时学一下cs224n的内容的。</p><hr /><h3 id="智能信息网络实验">智能信息网络实验</h3><h6 id="教师谭咏梅老师">教师：谭咏梅老师</h6><h4 id="考核方式-2">考核方式：</h4><p><strong>平时表现、小实验+大作业</strong>：总评成绩将由平时表现和小实验（40%）以及大作业（60%）构成。</p><h4 id="课程感受-1">课程感受：</h4><p><strong>授课水平</strong>：tym懂的都懂。</p><p><strong>如何拿分</strong>：请tym当指导老师参加比赛</p><ul><li><strong>签到</strong>，第二节课末或者第三节课课中点名，每次都点。</li></ul><p><strong>课程小结</strong>：这门课被我误打误撞发现了拿分要点。tym老师不知何原因应该是转教学岗了，她这个课的目的就是让你在<strong>她的指导下</strong>拿奖，所以选一个合适的比赛请tym当指导老师会舒服很多。大作业的选题不重要，只要让tym当指导老师就行，如果比赛有机会拿奖的话你会见到tym老师未曾轻易向学生展示的温柔一面。最后因为“小组作业组长做”导致比赛没拿奖喜提<strong>“93”</strong>。</p><hr /><h3 id="语音信息处理">语音信息处理</h3><h6 id="教师李雅老师">教师：李雅老师</h6><h4 id="考核方式-3">考核方式：</h4><p><strong>平时表现、三个小实验+大作业</strong>：总评成绩将由平时表现和实验成绩（40%）以及大作业（60%）构成。</p><h4 id="分组大作业考核基本要求">分组大作业考核基本要求</h4><ul><li><strong>自由分组</strong>：需在第3次课前完成分组，每组4-5人，指定一位组长，并在报告中明确每位成员的贡献。</li><li>提交材料：<ol type="1"><li><strong>书面报告</strong>：一次。</li><li><strong>公开演讲</strong>：一次。</li></ol></li><li><strong>格式</strong>：报告格式应参照一般的论文格式。</li><li><strong>提交方式</strong>：报告需提前发送至老师邮箱yli01@bupt.edu.cn，邮件主题格式为“队伍编号+作业主题”。具体提交时间待后续通知。</li><li><strong>系统提交</strong>：需提交完整的系统，包括数据和源代码。对于体积较大的文件，如预训练模型、数据等，可以上传至百度云，并在报告中附上下载链接。</li></ul><h4 id="课程感受-2">课程感受：</h4><p><strong>授课水平</strong>：中规中矩，平均水平，如果不是有志于此的方向不建议去听。</p><p><strong>如何拿分</strong>：最后的大作业答辩尽力展示<strong>自己</strong>。</p><ul><li><strong>课程实验</strong>，都不难，很好水，能回答出来助教的问题就行。</li><li><strong>大作业</strong>，很重要，关键性决定因素。最好找稍微靠谱但能力不如你的同学组队。最后是”李蓝天“负责的答辩，会问很多细致的问题，谁被拷打且回答的满意会有很高的分（如果你不是上去讲的人的话即使出力多分数也不会高）。难度高的选题分数不如难度低的组的最高分，所以你应该知道怎么组队了吧。</li><li><strong>签到</strong>，说过两次签到，但是一次都没签，去的人也不多。</li></ul><p><strong>课程小结</strong>：这课和混的同学组的队，我负责了一次实验，大作业通过我一个人做NLP来交换这个课大作业由别人负责结果就是DDL前五天他们才开始搞，最后验收时负责技术的还睡过头了，最终得分远低于平均。幸好博主的成绩保外不足，保内有余，要不然这课分差还是蛮大的，只能安慰自己没在这门课上浪费时间了。</p><hr /><h3 id="脑认知">脑认知</h3><h6 id="教师仲苏玉老师">教师：仲苏玉老师</h6><h4 id="考核方式-4">考核方式：</h4><p><strong>平时表现（随堂小测），作业+开卷考试</strong></p><h4 id="课程感受-3">课程感受：</h4><p><strong>授课水平</strong>：仲苏玉老师是大一C++的授课老师，这么多年过去老师也深谙授课之道，虽然讲的不怎么样。</p><p><strong>如何拿分</strong>：开卷考试考好。</p><ul><li><strong>开卷考试</strong>，<strong>买书！买书！买书！</strong>。</li><li><strong>作业</strong>，老师直接忘记布置了，最后才布置，gpt之类的水一下就行。</li><li><strong>随堂小测</strong>，感觉是让别人代交也行，随便写写即可。</li></ul><p><strong>课程小结</strong>：这课也是浪费时间的水课，重点再说下期末。期末的开卷老师给个ppt有很多复习题，但是没有书你很多问题是回答不上来的。另外有能力的最好找前辈要下往年题让gpt模拟点大题学习一下思路。最后没书的我和舍友83,75；拿我部分资料且有书的同学91。</p><hr /><h3 id="linux">Linux</h3><p>不细说了，基本人均<strong>“95”</strong>，老师就点了一次名还因为来25人签到50人恼羞成怒之后给作废了</p><hr /><h3 id="学期总结">学期总结</h3><p>总的来说这学期的课不多，但是课程作业如果认真完成的压力不算小，如果是考研的同学建议及时开摆。保研的同学前面提到的一些课程还是建议认真学习的，要不然读研了还要补。还有就是尽早联系靠谱的老师，这里点名知名牛导xwr，变热门后养一堆实习生。最好早早找靠谱导师后开始进组沉淀，个人感觉如果想搞科研提前进组还是有必要的。找导师的话青椒里还是有挺不错的盲盒，建议仔细找找。想冲wxj，ycx这种热门导师的同学做好8月还找不到导师的准备，这俩老师据我了解只在夏令营各收了一个前十。如果有想了解导师的也可以在置顶文章的链接进去评论，如果我了解且能回答的话会回复。</p>]]></content>
    
    
    <categories>
      
      <category>Talk</category>
      
    </categories>
    
    
    <tags>
      
      <tag>课程</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
